{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Write-out-the-frame-table\" data-toc-modified-id=\"Write-out-the-frame-table-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Write out the frame table</a></span></li><li><span><a href=\"#Write-out-the-video-table\" data-toc-modified-id=\"Write-out-the-video-table-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Write out the video table</a></span></li><li><span><a href=\"#Write-out-the-identity-table\" data-toc-modified-id=\"Write-out-the-identity-table-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Write out the identity table</a></span></li><li><span><a href=\"#Write-out-interval-sets\" data-toc-modified-id=\"Write-out-interval-sets-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Write out interval sets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Commercials\" data-toc-modified-id=\"Commercials-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Commercials</a></span></li><li><span><a href=\"#Faces\" data-toc-modified-id=\"Faces-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Faces</a></span></li><li><span><a href=\"#Identity\" data-toc-modified-id=\"Identity-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Identity</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T19:06:46.745581Z",
     "start_time": "2019-04-30T19:06:46.712865Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "from pytz import timezone\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from django.db.models import F, ExpressionWrapper, FloatField, IntegerField\n",
    "\n",
    "from esper.spark_util import *\n",
    "from esper.major_canonical_shows import MAJOR_CANONICAL_SHOWS\n",
    "\n",
    "WIDGET_DATA_DIR = '/app/data/widget-data'\n",
    "if not os.path.exists(WIDGET_DATA_DIR):\n",
    "    os.makedirs(WIDGET_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T18:52:01.559834Z",
     "start_time": "2019-04-30T18:52:01.522877Z"
    }
   },
   "outputs": [],
   "source": [
    "OVERWRITE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T08:04:29.301669Z",
     "start_time": "2019-04-30T07:58:12.798219Z"
    }
   },
   "outputs": [],
   "source": [
    "face_genders = get_face_genders()\n",
    "face_genders = face_genders.where(\n",
    "    (face_genders.labeler_id == Labeler.objects.get(name='knn-gender').id) &\n",
    "    (face_genders.height >= 0.2) # &\n",
    "#     (face_genders.in_commercial == False)\n",
    ")\n",
    "face_genders = face_genders.withColumn('start_time', face_genders.min_frame / face_genders.fps)\n",
    "face_genders = face_genders.withColumn('end_time', face_genders.max_frame / face_genders.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T11:13:32.146890Z",
     "start_time": "2019-04-24T11:12:15.539217Z"
    }
   },
   "outputs": [],
   "source": [
    "face_identities = get_face_identities()\n",
    "face_identities = face_identities.where(\n",
    "#     (face_identities.in_commercial == False) &\n",
    "    (face_identities.height >= 0.2)\n",
    ")\n",
    "face_identities = face_identities.withColumn('start_time', face_identities.min_frame / face_identities.fps)\n",
    "face_identities = face_identities.withColumn('end_time', face_identities.max_frame / face_identities.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T08:01:20.253737Z",
     "start_time": "2019-03-09T08:01:20.206986Z"
    }
   },
   "outputs": [],
   "source": [
    "class FrameInfo(object):\n",
    "    \n",
    "    def __init__(self, start, end):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.male_cnt = 0.\n",
    "        self.female_cnt = 0.\n",
    "        self.gender_var = 0. # SURPRISE! THEY ARE EQUAL!\n",
    "        self.male_nh_cnt = 0.\n",
    "        self.female_nh_cnt = 0.\n",
    "        self.gender_nh_var = 0.\n",
    "        self.identities = {}\n",
    "    \n",
    "    def add_face_gender(self, fg):\n",
    "        female_prob = fg['female_probability']\n",
    "        male_prob = fg['male_probability']\n",
    "        nh_host_prob = 1. - fg['host_probability']\n",
    "        \n",
    "        # Adding indicator variables and their variances\n",
    "        self.male_cnt += male_prob\n",
    "        self.female_cnt += female_prob\n",
    "        self.gender_var += (1. - male_prob) * male_prob\n",
    "        \n",
    "        self.male_nh_cnt += male_prob * nh_host_prob\n",
    "        self.female_nh_cnt += female_prob * nh_host_prob\n",
    "        self.gender_nh_var += (1. - male_prob) * male_prob * (nh_host_prob ** 2)\n",
    "    \n",
    "    def add_face_identity(self, fi):\n",
    "        identity_id = fi['identity_id']\n",
    "        identity_prob = fi['probability']\n",
    "        if identity_id in self.identities:\n",
    "            cur_cnt, cur_var = self.identities[identity_id]\n",
    "        else:\n",
    "            cur_cnt, cur_var = 0., 0.\n",
    "        self.identities[identity_id] = (cur_cnt + identity_prob, cur_var + identity_prob * (1. - identity_prob))\n",
    "        \n",
    "    def get(self):\n",
    "        return (\n",
    "            self.start, self.end, \n",
    "            self.male_cnt,\n",
    "            self.female_cnt, \n",
    "            self.gender_var, \n",
    "            self.male_nh_cnt,\n",
    "            self.female_nh_cnt,\n",
    "            self.gender_nh_var,\n",
    "            self.identities\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T09:13:58.246526Z",
     "start_time": "2019-03-09T08:01:23.002567Z"
    }
   },
   "outputs": [],
   "source": [
    "video_id_to_frames_to_info = {}\n",
    "\n",
    "fg_query = face_genders.select(\n",
    "    'video_id', 'min_frame', 'start_time', 'end_time', \n",
    "    'male_probability', 'female_probability', 'host_probability'\n",
    ")\n",
    "# fg_query = fg_query.limit(1000)\n",
    "\n",
    "for fg in fg_query.collect():\n",
    "    video_id = fg.video_id\n",
    "    frames_to_info = video_id_to_frames_to_info.get(video_id, {})\n",
    "    min_frame = fg.min_frame\n",
    "    if min_frame not in frames_to_info:\n",
    "        frames_to_info[min_frame] = FrameInfo(fg.start_time, fg.end_time)\n",
    "    frames_to_info[min_frame].add_face_gender(fg)\n",
    "    video_id_to_frames_to_info[video_id] = frames_to_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T09:37:07.329783Z",
     "start_time": "2019-03-09T09:13:58.250023Z"
    }
   },
   "outputs": [],
   "source": [
    "fi_query = face_identities.select(\n",
    "    'video_id', 'min_frame', 'start_time', 'end_time',\n",
    "    'identity_id', 'probability'\n",
    ")\n",
    "# fi_query = fi_query.limit(1000)\n",
    "\n",
    "for fi in fi_query.collect():\n",
    "    video_id = fi.video_id\n",
    "    frames_to_info = video_id_to_frames_to_info.get(video_id, {})\n",
    "    min_frame = fi.min_frame\n",
    "    if min_frame not in frames_to_info:\n",
    "        print('Weird: {} has no gender but has identities'.format(min_frame))\n",
    "        frames_to_info[min_frame] = FrameInfo(fi.start_time, fi.end_time)\n",
    "    frames_to_info[min_frame].add_face_identity(fi)\n",
    "    video_id_to_frames_to_info[video_id] = frames_to_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T09:55:07.644883Z",
     "start_time": "2019-03-09T09:37:07.633812Z"
    }
   },
   "outputs": [],
   "source": [
    "output_video_id_to_frames = {}\n",
    "for video_id, f2i in video_id_to_frames_to_info.items():\n",
    "    frame_list = []\n",
    "    for min_frame, frame_info in f2i.items():\n",
    "        frame_list.append((min_frame, *frame_info.get()))\n",
    "    frame_list.sort(key=lambda x: x[1]) # sort by start time\n",
    "    output_video_id_to_frames[video_id] = frame_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the frame table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T10:57:03.293089Z",
     "start_time": "2019-03-09T10:07:03.305962Z"
    }
   },
   "outputs": [],
   "source": [
    "FRAME_PER_VIDEO_DIR = os.path.join(WIDGET_DATA_DIR, 'frame_table')\n",
    "if not os.path.exists(FRAME_PER_VIDEO_DIR):\n",
    "    os.makedirs(FRAME_PER_VIDEO_DIR)\n",
    "\n",
    "for video_id in tqdm(output_video_id_to_frames):\n",
    "    video_file_path = os.path.join(FRAME_PER_VIDEO_DIR, '{}.json'.format(video_id))\n",
    "    with open(video_file_path, 'w') as f:\n",
    "        json.dump(output_video_id_to_frames[video_id], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the video table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T18:54:27.073770Z",
     "start_time": "2019-04-30T18:54:18.080528Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_video_name(p):\n",
    "    return Path(p).name.split('.')[0]\n",
    "\n",
    "UTC = timezone('UTC')\n",
    "EST = timezone('EST')\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "def get_date_minute_from_name(p):\n",
    "    channel, ymd, hms, _ = p.split('_', 3)\n",
    "    timestamp = datetime.datetime.strptime(ymd + hms, '%Y%m%d%H%M%S')\n",
    "    timestamp_est = timestamp.replace(tzinfo=UTC).astimezone(tz=EST)\n",
    "    assert timestamp.hour != timestamp_est.hour\n",
    "    return timestamp_est.strftime(DATE_FORMAT), timestamp_est.hour * 60 + timestamp_est.minute\n",
    "\n",
    "video_data = []\n",
    "for v in Video.objects.filter(\n",
    "    duplicate=False, corrupted=False,\n",
    ").values(\n",
    "    'id', 'path', 'show__canonical_show__name', 'channel__name', 'num_frames', 'fps', 'width', 'height'\n",
    "):\n",
    "    video_name = get_video_name(v['path'])\n",
    "    video_date, video_minute = get_date_minute_from_name(video_name)\n",
    "    video_data.append((\n",
    "        v['id'],\n",
    "        video_name,\n",
    "        v['show__canonical_show__name'],\n",
    "        v['channel__name'],\n",
    "        video_date,\n",
    "        video_minute,\n",
    "        v['num_frames'],\n",
    "        v['fps'],\n",
    "        v['width'],\n",
    "        v['height']\n",
    "    ))\n",
    "                      \n",
    "VIDEO_TABLE_PATH = os.path.join(WIDGET_DATA_DIR, 'videos.json')\n",
    "if not OVERWRITE and os.path.exists(VIDEO_TABLE_PATH):\n",
    "    raise Exception('File exists!')\n",
    "    \n",
    "with open(VIDEO_TABLE_PATH, 'w') as f:\n",
    "    json.dump(video_data, f)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the identity table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T23:56:55.378163Z",
     "start_time": "2019-03-15T23:56:55.336677Z"
    }
   },
   "outputs": [],
   "source": [
    "identity_data = [(i.id, i.name) for i in Identity.objects.all()]\n",
    "\n",
    "IDENTITY_TABLE_PATH = os.path.join(WIDGET_DATA_DIR, 'identity.json')\n",
    "if not OVERWRITE and os.path.exists(IDENTITY_TABLE_PATH):\n",
    "    raise Exception('File exists!')\n",
    "    \n",
    "with open(IDENTITY_TABLE_PATH, 'w') as f:\n",
    "    json.dump(identity_data, f)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out interval sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T19:08:03.742706Z",
     "start_time": "2019-04-30T19:08:03.684995Z"
    }
   },
   "outputs": [],
   "source": [
    "class IntervalSetMappingWriter(object):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self._fp = open(path, 'wb')\n",
    "        self._path = path\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, tb):\n",
    "        self.close()\n",
    "\n",
    "    def __fmt_u32(self, v):\n",
    "        return v.to_bytes(4, byteorder='little')\n",
    "\n",
    "    def write(self, id_, intervals):\n",
    "        self._fp.write(self.__fmt_u32(id_))\n",
    "        self._fp.write(self.__fmt_u32(len(intervals)))\n",
    "        for a, b in intervals:\n",
    "            self._fp.write(self.__fmt_u32(a))\n",
    "            self._fp.write(self.__fmt_u32(b))\n",
    "\n",
    "    def close(self):\n",
    "        if self._fp is not None:\n",
    "            self._fp.close()\n",
    "            self._fp = None\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return self._path\n",
    "    \n",
    "class IntervalAccumulator(object):\n",
    "    \n",
    "    def __init__(self, fuzz=250):\n",
    "        self._intervals = None\n",
    "        self._fuzz = fuzz\n",
    "        \n",
    "    def add(self, start, end):\n",
    "        assert start <= end\n",
    "        start = max(0, start - self._fuzz)\n",
    "        end += self._fuzz\n",
    "        if not self._intervals:\n",
    "            self._intervals = [(start, end)]\n",
    "        else:\n",
    "            last_int = self._intervals[-1]\n",
    "            if start > last_int[1]:\n",
    "                self._intervals.append((start, end))\n",
    "            elif end > last_int[1]:\n",
    "                assert start >= last_int[0]\n",
    "                assert last_int[0] <= end\n",
    "                self._intervals[-1] = (last_int[0], end)\n",
    "    \n",
    "    def get(self):\n",
    "        return self._intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commercials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T19:09:05.551234Z",
     "start_time": "2019-04-30T19:08:50.916957Z"
    }
   },
   "outputs": [],
   "source": [
    "COMMERCIAL_INTERVAL_FILE = '/app/data/widget-data/commercials.bin'\n",
    "\n",
    "commercials_by_video_id = defaultdict(list) \n",
    "for c in Commercial.objects.filter(\n",
    "    labeler__name='haotian-commercials', \n",
    "    video__duplicate=False, video__corrupted=False\n",
    ").annotate(\n",
    "    start_ms=ExpressionWrapper(F('min_frame') / F('video__fps') * 1000, output_field=IntegerField()),\n",
    "    end_ms=ExpressionWrapper(F('max_frame') / F('video__fps') * 1000, output_field=IntegerField())\n",
    ").values('video__id', 'start_ms', 'end_ms'):\n",
    "    commercials_by_video_id[c['video__id']].append((c['start_ms'], c['end_ms']))\n",
    "\n",
    "with IntervalSetMappingWriter(\n",
    "    os.path.join(COMMERCIAL_INTERVAL_FILE, COMMERCIAL_INTERVAL_FILE)\n",
    ") as COMM_INTS:\n",
    "    for video_id in sorted(commercials_by_video_id.keys()):\n",
    "        COMM_INTS.write(video_id, list(sorted(commercials_by_video_id[video_id])))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T09:52:43.755059Z",
     "start_time": "2019-04-30T08:04:29.367080Z"
    }
   },
   "outputs": [],
   "source": [
    "FACE_INTERVAL_DIR = '/app/data/widget-data/face'\n",
    "if not os.path.exists(FACE_INTERVAL_DIR):\n",
    "    os.makedirs(FACE_INTERVAL_DIR)\n",
    "\n",
    "with IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'all.bin')\n",
    ") as ALL_INTS, IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'male.bin')\n",
    ") as MALE_INTS, IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'female.bin')\n",
    ") as FEMALE_INTS, IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'host.bin')\n",
    ") as HOST_INTS, IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'nonhost.bin')\n",
    ") as NON_HOST_INTS, IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'male_host.bin')\n",
    ") as MALE_HOST_INTS, IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'male_nonhost.bin')\n",
    ") as MALE_NON_HOST_INTS, IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'female_host.bin')\n",
    ") as FEMALE_HOST_INTS, IntervalSetMappingWriter(\n",
    "    os.path.join(FACE_INTERVAL_DIR, 'female_nonhost.bin')\n",
    ") as FEMALE_NON_HOST_INTS:\n",
    "    face_genders_int = face_genders\n",
    "    face_genders_int = face_genders_int.withColumn(\n",
    "        'start_ms', (face_genders_int.start_time * 1000).cast('int'))\n",
    "    face_genders_int = face_genders_int.withColumn(\n",
    "        'end_ms', (face_genders_int.end_time * 1000).cast('int'))\n",
    "    \n",
    "    # DEBUG\n",
    "#     face_genders_int = face_genders_int.where(face_genders_int.video_id < 10)\n",
    "    \n",
    "    fg_query = face_genders_int.select(\n",
    "        'video_id', 'start_ms', 'end_ms', \n",
    "        'male_probability', 'host_probability'\n",
    "    ).sort('video_id', 'start_ms')\n",
    "\n",
    "    n_videos_done = 0\n",
    "    curr_video_id = None\n",
    "    for fg in fg_query.collect():\n",
    "        if fg.video_id != curr_video_id:\n",
    "            if curr_video_id is not None:\n",
    "                n_videos_done += 1\n",
    "                if n_videos_done % 1000 == 0:\n",
    "                    print('Processed {} videos'.format(n_videos_done))\n",
    "                if all_int.get():\n",
    "                    ALL_INTS.write(curr_video_id, all_int.get())\n",
    "                if male_int.get():\n",
    "                    MALE_INTS.write(curr_video_id, male_int.get())\n",
    "                if female_int.get():\n",
    "                    FEMALE_INTS.write(curr_video_id, female_int.get())\n",
    "                if host_int.get():\n",
    "                    HOST_INTS.write(curr_video_id, host_int.get())\n",
    "                if nh_int.get():\n",
    "                    NON_HOST_INTS.write(curr_video_id, nh_int.get())\n",
    "                if male_host_int.get():\n",
    "                    MALE_HOST_INTS.write(curr_video_id, male_host_int.get())\n",
    "                if male_nh_int.get():\n",
    "                    MALE_NON_HOST_INTS.write(curr_video_id, male_nh_int.get())\n",
    "                if female_host_int.get():\n",
    "                    FEMALE_HOST_INTS.write(curr_video_id, female_host_int.get())\n",
    "                if female_nh_int.get():\n",
    "                    FEMALE_NON_HOST_INTS.write(curr_video_id, female_nh_int.get())\n",
    "            \n",
    "            curr_video_id = fg.video_id\n",
    "            all_int = IntervalAccumulator()\n",
    "            male_int = IntervalAccumulator()\n",
    "            female_int = IntervalAccumulator()\n",
    "            host_int = IntervalAccumulator()\n",
    "            nh_int = IntervalAccumulator()\n",
    "            male_nh_int = IntervalAccumulator()\n",
    "            female_nh_int = IntervalAccumulator()\n",
    "            male_host_int = IntervalAccumulator()\n",
    "            female_host_int = IntervalAccumulator()\n",
    "\n",
    "        all_int.add(fg.start_ms, fg.end_ms)\n",
    "        \n",
    "        if fg.host_probability >= 0.5:\n",
    "            host_int.add(fg.start_ms, fg.end_ms)\n",
    "        else:\n",
    "            nh_int.add(fg.start_ms, fg.end_ms)\n",
    "            \n",
    "        if fg.male_probability >= 0.5:\n",
    "            male_int.add(fg.start_ms, fg.end_ms)\n",
    "            if fg.host_probability >= 0.5:\n",
    "                male_host_int.add(fg.start_ms, fg.end_ms)\n",
    "            else:\n",
    "                male_nh_int.add(fg.start_ms, fg.end_ms)\n",
    "        else:\n",
    "            female_int.add(fg.start_ms, fg.end_ms)\n",
    "            if fg.host_probability >= 0.5:\n",
    "                female_host_int.add(fg.start_ms, fg.end_ms)\n",
    "            else:\n",
    "                female_nh_int.add(fg.start_ms, fg.end_ms)\n",
    "                \n",
    "    if curr_video_id is not None:\n",
    "        if all_int.get():\n",
    "            ALL_INTS.write(curr_video_id, all_int.get())\n",
    "        if male_int.get():\n",
    "            MALE_INTS.write(curr_video_id, male_int.get())\n",
    "        if female_int.get():\n",
    "            FEMALE_INTS.write(curr_video_id, female_int.get())\n",
    "        if host_int.get():\n",
    "            HOST_INTS.write(curr_video_id, host_int.get())\n",
    "        if nh_int.get():\n",
    "            NON_HOST_INTS.write(curr_video_id, nh_int.get())\n",
    "        if male_host_int.get():\n",
    "            MALE_HOST_INTS.write(curr_video_id, male_host_int.get())\n",
    "        if male_nh_int.get():\n",
    "            MALE_NON_HOST_INTS.write(curr_video_id, male_nh_int.get())\n",
    "        if female_host_int.get():\n",
    "            FEMALE_HOST_INTS.write(curr_video_id, female_host_int.get())\n",
    "        if female_nh_int.get():\n",
    "            FEMALE_NON_HOST_INTS.write(curr_video_id, female_nh_int.get())\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T11:37:34.308167Z",
     "start_time": "2019-04-24T11:21:33.989797Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IDENTITY_INTERVAL_DIR = '/app/data/widget-data/identity'\n",
    "if not os.path.exists(IDENTITY_INTERVAL_DIR):\n",
    "    os.makedirs(IDENTITY_INTERVAL_DIR)\n",
    "\n",
    "face_identities_int = face_identities.where(face_identities.probability >= 0.5)\n",
    "face_identities_int = face_identities_int.withColumn(\n",
    "    'start_ms', (face_identities_int.start_time * 1000).cast('int'))\n",
    "face_identities_int = face_identities_int.withColumn(\n",
    "    'end_ms', (face_identities_int.end_time * 1000).cast('int'))\n",
    "\n",
    "# debug\n",
    "# face_identities_int = face_identities_int.where(face_identities_int.video_id < 10)\n",
    "\n",
    "fi_query = face_identities_int.select(\n",
    "    'video_id', 'identity_id', 'start_ms', 'end_ms'\n",
    ").sort('video_id', 'identity_id', 'start_ms')\n",
    "\n",
    "identity_writers = {}\n",
    "def flush_idenity_accumulators(video_id, accumulators):\n",
    "    for identity_id, identity_acc in accumulators.items():\n",
    "        if identity_acc.get():\n",
    "            if identity_id not in identity_writers:\n",
    "                identity_writers[identity_id] = IntervalSetMappingWriter(\n",
    "                    os.path.join(\n",
    "                        IDENTITY_INTERVAL_DIR, \n",
    "                        '{}.bin'.format(\n",
    "                            Identity.objects.get(id=identity_id).name.lower()\n",
    "                        )))\n",
    "            identity_writers[identity_id].write(video_id, identity_acc.get())\n",
    "\n",
    "n_videos_done = 0\n",
    "curr_video_id = None\n",
    "for fi in fi_query.collect():\n",
    "    if fi.video_id != curr_video_id:\n",
    "        if curr_video_id is not None:\n",
    "            n_videos_done += 1\n",
    "            if n_videos_done % 1000 == 0:\n",
    "                print('Processed {} videos'.format(n_videos_done))\n",
    "            flush_idenity_accumulators(curr_video_id, curr_accumulators)\n",
    "                    \n",
    "        curr_video_id = fi.video_id\n",
    "        curr_accumulators = defaultdict(lambda: IntervalAccumulator())\n",
    "    curr_accumulators[fi.identity_id].add(fi.start_ms, fi.end_ms)\n",
    "    \n",
    "if curr_video_id is not None:\n",
    "    flush_idenity_accumulators(curr_video_id, curr_accumulators)\n",
    "            \n",
    "for iw in identity_writers.values():\n",
    "    iw.close()\n",
    "del identity_writers\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T19:01:03.456542Z",
     "start_time": "2019-04-30T19:01:03.419585Z"
    }
   },
   "outputs": [],
   "source": [
    "Labeler.objects.filter(name__contains='haotian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
