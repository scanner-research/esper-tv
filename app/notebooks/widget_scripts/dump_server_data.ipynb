{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Write-out-the-video-table\" data-toc-modified-id=\"Write-out-the-video-table-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Write out the video table</a></span></li><li><span><a href=\"#Write-out-interval-sets\" data-toc-modified-id=\"Write-out-interval-sets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Write out interval sets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Commercials\" data-toc-modified-id=\"Commercials-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Commercials</a></span></li><li><span><a href=\"#Faces\" data-toc-modified-id=\"Faces-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Faces</a></span></li><li><span><a href=\"#Identity\" data-toc-modified-id=\"Identity-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Identity</a></span></li><li><span><a href=\"#Our-labels\" data-toc-modified-id=\"Our-labels-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Our labels</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T05:59:25.200210Z",
     "start_time": "2019-09-26T05:59:25.134060Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "from pytz import timezone\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from django.db.models import F, ExpressionWrapper, FloatField, IntegerField\n",
    "\n",
    "from esper.spark_util import *\n",
    "from esper.major_canonical_shows import MAJOR_CANONICAL_SHOWS\n",
    "\n",
    "WIDGET_DATA_DIR = '/app/data/widget-data'\n",
    "if not os.path.exists(WIDGET_DATA_DIR):\n",
    "    os.makedirs(WIDGET_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the video table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:05:40.279742Z",
     "start_time": "2019-09-25T08:05:30.883651Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_video_name(p):\n",
    "    return Path(p).name.split('.')[0]\n",
    "\n",
    "UTC = timezone('UTC')\n",
    "EST = timezone('EST')\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "def get_date_minute_from_name(p):\n",
    "    channel, ymd, hms = p.split('_', 3)[:3]\n",
    "    timestamp = datetime.datetime.strptime(ymd + hms, '%Y%m%d%H%M%S')\n",
    "    timestamp_est = timestamp.replace(tzinfo=UTC).astimezone(tz=EST)\n",
    "    assert timestamp.hour != timestamp_est.hour\n",
    "    return timestamp_est.strftime(DATE_FORMAT), timestamp_est.hour * 60 + timestamp_est.minute\n",
    "\n",
    "video_data = []\n",
    "for v in Video.objects.filter(\n",
    "    duplicate=False, corrupted=False,\n",
    ").values(\n",
    "    'id', 'path', 'show__canonical_show__name', 'channel__name', 'num_frames', 'fps', 'width', 'height'\n",
    "):\n",
    "    video_name = get_video_name(v['path'])\n",
    "    video_date, video_minute = get_date_minute_from_name(video_name)\n",
    "    video_data.append((\n",
    "        v['id'],\n",
    "        video_name,\n",
    "        v['show__canonical_show__name'],\n",
    "        v['channel__name'],\n",
    "        video_date,\n",
    "        video_minute,\n",
    "        v['num_frames'],\n",
    "        v['fps'],\n",
    "        v['width'],\n",
    "        v['height']\n",
    "    ))\n",
    "                      \n",
    "VIDEO_DATA_PATH = os.path.join(WIDGET_DATA_DIR, 'videos.json')\n",
    "with open(VIDEO_DATA_PATH, 'w') as f:\n",
    "    json.dump(video_data, f)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out interval sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T06:00:45.739139Z",
     "start_time": "2019-09-26T06:00:45.597676Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional, BinaryIO\n",
    "\n",
    "\n",
    "class IntervalSetMappingWriter(object):\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        self._fp = open(path, 'wb')\n",
    "        self._path = path\n",
    "\n",
    "    def __enter__(self) -> 'IntervalSetMappingWriter':\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, tb):\n",
    "        self.close()\n",
    "\n",
    "    def __fmt_u32(self, v: int) -> bytes:\n",
    "        return v.to_bytes(4, byteorder='little')\n",
    "\n",
    "    def write(self, id_: int, intervals: List[Tuple[int, int]]) -> None:\n",
    "        assert self._fp is not None\n",
    "        self._fp.write(self.__fmt_u32(id_))\n",
    "        self._fp.write(self.__fmt_u32(len(intervals)))\n",
    "        for a, b in intervals:\n",
    "            assert b > a, 'invalid interval: ({}, {})'.format(a, b)\n",
    "            self._fp.write(self.__fmt_u32(a))\n",
    "            self._fp.write(self.__fmt_u32(b))\n",
    "\n",
    "    def close(self) -> None:\n",
    "        if self._fp is not None:\n",
    "            self._fp.close()\n",
    "            self._fp = None\n",
    "\n",
    "    \n",
    "class IntervalAccumulator(object):\n",
    "    \n",
    "    def __init__(self, fuzz=250):\n",
    "        self._intervals = None\n",
    "        self._fuzz = fuzz\n",
    "        \n",
    "    def add(self, start, end):\n",
    "        assert start <= end\n",
    "        if not self._intervals:\n",
    "            self._intervals = [(start, end)]\n",
    "        else:\n",
    "            last_int = self._intervals[-1]\n",
    "            if start > last_int[1] + self._fuzz:\n",
    "                self._intervals.append((start, end))\n",
    "            elif end > last_int[1]:\n",
    "                assert start >= last_int[0]\n",
    "                assert last_int[0] <= end\n",
    "                self._intervals[-1] = (last_int[0], end)\n",
    "    \n",
    "    def get(self):\n",
    "        return self._intervals\n",
    "    \n",
    "\n",
    "class IntervalListMappingWriter(object):\n",
    "\n",
    "    def __init__(self, path: str, payload_len: int):\n",
    "        self._fp = open(path, 'wb')\n",
    "        self._path = path\n",
    "        self._payload_len = payload_len\n",
    "\n",
    "    def __enter__(self) -> 'IntervalListMappingWriter':\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, tb) -> None:\n",
    "        self.close()\n",
    "\n",
    "    def __fmt_u32(self, v: int) -> bytes:\n",
    "        return v.to_bytes(4, byteorder='little')\n",
    "\n",
    "    def __fmt_payload(self, v: int) -> bytes:\n",
    "        return v.to_bytes(self._payload_len, byteorder='little')\n",
    "\n",
    "    def write(self, id_: int, intervals: List[Tuple[int, int, int]]) -> None:\n",
    "        assert self._fp is not None\n",
    "        self._fp.write(self.__fmt_u32(id_))\n",
    "        self._fp.write(self.__fmt_u32(len(intervals)))\n",
    "        for a, b, c in intervals:\n",
    "            assert b > a, 'invalid interval: ({}, {})'.format(a, b)\n",
    "            self._fp.write(self.__fmt_u32(a))\n",
    "            self._fp.write(self.__fmt_u32(b))\n",
    "            self._fp.write(self.__fmt_payload(c))\n",
    "\n",
    "    def close(self) -> None:\n",
    "        if self._fp is not None:\n",
    "            self._fp.close()\n",
    "            self._fp = None\n",
    "\n",
    "\n",
    "def encode_payload(is_male, is_host, height):\n",
    "    ret = 0\n",
    "    if is_male:\n",
    "        ret |= 1\n",
    "    if is_host:\n",
    "        ret |= 1 << 1\n",
    "    ret |= height << 2\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commercials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T17:33:26.972868Z",
     "start_time": "2019-05-21T17:33:13.061804Z"
    }
   },
   "outputs": [],
   "source": [
    "COMMERCIAL_INTERVAL_FILE = '/app/data/widget-data/commercials.iset.bin'\n",
    "\n",
    "commercials_by_video_id = defaultdict(list) \n",
    "for c in Commercial.objects.filter(\n",
    "    labeler__name='haotian-commercials', \n",
    "    video__duplicate=False, video__corrupted=False\n",
    ").annotate(\n",
    "    start_ms=ExpressionWrapper(F('min_frame') / F('video__fps') * 1000, output_field=IntegerField()),\n",
    "    end_ms=ExpressionWrapper(F('max_frame') / F('video__fps') * 1000, output_field=IntegerField())\n",
    ").values('video__id', 'start_ms', 'end_ms'):\n",
    "    commercials_by_video_id[c['video__id']].append((c['start_ms'], c['end_ms']))\n",
    "\n",
    "with IntervalSetMappingWriter(\n",
    "    os.path.join(COMMERCIAL_INTERVAL_FILE, COMMERCIAL_INTERVAL_FILE)\n",
    ") as COMM_INTS:\n",
    "    for video_id in sorted(commercials_by_video_id.keys()):\n",
    "        COMM_INTS.write(video_id, list(sorted(commercials_by_video_id[video_id])))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T06:07:32.549954Z",
     "start_time": "2019-09-26T06:00:48.351412Z"
    }
   },
   "outputs": [],
   "source": [
    "face_genders = get_face_genders()\n",
    "face_genders = face_genders.where(\n",
    "    (face_genders.labeler_id == Labeler.objects.get(name='knn-gender').id)\n",
    ")\n",
    "face_genders = face_genders.withColumn(\n",
    "    'start_time', face_genders.min_frame / face_genders.fps)\n",
    "face_genders = face_genders.withColumn(\n",
    "    'end_time', face_genders.max_frame / face_genders.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:53:54.431954Z",
     "start_time": "2019-09-26T07:40:41.560654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 videos\n",
      "Processed 2000 videos\n",
      "Processed 3000 videos\n",
      "Processed 4000 videos\n",
      "Processed 5000 videos\n",
      "Processed 6000 videos\n",
      "Processed 7000 videos\n",
      "Processed 8000 videos\n",
      "Processed 9000 videos\n",
      "Processed 10000 videos\n",
      "Processed 11000 videos\n",
      "Processed 12000 videos\n",
      "Processed 13000 videos\n",
      "Processed 14000 videos\n",
      "Processed 15000 videos\n",
      "Processed 16000 videos\n",
      "Processed 17000 videos\n",
      "Processed 18000 videos\n",
      "Processed 19000 videos\n",
      "Processed 20000 videos\n",
      "Processed 21000 videos\n",
      "Processed 22000 videos\n",
      "Processed 23000 videos\n",
      "Processed 24000 videos\n",
      "Processed 25000 videos\n",
      "Processed 26000 videos\n",
      "Processed 27000 videos\n",
      "Processed 28000 videos\n",
      "Processed 29000 videos\n",
      "Processed 30000 videos\n",
      "Processed 31000 videos\n",
      "Processed 32000 videos\n",
      "Processed 33000 videos\n",
      "Processed 34000 videos\n",
      "Processed 35000 videos\n",
      "Processed 36000 videos\n",
      "Processed 37000 videos\n",
      "Processed 38000 videos\n",
      "Processed 39000 videos\n",
      "Processed 40000 videos\n",
      "Processed 41000 videos\n",
      "Processed 42000 videos\n",
      "Processed 43000 videos\n",
      "Processed 44000 videos\n",
      "Processed 45000 videos\n",
      "Processed 46000 videos\n",
      "Processed 47000 videos\n",
      "Processed 48000 videos\n",
      "Processed 49000 videos\n",
      "Processed 50000 videos\n",
      "Processed 51000 videos\n",
      "Processed 52000 videos\n",
      "Processed 53000 videos\n",
      "Processed 54000 videos\n",
      "Processed 55000 videos\n",
      "Processed 56000 videos\n",
      "Processed 57000 videos\n",
      "Processed 58000 videos\n",
      "Processed 59000 videos\n",
      "Processed 60000 videos\n",
      "Processed 61000 videos\n",
      "Processed 62000 videos\n",
      "Processed 63000 videos\n",
      "Processed 64000 videos\n",
      "Processed 65000 videos\n",
      "Processed 66000 videos\n",
      "Processed 67000 videos\n",
      "Processed 68000 videos\n",
      "Processed 69000 videos\n",
      "Processed 70000 videos\n",
      "Processed 71000 videos\n",
      "Processed 72000 videos\n",
      "Processed 73000 videos\n",
      "Processed 74000 videos\n",
      "Processed 75000 videos\n",
      "Processed 76000 videos\n",
      "Processed 77000 videos\n",
      "Processed 78000 videos\n",
      "Processed 79000 videos\n",
      "Processed 80000 videos\n",
      "Processed 81000 videos\n",
      "Processed 82000 videos\n",
      "Processed 83000 videos\n",
      "Processed 84000 videos\n",
      "Processed 85000 videos\n",
      "Processed 86000 videos\n",
      "Processed 87000 videos\n",
      "Processed 88000 videos\n",
      "Processed 89000 videos\n",
      "Processed 90000 videos\n",
      "Processed 91000 videos\n",
      "Processed 92000 videos\n",
      "Processed 93000 videos\n",
      "Processed 94000 videos\n",
      "Processed 95000 videos\n",
      "Processed 96000 videos\n",
      "Processed 97000 videos\n",
      "Processed 98000 videos\n",
      "Processed 99000 videos\n",
      "Processed 100000 videos\n",
      "Processed 101000 videos\n",
      "Processed 102000 videos\n",
      "Processed 103000 videos\n",
      "Processed 104000 videos\n",
      "Processed 105000 videos\n",
      "Processed 106000 videos\n",
      "Processed 107000 videos\n",
      "Processed 108000 videos\n",
      "Processed 109000 videos\n",
      "Processed 110000 videos\n",
      "Processed 111000 videos\n",
      "Processed 112000 videos\n",
      "Processed 113000 videos\n",
      "Processed 114000 videos\n",
      "Processed 115000 videos\n",
      "Processed 116000 videos\n",
      "Processed 117000 videos\n",
      "Processed 118000 videos\n",
      "Processed 119000 videos\n",
      "Processed 120000 videos\n",
      "Processed 121000 videos\n",
      "Processed 122000 videos\n",
      "Processed 123000 videos\n",
      "Processed 124000 videos\n",
      "Processed 125000 videos\n",
      "Processed 126000 videos\n",
      "Processed 127000 videos\n",
      "Processed 128000 videos\n",
      "Processed 129000 videos\n",
      "Processed 130000 videos\n",
      "Processed 131000 videos\n",
      "Processed 132000 videos\n",
      "Processed 133000 videos\n",
      "Processed 134000 videos\n",
      "Processed 135000 videos\n",
      "Processed 136000 videos\n",
      "Processed 137000 videos\n",
      "Processed 138000 videos\n",
      "Processed 139000 videos\n",
      "Processed 140000 videos\n",
      "Processed 141000 videos\n",
      "Processed 142000 videos\n",
      "Processed 143000 videos\n",
      "Processed 144000 videos\n",
      "Processed 145000 videos\n",
      "Processed 146000 videos\n",
      "Processed 147000 videos\n",
      "Processed 148000 videos\n",
      "Processed 149000 videos\n",
      "Processed 150000 videos\n",
      "Processed 151000 videos\n",
      "Processed 152000 videos\n",
      "Processed 153000 videos\n",
      "Processed 154000 videos\n",
      "Processed 155000 videos\n",
      "Processed 156000 videos\n",
      "Processed 157000 videos\n",
      "Processed 158000 videos\n",
      "Processed 159000 videos\n",
      "Processed 160000 videos\n",
      "Processed 161000 videos\n",
      "Processed 162000 videos\n",
      "Processed 163000 videos\n",
      "Processed 164000 videos\n",
      "Processed 165000 videos\n",
      "Processed 166000 videos\n",
      "Processed 167000 videos\n",
      "Processed 168000 videos\n",
      "Processed 169000 videos\n",
      "Processed 170000 videos\n",
      "Processed 171000 videos\n",
      "Processed 172000 videos\n",
      "Processed 173000 videos\n",
      "Processed 174000 videos\n",
      "Processed 175000 videos\n",
      "Processed 176000 videos\n",
      "Processed 177000 videos\n",
      "Processed 178000 videos\n",
      "Processed 179000 videos\n",
      "Processed 180000 videos\n",
      "Processed 181000 videos\n",
      "Processed 182000 videos\n",
      "Processed 183000 videos\n",
      "Processed 184000 videos\n",
      "Processed 185000 videos\n",
      "Processed 186000 videos\n",
      "Processed 187000 videos\n",
      "Processed 188000 videos\n",
      "Processed 189000 videos\n",
      "Processed 190000 videos\n",
      "Processed 191000 videos\n",
      "Processed 192000 videos\n",
      "Processed 193000 videos\n",
      "Processed 194000 videos\n",
      "Processed 195000 videos\n",
      "Processed 196000 videos\n",
      "Processed 197000 videos\n",
      "Processed 198000 videos\n",
      "Processed 199000 videos\n",
      "Processed 200000 videos\n",
      "Processed 201000 videos\n",
      "Processed 202000 videos\n",
      "Processed 203000 videos\n",
      "Processed 204000 videos\n",
      "Processed 205000 videos\n",
      "Processed 206000 videos\n",
      "Processed 207000 videos\n",
      "Processed 208000 videos\n",
      "Processed 209000 videos\n",
      "Processed 210000 videos\n",
      "Processed 211000 videos\n",
      "Processed 212000 videos\n",
      "Processed 213000 videos\n",
      "Processed 214000 videos\n",
      "Processed 215000 videos\n",
      "Processed 216000 videos\n",
      "Processed 217000 videos\n",
      "Processed 218000 videos\n",
      "Processed 219000 videos\n",
      "Processed 220000 videos\n",
      "Processed 221000 videos\n",
      "Processed 222000 videos\n",
      "Processed 223000 videos\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "FACE_INTERVAL_DIR = '/app/data/widget-data/face'\n",
    "if not os.path.exists(FACE_INTERVAL_DIR):\n",
    "    os.makedirs(FACE_INTERVAL_DIR)\n",
    "\n",
    "face_genders_int = face_genders\n",
    "face_genders_int = face_genders_int.withColumn(\n",
    "    'start_ms', (face_genders_int.start_time * 1000).cast('int'))\n",
    "face_genders_int = face_genders_int.withColumn(\n",
    "    'end_ms', (face_genders_int.end_time * 1000).cast('int'))\n",
    "    \n",
    "# DEBUG\n",
    "# face_genders_int = face_genders_int.where(face_genders_int.video_id < 10)\n",
    "    \n",
    "with IntervalListMappingWriter(\n",
    "    os.path.join(WIDGET_DATA_DIR, 'faces.ilist.bin'), 1\n",
    ") as ALL_FACES:\n",
    "    fg_query = face_genders_int.select(\n",
    "        'video_id', 'start_ms', 'end_ms', 'male_probability', \n",
    "        'host_probability', 'height'\n",
    "    ).sort('video_id', 'start_ms', 'end_ms')\n",
    "\n",
    "    n_videos_done = 0\n",
    "    curr_video_id = None\n",
    "    for fg in fg_query.collect():\n",
    "        if fg.video_id != curr_video_id:\n",
    "            if curr_video_id is not None:\n",
    "                n_videos_done += 1\n",
    "                if n_videos_done % 1000 == 0:\n",
    "                    print('Processed {} videos'.format(n_videos_done))\n",
    "                if curr_video_faces:\n",
    "                    ALL_FACES.write(curr_video_id, curr_video_faces)\n",
    "            \n",
    "            curr_video_id = fg.video_id\n",
    "            curr_video_faces = []\n",
    "\n",
    "        curr_video_faces.append(\n",
    "            (fg.start_ms, fg.end_ms, \n",
    "             encode_payload(\n",
    "                 fg.male_probability >= 0.5, \n",
    "                 fg.host_probability >= 0.5,\n",
    "                 min(round(fg.height * 100), 63)  # 6-bits\n",
    "             ))\n",
    "        )\n",
    "                \n",
    "    if curr_video_id is not None:\n",
    "        if curr_video_faces:\n",
    "            ALL_FACES.write(curr_video_id, curr_video_faces)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:53:56.208087Z",
     "start_time": "2019-09-26T09:53:54.435720Z"
    }
   },
   "outputs": [],
   "source": [
    "face_identities = get_face_identities()\n",
    "\n",
    "face_genders_basic = spark.load('query_facegender')\n",
    "face_genders_basic = face_genders_basic.where(\n",
    "    face_genders_basic.labeler_id == Labeler.objects.get(name='knn-gender').id)\n",
    "\n",
    "# identity_labeler_qs = (\n",
    "#     Labeler.objects.filter(name__startswith='face-identity:') |\n",
    "#     Labeler.objects.filter(name__startswith='face-identity-converted:') |\n",
    "#     Labeler.objects.filter(name__startswith='face-identity-uncommon:')\n",
    "# )\n",
    "identity_labeler_qs = (\n",
    "    Labeler.objects.filter(name='face-identity-rekognition') |\n",
    "    Labeler.objects.filter(name='face-identity-rekognition:augmented-l2-dist=0.7')\n",
    ")\n",
    "identity_labeler_ids = [x.id for x in identity_labeler_qs]\n",
    "\n",
    "face_identities = face_identities.where(\n",
    "    face_identities.labeler_id.isin(identity_labeler_ids))\n",
    "\n",
    "face_identities = face_identities.join(\n",
    "    face_genders_basic.select('face_id', 'gender_id'), \n",
    "    face_identities.face_id == face_genders_basic.face_id, 'left_outer'\n",
    ").select(\n",
    "    *[c if c != 'face_id' else 'face_identities.face_id' \n",
    "      for c in face_identities.columns],\n",
    "    face_genders_basic.gender_id\n",
    ")\n",
    "\n",
    "face_identities = face_identities.withColumn(\n",
    "    'start_time', face_identities.min_frame / face_identities.fps)\n",
    "face_identities = face_identities.withColumn(\n",
    "    'end_time', face_identities.max_frame / face_identities.fps)\n",
    "\n",
    "face_identities_int = face_identities.where(face_identities.probability >= 0.5)\n",
    "face_identities_int = face_identities_int.withColumn(\n",
    "    'start_ms', (face_identities_int.start_time * 1000).cast('int'))\n",
    "face_identities_int = face_identities_int.withColumn(\n",
    "    'end_ms', (face_identities_int.end_time * 1000).cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T10:04:20.026246Z",
     "start_time": "2019-09-26T09:53:56.212064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|identity_id|face_count|\n",
      "+-----------+----------+\n",
      "|       1238|    101525|\n",
      "|      16861|       493|\n",
      "|       4935|     28931|\n",
      "|      29719|       939|\n",
      "|      28836|      8068|\n",
      "|        833|     44446|\n",
      "|      29601|       383|\n",
      "|       5518|      2846|\n",
      "|      38868|       450|\n",
      "|       7993|       330|\n",
      "|       7982|       284|\n",
      "|      40383|       253|\n",
      "|       1591|     10816|\n",
      "|       2366|        69|\n",
      "|      41751|      1706|\n",
      "|      43527|      3347|\n",
      "|      27484|       996|\n",
      "|       1088|     38736|\n",
      "|       9427|       216|\n",
      "|      99621|        67|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Exporting intervals for 5572 identities\n"
     ]
    }
   ],
   "source": [
    "MIN_SCREENTIME_THRESHOLD = 600 # 10 minutes\n",
    "\n",
    "selected_identity_ids = []\n",
    "face_identities_counts = face_identities.groupby(\n",
    "    face_identities.identity_id\n",
    ").agg(\n",
    "    func.count(face_identities.face_id).alias('face_count')\n",
    ")\n",
    "face_identities_counts.show()\n",
    "for fi_count in face_identities_counts.where(\n",
    "    face_identities_counts.face_count >= MIN_SCREENTIME_THRESHOLD * 3\n",
    ").collect():\n",
    "    selected_identity_ids.append(fi_count['identity_id'])\n",
    "print('Exporting intervals for {} identities'.format(len(selected_identity_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:09:36.471644Z",
     "start_time": "2019-09-26T10:04:20.030029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 videos\n",
      "Processed 2000 videos\n",
      "Processed 3000 videos\n",
      "Processed 4000 videos\n",
      "Processed 5000 videos\n",
      "Processed 6000 videos\n",
      "Processed 7000 videos\n",
      "Processed 8000 videos\n",
      "Processed 9000 videos\n",
      "Processed 10000 videos\n",
      "Processed 11000 videos\n",
      "Processed 12000 videos\n",
      "Processed 13000 videos\n",
      "Processed 14000 videos\n",
      "Processed 15000 videos\n",
      "Processed 16000 videos\n",
      "Processed 17000 videos\n",
      "Processed 18000 videos\n",
      "Processed 19000 videos\n",
      "Processed 20000 videos\n",
      "Processed 21000 videos\n",
      "Processed 22000 videos\n",
      "Processed 23000 videos\n",
      "Processed 24000 videos\n",
      "Processed 25000 videos\n",
      "Processed 26000 videos\n",
      "Processed 27000 videos\n",
      "Processed 28000 videos\n",
      "Processed 29000 videos\n",
      "Processed 30000 videos\n",
      "Processed 31000 videos\n",
      "Processed 32000 videos\n",
      "Processed 33000 videos\n",
      "Processed 34000 videos\n",
      "Processed 35000 videos\n",
      "Processed 36000 videos\n",
      "Processed 37000 videos\n",
      "Processed 38000 videos\n",
      "Processed 39000 videos\n",
      "Processed 40000 videos\n",
      "Processed 41000 videos\n",
      "Processed 42000 videos\n",
      "Processed 43000 videos\n",
      "Processed 44000 videos\n",
      "Processed 45000 videos\n",
      "Processed 46000 videos\n",
      "Processed 47000 videos\n",
      "Processed 48000 videos\n",
      "Processed 49000 videos\n",
      "Processed 50000 videos\n",
      "Processed 51000 videos\n",
      "Processed 52000 videos\n",
      "Processed 53000 videos\n",
      "Processed 54000 videos\n",
      "Processed 55000 videos\n",
      "Processed 56000 videos\n",
      "Processed 57000 videos\n",
      "Processed 58000 videos\n",
      "Processed 59000 videos\n",
      "Processed 60000 videos\n",
      "Processed 61000 videos\n",
      "Processed 62000 videos\n",
      "Processed 63000 videos\n",
      "Processed 64000 videos\n",
      "Processed 65000 videos\n",
      "Processed 66000 videos\n",
      "Processed 67000 videos\n",
      "Processed 68000 videos\n",
      "Processed 69000 videos\n",
      "Processed 70000 videos\n",
      "Processed 71000 videos\n",
      "Processed 72000 videos\n",
      "Processed 73000 videos\n",
      "Processed 74000 videos\n",
      "Processed 75000 videos\n",
      "Processed 76000 videos\n",
      "Processed 77000 videos\n",
      "Processed 78000 videos\n",
      "Processed 79000 videos\n",
      "Processed 80000 videos\n",
      "Processed 81000 videos\n",
      "Processed 82000 videos\n",
      "Processed 83000 videos\n",
      "Processed 84000 videos\n",
      "Processed 85000 videos\n",
      "Processed 86000 videos\n",
      "Processed 87000 videos\n",
      "Processed 88000 videos\n",
      "Processed 89000 videos\n",
      "Processed 90000 videos\n",
      "Processed 91000 videos\n",
      "Processed 92000 videos\n",
      "Processed 93000 videos\n",
      "Processed 94000 videos\n",
      "Processed 95000 videos\n",
      "Processed 96000 videos\n",
      "Processed 97000 videos\n",
      "Processed 98000 videos\n",
      "Processed 99000 videos\n",
      "Processed 100000 videos\n",
      "Processed 101000 videos\n",
      "Processed 102000 videos\n",
      "Processed 103000 videos\n",
      "Processed 104000 videos\n",
      "Processed 105000 videos\n",
      "Processed 106000 videos\n",
      "Processed 107000 videos\n",
      "Processed 108000 videos\n",
      "Processed 109000 videos\n",
      "Processed 110000 videos\n",
      "Processed 111000 videos\n",
      "Processed 112000 videos\n",
      "Processed 113000 videos\n",
      "Processed 114000 videos\n",
      "Processed 115000 videos\n",
      "Processed 116000 videos\n",
      "Processed 117000 videos\n",
      "Processed 118000 videos\n",
      "Processed 119000 videos\n",
      "Processed 120000 videos\n",
      "Processed 121000 videos\n",
      "Processed 122000 videos\n",
      "Processed 123000 videos\n",
      "Processed 124000 videos\n",
      "Processed 125000 videos\n",
      "Processed 126000 videos\n",
      "Processed 127000 videos\n",
      "Processed 128000 videos\n",
      "Processed 129000 videos\n",
      "Processed 130000 videos\n",
      "Processed 131000 videos\n",
      "Processed 132000 videos\n",
      "Processed 133000 videos\n",
      "Processed 134000 videos\n",
      "Processed 135000 videos\n",
      "Processed 136000 videos\n",
      "Processed 137000 videos\n",
      "Processed 138000 videos\n",
      "Processed 139000 videos\n",
      "Processed 140000 videos\n",
      "Processed 141000 videos\n",
      "Processed 142000 videos\n",
      "Processed 143000 videos\n",
      "Processed 144000 videos\n",
      "Processed 145000 videos\n",
      "Processed 146000 videos\n",
      "Processed 147000 videos\n",
      "Processed 148000 videos\n",
      "Processed 149000 videos\n",
      "Processed 150000 videos\n",
      "Processed 151000 videos\n",
      "Processed 152000 videos\n",
      "Processed 153000 videos\n",
      "Processed 154000 videos\n",
      "Processed 155000 videos\n",
      "Processed 156000 videos\n",
      "Processed 157000 videos\n",
      "Processed 158000 videos\n",
      "Processed 159000 videos\n",
      "Processed 160000 videos\n",
      "Processed 161000 videos\n",
      "Processed 162000 videos\n",
      "Processed 163000 videos\n",
      "Processed 164000 videos\n",
      "Processed 165000 videos\n",
      "Processed 166000 videos\n",
      "Processed 167000 videos\n",
      "Processed 168000 videos\n",
      "Processed 169000 videos\n",
      "Processed 170000 videos\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "IDENTITY_INTERVAL_DIR = '/app/data/widget-data/aws-smoothed-identity'\n",
    "if not os.path.exists(IDENTITY_INTERVAL_DIR):\n",
    "    os.makedirs(IDENTITY_INTERVAL_DIR)\n",
    "\n",
    "fi_query = face_identities_int.where(\n",
    "    face_identities_int.identity_id.isin(selected_identity_ids)\n",
    ").select(\n",
    "    'video_id', 'identity_id', 'start_ms', 'end_ms', \n",
    "    'host_probability', 'gender_id', 'height'\n",
    ").sort('video_id', 'identity_id', 'start_ms', 'end_ms')\n",
    "\n",
    "identity_ilist_writers = {}\n",
    "identity_id_to_name = {i.id : i.name.lower() for i in Identity.objects.all()}\n",
    "MALE_GENDER_ID = Gender.objects.get(name='M').id \n",
    "def flush_identity_accumulators(video_id, ilist_accumulators):\n",
    "    for identity_id, face_ilist in ilist_accumulators.items():\n",
    "        if face_ilist:\n",
    "            if identity_id not in identity_ilist_writers:\n",
    "                identity_ilist_writers[identity_id] = IntervalListMappingWriter(\n",
    "                    os.path.join(\n",
    "                        IDENTITY_INTERVAL_DIR, \n",
    "                        '{}.ilist.bin'.format(identity_id_to_name[identity_id])\n",
    "                    ), 1)\n",
    "            identity_ilist_writers[identity_id].write(video_id, face_ilist)\n",
    "\n",
    "n_videos_done = 0\n",
    "curr_video_id = None\n",
    "for fi in fi_query.collect():\n",
    "    if fi.video_id != curr_video_id:\n",
    "        if curr_video_id is not None:\n",
    "            n_videos_done += 1\n",
    "            if n_videos_done % 1000 == 0:\n",
    "                print('Processed {} videos'.format(n_videos_done))\n",
    "            flush_identity_accumulators(\n",
    "                curr_video_id, curr_ilist_accumulators)\n",
    "                    \n",
    "        curr_video_id = fi.video_id\n",
    "        curr_ilist_accumulators = defaultdict(list)\n",
    "    curr_ilist_accumulators[fi.identity_id].append(\n",
    "        (fi.start_ms, fi.end_ms, \n",
    "         encode_payload(\n",
    "             fi.gender_id == MALE_GENDER_ID, \n",
    "             fi.host_probability >= 0.5,\n",
    "             min(round(fi.height * 100), 63)  # 6-bits\n",
    "         ))\n",
    "    )\n",
    "    \n",
    "if curr_video_id is not None:\n",
    "    flush_identity_accumulators(curr_video_id, curr_ilist_accumulators)\n",
    "            \n",
    "for iw in identity_ilist_writers.values():\n",
    "    iw.close()\n",
    "del identity_ilist_writers\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T07:10:01.947735Z",
     "start_time": "2019-09-26T06:05:09.358Z"
    }
   },
   "source": [
    "## Our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:09:38.780384Z",
     "start_time": "2019-09-26T11:09:36.473670Z"
    }
   },
   "outputs": [],
   "source": [
    "face_identities = get_face_identities()\n",
    "\n",
    "face_genders_basic = spark.load('query_facegender')\n",
    "face_genders_basic = face_genders_basic.where(\n",
    "    face_genders_basic.labeler_id == Labeler.objects.get(name='knn-gender').id)\n",
    "\n",
    "identity_labeler_qs = (\n",
    "    Labeler.objects.filter(name__startswith='face-identity:') |\n",
    "    Labeler.objects.filter(name__startswith='face-identity-converted:') |\n",
    "    Labeler.objects.filter(name__startswith='face-identity-uncommon:')\n",
    ")\n",
    "# identity_labeler_qs = (\n",
    "#     Labeler.objects.filter(name='face-identity-rekognition') |\n",
    "#     Labeler.objects.filter(name='face-identity-rekognition:augmented-l2-dist=0.7')\n",
    "# )\n",
    "identity_labeler_ids = [x.id for x in identity_labeler_qs]\n",
    "\n",
    "face_identities = face_identities.where(\n",
    "    face_identities.labeler_id.isin(identity_labeler_ids))\n",
    "\n",
    "face_identities = face_identities.join(\n",
    "    face_genders_basic.select('face_id', 'gender_id'), \n",
    "    face_identities.face_id == face_genders_basic.face_id, 'left_outer'\n",
    ").select(\n",
    "    *[c if c != 'face_id' else 'face_identities.face_id' \n",
    "      for c in face_identities.columns],\n",
    "    face_genders_basic.gender_id\n",
    ")\n",
    "\n",
    "face_identities = face_identities.withColumn(\n",
    "    'start_time', face_identities.min_frame / face_identities.fps)\n",
    "face_identities = face_identities.withColumn(\n",
    "    'end_time', face_identities.max_frame / face_identities.fps)\n",
    "\n",
    "face_identities_int = face_identities.where(face_identities.probability >= 0.5)\n",
    "face_identities_int = face_identities_int.withColumn(\n",
    "    'start_ms', (face_identities_int.start_time * 1000).cast('int'))\n",
    "face_identities_int = face_identities_int.withColumn(\n",
    "    'end_ms', (face_identities_int.end_time * 1000).cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:48:17.187848Z",
     "start_time": "2019-09-26T11:09:38.782715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 videos\n",
      "Processed 2000 videos\n",
      "Processed 3000 videos\n",
      "Processed 4000 videos\n",
      "Processed 5000 videos\n",
      "Processed 6000 videos\n",
      "Processed 7000 videos\n",
      "Processed 8000 videos\n",
      "Processed 9000 videos\n",
      "Processed 10000 videos\n",
      "Processed 11000 videos\n",
      "Processed 12000 videos\n",
      "Processed 13000 videos\n",
      "Processed 14000 videos\n",
      "Processed 15000 videos\n",
      "Processed 16000 videos\n",
      "Processed 17000 videos\n",
      "Processed 18000 videos\n",
      "Processed 19000 videos\n",
      "Processed 20000 videos\n",
      "Processed 21000 videos\n",
      "Processed 22000 videos\n",
      "Processed 23000 videos\n",
      "Processed 24000 videos\n",
      "Processed 25000 videos\n",
      "Processed 26000 videos\n",
      "Processed 27000 videos\n",
      "Processed 28000 videos\n",
      "Processed 29000 videos\n",
      "Processed 30000 videos\n",
      "Processed 31000 videos\n",
      "Processed 32000 videos\n",
      "Processed 33000 videos\n",
      "Processed 34000 videos\n",
      "Processed 35000 videos\n",
      "Processed 36000 videos\n",
      "Processed 37000 videos\n",
      "Processed 38000 videos\n",
      "Processed 39000 videos\n",
      "Processed 40000 videos\n",
      "Processed 41000 videos\n",
      "Processed 42000 videos\n",
      "Processed 43000 videos\n",
      "Processed 44000 videos\n",
      "Processed 45000 videos\n",
      "Processed 46000 videos\n",
      "Processed 47000 videos\n",
      "Processed 48000 videos\n",
      "Processed 49000 videos\n",
      "Processed 50000 videos\n",
      "Processed 51000 videos\n",
      "Processed 52000 videos\n",
      "Processed 53000 videos\n",
      "Processed 54000 videos\n",
      "Processed 55000 videos\n",
      "Processed 56000 videos\n",
      "Processed 57000 videos\n",
      "Processed 58000 videos\n",
      "Processed 59000 videos\n",
      "Processed 60000 videos\n",
      "Processed 61000 videos\n",
      "Processed 62000 videos\n",
      "Processed 63000 videos\n",
      "Processed 64000 videos\n",
      "Processed 65000 videos\n",
      "Processed 66000 videos\n",
      "Processed 67000 videos\n",
      "Processed 68000 videos\n",
      "Processed 69000 videos\n",
      "Processed 70000 videos\n",
      "Processed 71000 videos\n",
      "Processed 72000 videos\n",
      "Processed 73000 videos\n",
      "Processed 74000 videos\n",
      "Processed 75000 videos\n",
      "Processed 76000 videos\n",
      "Processed 77000 videos\n",
      "Processed 78000 videos\n",
      "Processed 79000 videos\n",
      "Processed 80000 videos\n",
      "Processed 81000 videos\n",
      "Processed 82000 videos\n",
      "Processed 83000 videos\n",
      "Processed 84000 videos\n",
      "Processed 85000 videos\n",
      "Processed 86000 videos\n",
      "Processed 87000 videos\n",
      "Processed 88000 videos\n",
      "Processed 89000 videos\n",
      "Processed 90000 videos\n",
      "Processed 91000 videos\n",
      "Processed 92000 videos\n",
      "Processed 93000 videos\n",
      "Processed 94000 videos\n",
      "Processed 95000 videos\n",
      "Processed 96000 videos\n",
      "Processed 97000 videos\n",
      "Processed 98000 videos\n",
      "Processed 99000 videos\n",
      "Processed 100000 videos\n",
      "Processed 101000 videos\n",
      "Processed 102000 videos\n",
      "Processed 103000 videos\n",
      "Processed 104000 videos\n",
      "Processed 105000 videos\n",
      "Processed 106000 videos\n",
      "Processed 107000 videos\n",
      "Processed 108000 videos\n",
      "Processed 109000 videos\n",
      "Processed 110000 videos\n",
      "Processed 111000 videos\n",
      "Processed 112000 videos\n",
      "Processed 113000 videos\n",
      "Processed 114000 videos\n",
      "Processed 115000 videos\n",
      "Processed 116000 videos\n",
      "Processed 117000 videos\n",
      "Processed 118000 videos\n",
      "Processed 119000 videos\n",
      "Processed 120000 videos\n",
      "Processed 121000 videos\n",
      "Processed 122000 videos\n",
      "Processed 123000 videos\n",
      "Processed 124000 videos\n",
      "Processed 125000 videos\n",
      "Processed 126000 videos\n",
      "Processed 127000 videos\n",
      "Processed 128000 videos\n",
      "Processed 129000 videos\n",
      "Processed 130000 videos\n",
      "Processed 131000 videos\n",
      "Processed 132000 videos\n",
      "Processed 133000 videos\n",
      "Processed 134000 videos\n",
      "Processed 135000 videos\n",
      "Processed 136000 videos\n",
      "Processed 137000 videos\n",
      "Processed 138000 videos\n",
      "Processed 139000 videos\n",
      "Processed 140000 videos\n",
      "Processed 141000 videos\n",
      "Processed 142000 videos\n",
      "Processed 143000 videos\n",
      "Processed 144000 videos\n",
      "Processed 145000 videos\n",
      "Processed 146000 videos\n",
      "Processed 147000 videos\n",
      "Processed 148000 videos\n",
      "Processed 149000 videos\n",
      "Processed 150000 videos\n",
      "Processed 151000 videos\n",
      "Processed 152000 videos\n",
      "Processed 153000 videos\n",
      "Processed 154000 videos\n",
      "Processed 155000 videos\n",
      "Processed 156000 videos\n",
      "Processed 157000 videos\n",
      "Processed 158000 videos\n",
      "Processed 159000 videos\n",
      "Processed 160000 videos\n",
      "Processed 161000 videos\n",
      "Processed 162000 videos\n",
      "Processed 163000 videos\n",
      "Processed 164000 videos\n",
      "Processed 165000 videos\n",
      "Processed 166000 videos\n",
      "Processed 167000 videos\n",
      "Processed 168000 videos\n",
      "Processed 169000 videos\n",
      "Processed 170000 videos\n",
      "Processed 171000 videos\n",
      "Processed 172000 videos\n",
      "Processed 173000 videos\n",
      "Processed 174000 videos\n",
      "Processed 175000 videos\n",
      "Processed 176000 videos\n",
      "Processed 177000 videos\n",
      "Processed 178000 videos\n",
      "Processed 179000 videos\n",
      "Processed 180000 videos\n",
      "Processed 181000 videos\n",
      "Processed 182000 videos\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "IDENTITY_INTERVAL_DIR = '/app/data/widget-data/our-identity'\n",
    "if not os.path.exists(IDENTITY_INTERVAL_DIR):\n",
    "    os.makedirs(IDENTITY_INTERVAL_DIR)\n",
    "\n",
    "fi_query = face_identities_int.where(\n",
    "    face_identities_int.identity_id.isin(selected_identity_ids)\n",
    ").select(\n",
    "    'video_id', 'identity_id', 'start_ms', 'end_ms', \n",
    "    'host_probability', 'gender_id', 'height'\n",
    ").sort('video_id', 'identity_id', 'start_ms', 'end_ms')\n",
    "\n",
    "identity_ilist_writers = {}\n",
    "identity_id_to_name = {i.id : i.name.lower() for i in Identity.objects.all()}\n",
    "MALE_GENDER_ID = Gender.objects.get(name='M').id \n",
    "def flush_identity_accumulators(video_id, ilist_accumulators):\n",
    "    for identity_id, face_ilist in ilist_accumulators.items():\n",
    "        if face_ilist:\n",
    "            if identity_id not in identity_ilist_writers:\n",
    "                identity_ilist_writers[identity_id] = IntervalListMappingWriter(\n",
    "                    os.path.join(\n",
    "                        IDENTITY_INTERVAL_DIR, \n",
    "                        '{}.ilist.bin'.format(identity_id_to_name[identity_id])\n",
    "                    ), 1)\n",
    "            identity_ilist_writers[identity_id].write(video_id, face_ilist)\n",
    "\n",
    "n_videos_done = 0\n",
    "curr_video_id = None\n",
    "for fi in fi_query.collect():\n",
    "    if fi.video_id != curr_video_id:\n",
    "        if curr_video_id is not None:\n",
    "            n_videos_done += 1\n",
    "            if n_videos_done % 1000 == 0:\n",
    "                print('Processed {} videos'.format(n_videos_done))\n",
    "            flush_identity_accumulators(\n",
    "                curr_video_id, curr_ilist_accumulators)\n",
    "                    \n",
    "        curr_video_id = fi.video_id\n",
    "        curr_ilist_accumulators = defaultdict(list)\n",
    "    curr_ilist_accumulators[fi.identity_id].append(\n",
    "        (fi.start_ms, fi.end_ms, \n",
    "         encode_payload(\n",
    "             fi.gender_id == MALE_GENDER_ID, \n",
    "             fi.host_probability >= 0.5,\n",
    "             min(round(fi.height * 100), 63)\n",
    "         ))\n",
    "    )\n",
    "    \n",
    "if curr_video_id is not None:\n",
    "    flush_identity_accumulators(curr_video_id, curr_ilist_accumulators)\n",
    "            \n",
    "for iw in identity_ilist_writers.values():\n",
    "    iw.close()\n",
    "del identity_ilist_writers\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
