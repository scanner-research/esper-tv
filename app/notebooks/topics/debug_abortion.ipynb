{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Choose-a-Topic\" data-toc-modified-id=\"Choose-a-Topic-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Choose a Topic</a></span></li><li><span><a href=\"#Build-a-Lexicon\" data-toc-modified-id=\"Build-a-Lexicon-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build a Lexicon</a></span></li><li><span><a href=\"#Find-A-Set-of-Videos-To-Analyze\" data-toc-modified-id=\"Find-A-Set-of-Videos-To-Analyze-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Find A Set of Videos To Analyze</a></span></li><li><span><a href=\"#Plot-Timelines\" data-toc-modified-id=\"Plot-Timelines-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Plot Timelines</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-28T09:00:34.280Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "from esper.stdlib import *\n",
    "from esper.topics import *\n",
    "from esper.spark_util import *\n",
    "\n",
    "from esper.plot_timeline import VideoRow, VideoSegment, plot_video_timelines\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-28T09:00:35.516Z"
    }
   },
   "outputs": [],
   "source": [
    "topic = 'abortion'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-28T09:00:36.461Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lexicon = mutual_info(topic)\n",
    "lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find A Set of Videos To Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T09:01:16.326463Z",
     "start_time": "2018-07-24T08:58:44.226841Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_segments = find_segments(lexicon, window_size=500, threshold=100, merge_overlaps=True)\n",
    "with open('/tmp/topic-{}.pkl'.format(topic), 'wb') as f:\n",
    "    pickle.dump(merged_segments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T17:25:25.513675Z",
     "start_time": "2018-07-24T17:25:25.470371Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/tmp/topic-{}.pkl'.format(topic), 'rb') as f:\n",
    "    merged_segments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the top videos for the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T17:58:42.929075Z",
     "start_time": "2018-07-24T17:58:42.888445Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_10_videos = sorted(get_topic_time_by_video(merged_segments).items(), key=lambda x: -x[1].total_seconds())[:10]\n",
    "top_10_video_ids = { k[0] for k, _ in top_10_videos }\n",
    "top_10_sub_paths = { k[1] for k, _ in top_10_videos }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T17:25:26.348641Z",
     "start_time": "2018-07-24T17:25:25.560986Z"
    }
   },
   "outputs": [],
   "source": [
    "show_segments(filter(lambda x: x[0] in top_10_video_ids, merged_segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T17:29:08.657055Z",
     "start_time": "2018-07-24T17:25:26.351159Z"
    }
   },
   "outputs": [],
   "source": [
    "related_topics = ['supreme court', 'gay marriage', 'obamacare']\n",
    "topic_to_lexicon = { t : mutual_info(t) for t in related_topics }\n",
    "topic_to_lexicon[topic] = lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T17:59:33.314531Z",
     "start_time": "2018-07-24T17:59:33.290100Z"
    }
   },
   "outputs": [],
   "source": [
    "video_ids = list(top_10_video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T18:01:19.432375Z",
     "start_time": "2018-07-24T17:59:35.039627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the face genders and commercials dataframes\n",
    "commercials = get_commercials()\n",
    "face_genders = get_face_genders()\n",
    "\n",
    "gender_map = { x.id : x.name for x in Gender.objects.all() }\n",
    "\n",
    "# Exact mentions\n",
    "video_id_to_mentions = caption_search([topic.upper()])[0]\n",
    "\n",
    "video_id_to_face_genders = defaultdict(list)\n",
    "for face_gender in face_genders.where(\n",
    "    (face_genders.video_id.isin(video_ids)) &\n",
    "    (face_genders.host_probability < 0.8) &\n",
    "    (face_genders.probability > 0.95)\n",
    ").select('video_id', 'gender_id', 'min_frame', 'max_frame').collect():\n",
    "    video_id_to_face_genders[\n",
    "        (face_gender['video_id'], gender_map[face_gender['gender_id']])\n",
    "    ].append(\n",
    "        (face_gender['min_frame'], face_gender['max_frame'])\n",
    "    )\n",
    "\n",
    "video_id_to_commercials = defaultdict(list)\n",
    "for commercial in commercials.where(\n",
    "    commercials.video_id.isin(video_ids)\n",
    ").select('video_id', 'min_frame', 'max_frame').collect():\n",
    "    video_id_to_commercials[\n",
    "        commercial['video_id']\n",
    "    ].append((commercial['min_frame'], commercial['max_frame']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T18:02:48.780857Z",
     "start_time": "2018-07-24T18:01:19.448613Z"
    }
   },
   "outputs": [],
   "source": [
    "video_id_and_topics_to_segments = defaultdict(list)\n",
    "for t, lex in topic_to_lexicon.items(): \n",
    "    for segment in find_segments(lex, window_size=500, threshold=10, \n",
    "                                 merge_overlaps=False, docs=list(top_10_sub_paths)):\n",
    "        video_id, _, interval, score, _ = segment\n",
    "        video_id_and_topics_to_segments[(video_id, t)].append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T18:03:35.595233Z",
     "start_time": "2018-07-24T18:02:48.783375Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_helper(videos, main_topic, threshold=50, show_legend=True):\n",
    "\n",
    "    def unpack_segments(segment_list):\n",
    "        return [(interval, val) for _, _, interval, val, _ in segment_list]\n",
    "\n",
    "    rows = []\n",
    "    for video in videos:\n",
    "        vid_segments = []\n",
    "\n",
    "        # Topic Segments\n",
    "        for (a, b), val in unpack_segments(video_id_and_topics_to_segments[(video.id, main_topic)]):\n",
    "            vid_segments.append(VideoSegment(\n",
    "                start_time=timedelta(seconds=a),\n",
    "                end_time=timedelta(seconds=b),\n",
    "                display_label='non-commercial',\n",
    "                display_value=min(1., val / 250.)\n",
    "            ))\n",
    "\n",
    "        # Commerical segments\n",
    "        vid_segments.extend([\n",
    "            VideoSegment(\n",
    "                start_time=timedelta(seconds=a / video.fps),\n",
    "                end_time=timedelta(seconds=b / video.fps),\n",
    "                display_label='commercial',\n",
    "                display_value=1.\n",
    "            ) for a, b in video_id_to_commercials[video.id]\n",
    "        ])\n",
    "\n",
    "        intervals_with_women = [\n",
    "            (timedelta(seconds=a / video.fps), timedelta(seconds=b / video.fps)) \n",
    "            for a, b in video_id_to_face_genders[(video.id, 'F')]\n",
    "        ]\n",
    "\n",
    "        intervals_with_men = [\n",
    "            (timedelta(seconds=a / video.fps), timedelta(seconds=b / video.fps)) \n",
    "            for a, b in video_id_to_face_genders[(video.id, 'M')]\n",
    "        ]\n",
    "        \n",
    "        interval_labels = OrderedDict([\n",
    "            ('woman on screen (excl. hosts)', intervals_with_women),\n",
    "            ('man on screen (excl. hosts)', intervals_with_men)\n",
    "        ])\n",
    "        for t in topic_to_lexicon:\n",
    "            interval_labels['{} score >= {}'.format(t, threshold)] = [\n",
    "                (timedelta(seconds=a), timedelta(seconds=b)) \n",
    "                for _, _, (a, b), val, _ in \n",
    "                video_id_and_topics_to_segments[(video.id, t)] if val >= threshold\n",
    "            ]\n",
    "\n",
    "        row = VideoRow(\n",
    "            video,\n",
    "            segments=vid_segments,\n",
    "            # Draw some intervals on all of the videos\n",
    "            interval_labels=interval_labels,\n",
    "            discrete_labels={\n",
    "                '{} mentioned'.format(topic): [\n",
    "                    timedelta(seconds=(a + b) / 2) for a, b in video_id_to_mentions.get(video.id, [])\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        rows.append(row)\n",
    "\n",
    "    interval_color_map = {\n",
    "        'woman on screen (excl. hosts)': 'Orange',\n",
    "        'man on screen (excl. hosts)': 'Blue'\n",
    "    }\n",
    "    interval_colors = ['Red', 'Violet', 'Green', 'Pink', 'Cyan']\n",
    "    for i, t in enumerate(topic_to_lexicon):\n",
    "        interval_color_map['{} score >= {}'.format(t, threshold)] = interval_colors[i]\n",
    "    \n",
    "    plot_video_timelines(\n",
    "        rows,\n",
    "        interval_label_color_map=interval_color_map,\n",
    "        discrete_label_shape_map={\n",
    "            '{} mentioned'.format(topic): 'o'\n",
    "        },\n",
    "        show_legend=show_legend,\n",
    "        max_length=timedelta(seconds=3600 * 2),\n",
    "        min_y_margin=1500\n",
    "    )\n",
    "\n",
    "videos = list(Video.objects.filter(id__in=video_ids))\n",
    "increment = 5\n",
    "for i in range(0, len(videos), increment):\n",
    "    plot_helper(videos[i:i+increment], topic, show_legend=i==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T20:19:33.174884Z",
     "start_time": "2018-07-24T20:19:33.138007Z"
    }
   },
   "outputs": [],
   "source": [
    "def lexicon_jaccard_sim(l1, l2):\n",
    "    l1_words = set([x[0] for x in l1])\n",
    "    l2_words = set([x[0] for x in l2])\n",
    "    return len(l1_words & l2_words) / len(l1_words | l2_words)\n",
    "\n",
    "for t1, l1 in topic_to_lexicon.items():\n",
    "    for t2, l2 in topic_to_lexicon.items():\n",
    "        if t1 <= t2:\n",
    "            continue\n",
    "        print(t1, ',', t2, ',', lexicon_jaccard_sim(l1, l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T20:32:23.143767Z",
     "start_time": "2018-07-24T20:32:23.112948Z"
    }
   },
   "outputs": [],
   "source": [
    "for t, l in topic_to_lexicon.items():\n",
    "    print(t)\n",
    "    print(l[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
