{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internet Archive TV news analysis <a class=\"tocSkip\">\n",
    "This document contains the code and corresponding visualizations/statistics for answering various questions about the TV news dataset.\n",
    "\n",
    "All times shown are H*:MM:SS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from query.datasets.prelude import *\n",
    "import query.datasets.tvnews.queries as queries\n",
    "from query.datasets.tvnews.validation import *\n",
    "import pyspark.sql.functions as func\n",
    "import IPython\n",
    "import shutil\n",
    "\n",
    "rudecarnie = Labeler.objects.get(name='rudecarnie')\n",
    "mtcnn = Labeler.objects.get(name='mtcnn')\n",
    "\n",
    "spark = SparkWrapper()\n",
    "\n",
    "def format_time(seconds, padding=4):\n",
    "    return '{{:0{}d}}:{{:02d}}:{{:02d}}'.format(padding).format(seconds/3600, seconds/60 % 60, seconds % 60)\n",
    "\n",
    "def format_number(n):\n",
    "    def fmt(n):\n",
    "        suffixes = {\n",
    "            6: 'thousand',\n",
    "            9: 'million',\n",
    "            12: 'billion',\n",
    "            15: 'trillion'\n",
    "        }\n",
    "\n",
    "        log = math.log10(n)\n",
    "        suffix = None\n",
    "        key = None\n",
    "        for k in sorted(suffixes.keys()):\n",
    "            if log < k:\n",
    "                suffix = suffixes[k]\n",
    "                key = k\n",
    "                break\n",
    "\n",
    "        return '{:.2f} {}'.format(n / float(10**(key-3)), suffix)\n",
    "    if isinstance(n, list):\n",
    "        return map(fmt, n)\n",
    "    else:\n",
    "        return fmt(n)\n",
    "\n",
    "def show_df(table, ordering, clear=True):\n",
    "    if clear:\n",
    "        IPython.display.clear_output()\n",
    "    return pd.DataFrame(table)[ordering]\n",
    "        \n",
    "def format_hour(h):\n",
    "    if h <= 12:\n",
    "        return '{} AM'.format(h)\n",
    "    else:\n",
    "        return '{} PM'.format(h-12)\n",
    "    \n",
    "hours = [r['hour'] for r in \n",
    "         Video.objects.annotate(hour=Extract('time', 'hour')).distinct('hour').order_by('hour').values('hour')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#All-videos\" data-toc-modified-id=\"All-videos-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>All videos</a></span></li><li><span><a href=\"#Videos-by-channel\" data-toc-modified-id=\"Videos-by-channel-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Videos by channel</a></span></li><li><span><a href=\"#Videos-by-show\" data-toc-modified-id=\"Videos-by-show-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Videos by show</a></span></li><li><span><a href=\"#Videos-by-time-of-day\" data-toc-modified-id=\"Videos-by-time-of-day-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Videos by time of day</a></span></li></ul></li><li><span><a href=\"#Shots\" data-toc-modified-id=\"Shots-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Shots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Shot-validation\" data-toc-modified-id=\"Shot-validation-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Shot validation</a></span></li><li><span><a href=\"#All-shots\" data-toc-modified-id=\"All-shots-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>All shots</a></span></li><li><span><a href=\"#Shots-by-channel\" data-toc-modified-id=\"Shots-by-channel-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Shots by channel</a></span></li><li><span><a href=\"#Shots-by-show\" data-toc-modified-id=\"Shots-by-show-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Shots by show</a></span></li><li><span><a href=\"#Shots-by-time-of-day\" data-toc-modified-id=\"Shots-by-time-of-day-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Shots by time of day</a></span></li></ul></li><li><span><a href=\"#Commercials\" data-toc-modified-id=\"Commercials-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Commercials</a></span><ul class=\"toc-item\"><li><span><a href=\"#All-commercials\" data-toc-modified-id=\"All-commercials-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>All commercials</a></span></li><li><span><a href=\"#Commercials-by-channel\" data-toc-modified-id=\"Commercials-by-channel-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Commercials by channel</a></span></li><li><span><a href=\"#Commercials-by-show\" data-toc-modified-id=\"Commercials-by-show-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Commercials by show</a></span></li><li><span><a href=\"#Commercials-by-time-of-day\" data-toc-modified-id=\"Commercials-by-time-of-day-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Commercials by time of day</a></span></li></ul></li><li><span><a href=\"#Faces\" data-toc-modified-id=\"Faces-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Faces</a></span><ul class=\"toc-item\"><li><span><a href=\"#Face-validation\" data-toc-modified-id=\"Face-validation-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Face validation</a></span></li><li><span><a href=\"#All-faces\" data-toc-modified-id=\"All-faces-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>All faces</a></span></li></ul></li><li><span><a href=\"#Gender\" data-toc-modified-id=\"Gender-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Gender</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gender-validation\" data-toc-modified-id=\"Gender-validation-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Gender validation</a></span></li><li><span><a href=\"#All-gender\" data-toc-modified-id=\"All-gender-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>All gender</a></span></li><li><span><a href=\"#Gender-by-channel\" data-toc-modified-id=\"Gender-by-channel-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Gender by channel</a></span></li><li><span><a href=\"#Gender-by-show\" data-toc-modified-id=\"Gender-by-show-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Gender by show</a></span></li><li><span><a href=\"#Gender-by-time-of-day\" data-toc-modified-id=\"Gender-by-time-of-day-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Gender by time of day</a></span></li><li><span><a href=\"#Gender-by-day-of-the-week\" data-toc-modified-id=\"Gender-by-day-of-the-week-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Gender by day of the week</a></span></li><li><span><a href=\"#Gender-by-topic\" data-toc-modified-id=\"Gender-by-topic-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Gender by topic</a></span></li><li><span><a href=\"#Male-vs.-female-faces-in-panels\" data-toc-modified-id=\"Male-vs.-female-faces-in-panels-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>Male vs. female faces in panels</a></span></li></ul></li><li><span><a href=\"#Pose\" data-toc-modified-id=\"Pose-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Pose</a></span></li><li><span><a href=\"#Topics\" data-toc-modified-id=\"Topics-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Topics</a></span></li><li><span><a href=\"#Figures\" data-toc-modified-id=\"Figures-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Figures</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_videos():\n",
    "    return spark.qs_to_df(\n",
    "        Video.objects.all().annotate( \n",
    "            hour=Extract('time', 'hour'), duration=Cast(F('num_frames') / F('fps'), models.IntegerField())) \\\n",
    "        .values('path', 'num_frames', 'fps', 'show_id', 'channel_id', 'hour', 'duration'))\n",
    "videos = spark.load('videos', load_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def video_stats(key, labels):\n",
    "    if key is not None:\n",
    "        rows = videos.groupBy(key).agg(\n",
    "            videos[key], func.count('duration'), func.avg('duration'), func.sum('duration'), func.stddev_pop('duration')) \\\n",
    "            .collect()\n",
    "    else:\n",
    "        rows = videos.agg(\n",
    "            func.count('duration'), func.avg('duration'), func.sum('duration'), func.stddev_pop('duration')).collect()\n",
    "    rmap = {(0 if key is None else r[key]): r for r in rows}\n",
    "    return [{\n",
    "        'label': label['name'],\n",
    "        'count': rmap[label['id']]['count(duration)'],\n",
    "        'duration': format_time(int(rmap[label['id']]['sum(duration)'])),\n",
    "        'avg_duration': '{} (σ = {})'.format(\n",
    "            format_time(int(rmap[label['id']]['avg(duration)'])),\n",
    "            format_time(int(rmap[label['id']]['stddev_pop(duration)']), padding=0))\n",
    "    } for label in labels]\n",
    "\n",
    "video_ordering = ['label', 'count', 'duration', 'avg_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## All videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_df(\n",
    "    video_stats(None, [{'id': 0, 'name': 'whole dataset'}]),\n",
    "    video_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Videos by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    video_stats('channel_id', list(Channel.objects.all().values('id', 'name'))),\n",
    "    video_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Videos by show\n",
    "\"Situation Room with Wolf Blitzer\" and \"Special Report with Bret Baier\" were ingested as 60 10-minute segments each, whereas the other shows have 10 ≥1 hour segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    video_stats('show_id', list(Show.objects.all().values('id', 'name'))),\n",
    "    video_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Videos by time of day\n",
    "Initial selection of videos was only prime-time, so between 4pm-11pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    video_stats('hour', [{'id': hour, 'name': format_hour(hour)} for hour in hours]),\n",
    "    video_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_fields(qs, more_fields=[]):\n",
    "    return qs.annotate( \n",
    "            hour=Extract('video__time', 'hour'), \n",
    "            week_day=Extract('video__time', 'week_day'),\n",
    "            duration=Cast(\n",
    "                (F('max_frame') - F('min_frame')) / F('video__fps'),\n",
    "                models.FloatField())) \\\n",
    "        .values(*(['id', 'min_frame', 'max_frame', 'video__channel', 'video__show', 'duration', 'hour', \n",
    "                   'video_id', 'week_day', 'video__time'] + more_fields)) \\\n",
    "        .order_by('id')\n",
    "\n",
    "shot_labeler = Labeler.objects.get(name='shot-histogram')\n",
    "def load_shots():\n",
    "    return spark.qs_to_df(track_fields(Shot.objects.filter(labeler=shot_labeler)))\n",
    "shots = spark.load('shots', load_shots)\n",
    "\n",
    "commercial_labeler = Labeler.objects.get(name='haotian-commercials')\n",
    "def load_commercials():\n",
    "    return spark.qs_to_df(track_fields(Commercial.objects.filter(labeler=commercial_labeler)))\n",
    "commercials = spark.load('commercials', load_commercials)\n",
    "\n",
    "segment_labeler = Labeler.objects.get(name='haotian-segments')\n",
    "def load_segments():\n",
    "    return spark.qs_to_df(\n",
    "        track_fields(Segment.objects.filter(labeler=segment_labeler), ['polarity', 'subjectivity']))\n",
    "segments = spark.load('segments', load_segments)\n",
    "\n",
    "def match_segments(df):\n",
    "    with Timer('collect'):\n",
    "        fields = ['id', 'min_frame', 'max_frame', 'video_id']\n",
    "        shots_list = df.select(*fields).collect()\n",
    "        commercials_list = commercials.select(*fields).collect()\n",
    "        segments_list = segments.select(*fields).collect()\n",
    "\n",
    "    with Timer('group by key'):\n",
    "        grouped_shots = collect(shots_list, itemgetter('video_id'))\n",
    "        grouped_commercials = collect(commercials_list, itemgetter('video_id'))\n",
    "        grouped_segments = collect(segments_list, itemgetter('video_id'))\n",
    "\n",
    "    def inrange(a, b):\n",
    "        return b['min_frame'] <= a['min_frame'] and a['max_frame'] <= b['max_frame']\n",
    "\n",
    "    in_commercial_dict = {d['id']: False for d in tqdm(shots_list)}\n",
    "    segment_col = []\n",
    "    for video_id, vid_shots in tqdm(grouped_shots.iteritems()):\n",
    "        if video_id not in grouped_commercials: continue\n",
    "        vid_commercials = grouped_commercials[video_id]\n",
    "        vid_segments = grouped_segments[video_id]\n",
    "\n",
    "        for shot in vid_shots:\n",
    "            segment_id = None\n",
    "            for commercial in vid_commercials:\n",
    "                if inrange(shot, commercial):\n",
    "                    in_commercial_dict[shot['id']] = True\n",
    "                    break\n",
    "            for segment in vid_segments:\n",
    "                if inrange(shot, segment):\n",
    "                    segment_id = segment['id']\n",
    "                    break\n",
    "            segment_col.append([shot['id'], segment_id])\n",
    "\n",
    "    sorted_col = [[k, in_commercial_dict[k]] for k in tqdm(sorted(in_commercial_dict.keys()))]    \n",
    "    df1 = spark.append_column(df, 'in_commercial', sorted_col)\n",
    "    return spark.append_column(df1, 'segment_id', sorted(segment_col, key=itemgetter(0)))\n",
    "     \n",
    "def load_shots2():\n",
    "    return match_segments(shots)\n",
    "\n",
    "shots2 = spark.load('shots2', load_shots2)\n",
    "shots = shots2.where(shots2.in_commercial == False)\n",
    "shots_com = shots2.where(shots2.in_commercial == True)\n",
    "\n",
    "speaker_labeler, _ = Labeler.objects.get_or_create(name='lium')\n",
    "def load_speakers():\n",
    "    return spark.qs_to_df(track_fields(Speaker.objects.filter(labeler=speaker_labeler), ['gender_id']))\n",
    "speakers = spark.load('speakers', load_speakers)\n",
    "\n",
    "def load_speakers2():\n",
    "    return match_segments(speakers)\n",
    "speakers2 = spark.load('speakers2', load_speakers2)\n",
    "speakers2 = speakers2.where(speakers2.in_commercial == False)\n",
    "\n",
    "def load_faces():\n",
    "    return spark.qs_to_df(Face.objects \\\n",
    "        .annotate(height=F('bbox_y2') - F('bbox_y1')) \\\n",
    "        .filter(labeler=mtcnn) \\\n",
    "        .annotate(\n",
    "            duration=Cast(\n",
    "                (F('shot__max_frame') - F('shot__min_frame')) / F('shot__video__fps'),\n",
    "                models.FloatField()),\n",
    "            hour=Extract('person__frame__video__time', 'hour')) \\\n",
    "        .values('duration', 'person__frame__video__channel', 'person__frame__video__show', 'hour', 'shot', 'is_host'))\n",
    "\n",
    "faces = spark.load('faces', load_faces)\n",
    "faces_cols = faces.columns\n",
    "faces = faces.join(shots, faces.shot_id == shots.id).select(*[faces[k] for k in faces_cols])\n",
    "\n",
    "def filter_hosts():\n",
    "    with Timer('collect'):\n",
    "        fields = ['id', 'min_frame', 'max_frame', 'video_id']\n",
    "        speakers_list = speakers2.select(*fields).collect()\n",
    "        hosts = faces.where(faces.is_host == True)\n",
    "        shots_list = shots.join(hosts, shots.id == faces.shot_id, 'inner').select(*fields).collect()\n",
    "\n",
    "    with Timer('group by key'):\n",
    "        grouped_shots = collect(shots_list, itemgetter('video_id'))\n",
    "        grouped_speakers = collect(speakers_list, itemgetter('video_id'))\n",
    "\n",
    "    def inrange(a, b):\n",
    "        return b['min_frame'] <= a['min_frame'] and a['max_frame'] <= b['max_frame']\n",
    "\n",
    "    has_host_dict = {d['id']: False for d in tqdm(speakers_list)}\n",
    "    for video_id, vid_speakers in tqdm(list(grouped_speakers.iteritems())):\n",
    "        if video_id not in grouped_shots: continue\n",
    "        vid_shots = grouped_shots[video_id]\n",
    "\n",
    "        for speaker in vid_speakers:\n",
    "            for shot in vid_shots:\n",
    "                if inrange(speaker, shot):\n",
    "                    has_host_dict[speaker['id']] = True\n",
    "                    break\n",
    "\n",
    "    sorted_col = [[k, has_host_dict[k]] for k in tqdm(sorted(has_host_dict.keys()))]    \n",
    "    df1 = spark.append_column(speakers2, 'has_host', sorted_col)\n",
    "    return df1\n",
    "speakers = spark.load('speakers3', filter_hosts)\n",
    "\n",
    "def load_segment_links():\n",
    "    return spark.qs_to_df(\n",
    "        Segment.things.through.objects.filter(tvnews_segment__labeler=segment_labeler) \\\n",
    "        .values('id', 'tvnews_segment_id', 'tvnews_thing_id').order_by('id'))\n",
    "segment_links = spark.load('segment_links', load_segment_links).withColumnRenamed('tvnews_segment_id', 'segment_id') \\\n",
    "    .withColumnRenamed('tvnews_thing_id', 'thing_id')\n",
    "\n",
    "def load_things():\n",
    "    return spark.qs_to_df(Thing.objects.values('id', 'name', 'type').order_by('id'))\n",
    "things = spark.load('things', load_things)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_withcom = shots_com.approxQuantile('duration', [0.5], 0.01)[0]\n",
    "med_nocom = shots.approxQuantile('duration', [0.5], 0.01)[0]\n",
    "med_channels = {\n",
    "    c.name: shots.where(shots.channel_id == c.id).approxQuantile('duration', [0.5], 0.01)[0]\n",
    "    for c in Channel.objects.all()\n",
    "}\n",
    "pickle.dump({\n",
    "    'withcom': med_withcom,\n",
    "    'nocom': med_nocom,\n",
    "    'channels': med_channels\n",
    "}, open('/app/data/shot_medians.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shot_durations =  np.array([r['duration'] for r in shots.select('duration').collect()])\n",
    "hist, edges = np.histogram(all_shot_durations, bins=list(range(0, 3600)) + [10000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(hist, open('/app/data/shot_histogram.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# print(spark.median(shots.where(shots.channel_id == Channel.objects.get(name='FOXNEWS').id), 'duration'))\n",
    "# print(spark.median(shots.where(shots.channel_id == Channel.objects.get(name='CNN').id), 'duration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# import pylab\n",
    "# #scipy.stats.skewtest(np.log10(durations2))\n",
    "# scipy.stats.probplot(np.log10(durations2), dist=\"norm\", plot=pylab)\n",
    "# pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# def loaddur(df):\n",
    "#     durations = df.select('duration').collect()\n",
    "#     return [d.duration for d in tqdm(durations)]\n",
    "# durations2 = loaddur(shots)\n",
    "# #cnn_dur = loaddur(shots.where(shots.channel_id == Channel.objects.get(name='CNN').id))\n",
    "# #fox_dur = loaddur(shots.where(shots.channel_id == Channel.objects.get(name='FOXNEWS').id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# N = 3599\n",
    "\n",
    "# cnn_hist = np.histogram(durations2, bins=list(range(N)) + [3600])\n",
    "# #fox_hist = np.histogram(cnn_dur, bins=list(range(N)) + [3600])\n",
    "\n",
    "# plt.title('TV news shot duration histogram')\n",
    "# plt.xlabel('Shot length')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.gca().yaxis.grid(True)\n",
    "# plt.plot(list(range(N)), cnn_hist[0], 'r')\n",
    "# #plt.plot(list(range(N)), fox_hist[0], 'g')\n",
    "# plt.savefig('shot_duration_histogram_loglog.png', dpi=300)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Shot validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# From Sahaj\n",
    "shot_precision = 0.97\n",
    "shot_recall = 0.97  \n",
    "\n",
    "def shot_error_interval(n):\n",
    "    return [n * shot_precision, n * (2 - shot_recall)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_stats(key, labels, shots=shots):\n",
    "    if key is not None:\n",
    "        df = shots.groupBy(key)\n",
    "        rows = df.agg(shots[key], func.count('duration'), func.avg('duration'), func.sum('duration'), func.stddev_pop('duration')).collect()\n",
    "    else:\n",
    "        df = shots\n",
    "        rows = df.agg(func.count('duration'), func.avg('duration'), func.sum('duration'), func.stddev_pop('duration')).collect()\n",
    "    rmap = {(0 if key is None else r[key]): r for r in rows}\n",
    "    out_rows = []\n",
    "    for label in labels:\n",
    "        try:\n",
    "            out_rows.append({\n",
    "                'label': label['name'],\n",
    "                'count': format_number(shot_error_interval(rmap[label['id']]['count(duration)'])),\n",
    "                'duration': format_time(int(rmap[label['id']]['sum(duration)'])),\n",
    "                'avg_duration': '{:06.2f}s (σ = {:06.2f})'.format(\n",
    "                    rmap[label['id']]['avg(duration)'],\n",
    "                    rmap[label['id']]['stddev_pop(duration)'])\n",
    "            })\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return out_rows\n",
    "\n",
    "shot_ordering = ['label', 'count', 'duration', 'avg_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    shot_stats(None, [{'id': 0, 'name': 'whole dataset'}], shots=shots_com),\n",
    "    shot_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shots by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    shot_stats('channel_id', list(Channel.objects.all().values('id', 'name'))),\n",
    "    shot_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shots by show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    shot_stats('show_id', list(Show.objects.all().values('id', 'name'))),\n",
    "    shot_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shots by time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: multi hour videos are lumped into a single hour bin\n",
    "\n",
    "show_df(\n",
    "    shot_stats('hour', [{'id': hour, 'name': format_hour(hour)} for hour in hours]),\n",
    "    shot_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commercials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commercial_stats(key, labels):\n",
    "    if key is not None:\n",
    "        rows = commercials.groupBy(key).agg(commercials[key], func.count('duration'), func.avg('duration'), func.sum('duration')).collect()\n",
    "    else:\n",
    "        rows = commercials.agg(func.count('duration'), func.avg('duration'), func.sum('duration')).collect()\n",
    "    rmap = {(0 if key is None else r[key]): r for r in rows}\n",
    "    out_rows = []\n",
    "    for label in labels:\n",
    "        try:\n",
    "            out_rows.append({\n",
    "                'label': label['name'],\n",
    "                'count': format_number(rmap[label['id']]['count(duration)']),\n",
    "                'duration': format_time(int(rmap[label['id']]['sum(duration)'])),\n",
    "                'avg_duration': '{:06.2f}s'.format(rmap[label['id']]['avg(duration)'])\n",
    "            })\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return out_rows\n",
    "\n",
    "commercial_ordering = ['label', 'count', 'duration', 'avg_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All commercials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute avg # commercials per video\n",
    "show_df(\n",
    "    commercial_stats(None, [{'id': 0, 'name': 'whole dataset'}]),\n",
    "    commercial_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commercials by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    commercial_stats('channel_id', list(Channel.objects.all().values('id', 'name'))),\n",
    "    commercial_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commercials by show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_df(\n",
    "    commercial_stats('show_id', list(Show.objects.all().values('id', 'name'))),\n",
    "    commercial_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commercials by time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(\n",
    "    commercial_stats('hour', [{'id': hour, 'name': format_hour(hour)} for hour in hours]),\n",
    "    commercial_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_face_stats = face_validation('All faces', lambda x: x)\n",
    "big_face_stats = face_validation(\n",
    "    'Faces height > 0.2', lambda qs: qs.annotate(height=F('bbox_y2') - F('bbox_y1')).filter(height__gte=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_error_interval(n, face_stats):\n",
    "    (face_precision, face_recall) = face_stats\n",
    "    return [n * shot_precision * face_precision, n * (2 - shot_recall) * (2 - face_recall)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total faces: {}'.format(\n",
    "    format_number(face_error_interval(faces.count(), base_face_stats[2]))))\n",
    "\n",
    "total_duration = videos.agg(func.sum('duration')).collect()[0]['sum(duration)'] - \\\n",
    "    commercials.agg(func.sum('duration')).collect()[0]['sum(duration)']\n",
    "face_duration = faces.groupBy('shot_id') \\\n",
    "    .agg(func.first('duration').alias('duration')).agg(func.sum('duration')).collect()[0]['sum(duration)']\n",
    "print('% of time a face is on screen: {}'.format(100.0 * face_duration / total_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "# Gender\n",
    "These queries analyze the distribution of men vs. women across a number of axes. We use faces detected by [MTCNN](https://github.com/kpzhang93/MTCNN_face_detection_alignment/) and gender detected by [rude-carnie](https://github.com/dpressel/rude-carnie). We only consider faces with a height > 20% of the frame to eliminate people in the background.\n",
    "\n",
    "Time for a given gender is the amount of time during which at least one person of that gender was on screen. Percentages are (gender screen time) / (total time any person was on screen).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def load_genders():\n",
    "    return spark.qs_to_df(FaceGender.objects \\\n",
    "        .annotate(height=F('face__bbox_y2') - F('face__bbox_y1')) \\\n",
    "        .filter(labeler=rudecarnie, face__labeler=mtcnn) \\\n",
    "        .annotate(\n",
    "            duration=Cast(\n",
    "                (F('face__shot__max_frame') - F('face__shot__min_frame')) / F('face__shot__video__fps'),\n",
    "                models.FloatField()),\n",
    "            hour=Extract('face__person__frame__video__time', 'hour'),\n",
    "            week_day=Extract('face__person__frame__video__time', 'week_day')) \\\n",
    "        .values('gender', 'height', 'duration', 'face__person__frame__video__channel', 'face__person__frame__video__show', 'hour', 'face__shot', 'week_day', 'face__is_host'))\n",
    "\n",
    "genders = spark.load('genders', load_genders)\n",
    "genders = genders.where(genders.height > 0.2)\n",
    "genders_cols = genders.columns\n",
    "genders = genders.join(shots, genders.shot_id == shots.id).select(*([genders[k] for k in genders_cols] + [shots.segment_id, shots.video_id]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# gender_validation('All gender', base_face_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "_, Cm = gender_validation('Gender w/ face height > 0.2', big_face_stats)\n",
    "\n",
    "def P(y, yhat):\n",
    "    d = {'M': 0, 'F': 1, 'U': 2}\n",
    "    return float(Cm[d[y]][d[yhat]]) / sum([Cm[i][d[yhat]] for i in d.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P('M', 'U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove a host -- use face features to identify and remove rachel maddow from computation\n",
    "# TODO: more discrete time zones (\"sunday mornings\", \"prime time\", \"daytime\", \"late evening\")\n",
    "# TODO: by year\n",
    "# TODO: specific dates, e.g. during the RNC\n",
    "\n",
    "MALE = Gender.objects.get(name='M')\n",
    "FEMALE = Gender.objects.get(name='F')\n",
    "UNKNOWN = Gender.objects.get(name='U')\n",
    "gender_names = {g.id: g.name for g in Gender.objects.all()}\n",
    "\n",
    "def gender_singlecount_stats(key, labels, min_dur=None):\n",
    "    if key == 'topic':        \n",
    "        df1 = genders.join(segment_links, genders.segment_id == segment_links.segment_id)\n",
    "        df2 = df1.join(things, segment_links.thing_id == things.id)\n",
    "        topic_type = ThingType.objects.get(name='topic').id\n",
    "        df3 = df2.where(things.type_id == topic_type).select(\n",
    "            *(['duration', 'channel_id', 'show_id', 'hour', 'week_day', 'gender_id'] +  \\\n",
    "              [things.id.alias('topic'), 'shot_id']))\n",
    "        full_df = df3\n",
    "    else:\n",
    "        full_df = genders\n",
    "        \n",
    "    keys = ['duration', 'channel_id', 'show_id', 'hour', 'week_day']\n",
    "    aggs = [func.count('gender_id')] + [func.first(full_df[k]).alias(k) for k in keys] + \\\n",
    "        ([full_df.topic] if key == 'topic' else [])\n",
    "    groups = ([key] if key is not None else []) + ['gender_id']\n",
    "    counts = full_df.groupBy(*(['shot_id', 'gender_id'] + (['topic'] if key == 'topic' else []))).agg(*aggs)\n",
    "    rows = counts.where(counts['count(gender_id)'] > 0).groupBy(*groups) \\\n",
    "        .agg(func.sum('duration')).collect()\n",
    "\n",
    "    if key is not None:\n",
    "        base_counts = full_df.groupBy(['shot_id', key]).agg(full_df[key], func.first('duration').alias('duration')) \\\n",
    "            .groupBy(key).agg(full_df[key], func.sum('duration')).collect()\n",
    "    else:\n",
    "        base_counts = full_df.groupBy('shot_id').agg(func.first('duration').alias('duration')) \\\n",
    "            .agg(func.sum('duration')).collect()\n",
    "    base_map = {\n",
    "        (row[key] if key is not None else 0): row['sum(duration)']\n",
    "        for row in base_counts\n",
    "    }\n",
    "        \n",
    "    out_rows = []\n",
    "    for label in labels:\n",
    "        label_rows = {row.gender_id: row for row in rows if key is None or row[key] == label['id']}\n",
    "        if len(label_rows) < 3: \n",
    "            continue\n",
    "\n",
    "        base_dur = int(base_map[label['id']])\n",
    "        if min_dur != None and base_dur < min_dur:\n",
    "            continue\n",
    "            \n",
    "        durs = {\n",
    "            g.id: int(label_rows[g.id]['sum(duration)'])\n",
    "            for g in [MALE, FEMALE, UNKNOWN]\n",
    "        }       \n",
    "        \n",
    "        def adjust(g):\n",
    "            return int(reduce(lambda a, b: a + b, [durs[g2] * P(gender_names[g], gender_names[g2]) for g2 in durs]))\n",
    "        \n",
    "        adj_durs = {\n",
    "            g: adjust(g)\n",
    "            for g in durs\n",
    "        }\n",
    "            \n",
    "        out_rows.append({\n",
    "            key: label['name'],\n",
    "            'M': format_time(durs[MALE.id]),\n",
    "            'F': format_time(durs[FEMALE.id]),\n",
    "            'U': format_time(durs[UNKNOWN.id]),\n",
    "            'base': format_time(base_dur),\n",
    "            'M%': int(100.0 * durs[MALE.id] / base_dur),\n",
    "            'F%': int(100.0 * durs[FEMALE.id] / base_dur),\n",
    "            'U%': int(100.0 * durs[UNKNOWN.id] / base_dur),\n",
    "#             'M-Adj': format_time(adj_durs[MALE.id]),\n",
    "#             'F-Adj': format_time(adj_durs[FEMALE.id]),\n",
    "#             'U-Adj': format_time(adj_durs[UNKNOWN.id]),\n",
    "#             'M-Adj%': int(100.0 * adj_durs[MALE.id] / base_dur),\n",
    "#             'F-Adj%': int(100.0 * adj_durs[FEMALE.id] / base_dur),\n",
    "#             'U-Adj%': int(100.0 * adj_durs[UNKNOWN.id] / base_dur),\n",
    "            #'Overlap': int(100.0 * float(male_dur + female_dur) / base_dur) - 100\n",
    "        })\n",
    "    return out_rows\n",
    "gender_ordering = ['M', 'M%', 'F', 'F%', 'U', 'U%']\n",
    "#gender_ordering = ['M', 'M%', 'M-Adj', 'M-Adj%', 'F', 'F%', 'F-Adj', 'F-Adj%', 'U', 'U%', 'U-Adj', 'U-Adj%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_multicount_stats(key, labels, min_dur=None, no_host=False, just_host=False):\n",
    "    df0 = genders\n",
    "    if no_host:\n",
    "        df0 = df0.where(df0.is_host == False)        \n",
    "    if just_host:\n",
    "        df0 = df0.where(df0.is_host == True)\n",
    "        \n",
    "    if key == 'topic':        \n",
    "        df1 = df0.join(segment_links, df0.segment_id == segment_links.segment_id)\n",
    "        df2 = df1.join(things, segment_links.thing_id == things.id)\n",
    "        topic_type = ThingType.objects.get(name='topic').id\n",
    "        df3 = df2.where(things.type_id == topic_type).select(\n",
    "            *(['duration', 'channel_id', 'show_id', 'hour', 'week_day', 'gender_id'] +  \\\n",
    "              [things.id.alias('topic'), 'shot_id']))\n",
    "        full_df = df3\n",
    "    else:\n",
    "        full_df = df0\n",
    "        \n",
    "    groups = ([key] if key is not None else []) + ['gender_id']\n",
    "    rows = full_df.groupBy(*groups).agg(func.sum('duration')).collect()\n",
    "        \n",
    "    out_rows = []\n",
    "    for label in labels:\n",
    "        label_rows = {row.gender_id: row for row in rows if key is None or row[key] == label['id']}\n",
    "        if len(label_rows) < 3: continue\n",
    "        male_dur = int(label_rows[MALE.id]['sum(duration)'])\n",
    "        female_dur = int(label_rows[FEMALE.id]['sum(duration)'])\n",
    "        unknown_dur = int(label_rows[UNKNOWN.id]['sum(duration)'])\n",
    "        base_dur = male_dur + female_dur\n",
    "        if min_dur != None and base_dur < min_dur:\n",
    "            continue\n",
    "        out_rows.append({\n",
    "            key: label['name'],\n",
    "            'M': format_time(male_dur),\n",
    "            'F': format_time(female_dur),\n",
    "            'U': format_time(unknown_dur),\n",
    "            'base': format_time(base_dur),\n",
    "            'M%': int(100.0 * male_dur / base_dur),\n",
    "            'F%': int(100.0 * female_dur / base_dur),\n",
    "            'U%': int(100.0 * unknown_dur / (base_dur + unknown_dur)),\n",
    "            'Overlap': 0,\n",
    "        })\n",
    "    return out_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_speaker_stats(key, labels, min_dur=None, no_host=False):\n",
    "    keys = ['duration', 'channel_id', 'show_id', 'hour', 'week_day']\n",
    "    \n",
    "    df0 = speakers\n",
    "    if no_host:\n",
    "        df0 = df0.where(df0.has_host == False)\n",
    "\n",
    "    if key == 'topic':        \n",
    "        df1 = df0.join(segment_links, speakers.segment_id == segment_links.segment_id)\n",
    "        df2 = df1.join(things, segment_links.thing_id == things.id)\n",
    "        topic_type = ThingType.objects.get(name='topic').id\n",
    "        df3 = df2.where(things.type_id == topic_type).select(\n",
    "            *(keys + ['gender_id', things.id.alias('topic')]))\n",
    "        full_df = df3\n",
    "    else:\n",
    "        full_df = df0\n",
    "  \n",
    "    aggs = [func.count('gender_id')] + [func.first(full_df[k]).alias(k) for k in keys] + \\\n",
    "        ([full_df.topic] if key == 'topic' else [])\n",
    "    groups = ([key] if key is not None else []) + ['gender_id'] + (['topic'] if key == 'topic' else [])\n",
    "    rows = full_df.groupBy(*groups).agg(func.sum('duration')).collect()\n",
    "\n",
    "    if key is not None:\n",
    "        base_counts = full_df.groupBy(key).agg(full_df[key], func.sum('duration')).collect()\n",
    "    else:\n",
    "        base_counts = full_df.agg(func.sum('duration')).collect()\n",
    "        \n",
    "    base_map = {\n",
    "        (row[key] if key is not None else 0): row['sum(duration)']\n",
    "        for row in base_counts\n",
    "    }\n",
    "        \n",
    "    out_rows = []\n",
    "    for label in labels:\n",
    "        label_rows = {row.gender_id: row for row in rows if key is None or row[key] == label['id']}\n",
    "        if len(label_rows) < 2: continue\n",
    "        male_dur = int(label_rows[MALE.id]['sum(duration)'])\n",
    "        female_dur = int(label_rows[FEMALE.id]['sum(duration)'])\n",
    "        base_dur = int(base_map[label['id']])\n",
    "        if min_dur != None and base_dur < min_dur:\n",
    "            continue\n",
    "        out_rows.append({\n",
    "            key: label['name'],\n",
    "            'M': format_time(male_dur),\n",
    "            'F': format_time(female_dur),\n",
    "            'base': format_time(base_dur),\n",
    "            'M%': int(100.0 * male_dur / base_dur),\n",
    "            'F%': int(100.0 * female_dur / base_dur),\n",
    "        })\n",
    "    return out_rows\n",
    "\n",
    "gender_speaker_ordering = ['M', 'M%', 'F', 'F%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## All gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Singlecount')\n",
    "show_df(gender_singlecount_stats(None, [{'id': 0, 'name': 'whole dataset'}]), gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multicount')\n",
    "gender_screen_all = gender_multicount_stats(None, [{'id': 0, 'name': 'whole dataset'}])\n",
    "gender_screen_all_nh = gender_multicount_stats(None, [{'id': 0, 'name': 'whole dataset'}], no_host=True)\n",
    "show_df(gender_screen_all, gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(gender_screen_all_nh, gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Speaking time')\n",
    "gender_speaking_all = gender_speaker_stats(None, [{'id': 0, 'name': 'whole dataset'}])\n",
    "gender_speaking_all_nh = gender_speaker_stats(None, [{'id': 0, 'name': 'whole dataset'}], no_host=True)\n",
    "show_df(gender_speaking_all, gender_speaker_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(gender_speaking_all_nh, gender_speaker_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Gender by channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Singlecount')\n",
    "show_df(\n",
    "    gender_singlecount_stats('channel_id', list(Channel.objects.values('id', 'name'))),\n",
    "    ['channel_id'] + gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multicount')\n",
    "show_df(\n",
    "    gender_multicount_stats('channel_id', list(Channel.objects.values('id', 'name'))),\n",
    "    ['channel_id'] + gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Speaking time')\n",
    "show_df(\n",
    "    gender_speaker_stats('channel_id', list(Channel.objects.values('id', 'name'))),\n",
    "    ['channel_id'] + gender_speaker_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Gender by show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Singlecount')\n",
    "show_df(\n",
    "    gender_singlecount_stats('show_id', list(Show.objects.values('id', 'name')), min_dur=3600*500),\n",
    "    ['show_id'] + gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multicount')\n",
    "gender_screen_show = gender_multicount_stats('show_id', list(Show.objects.values('id', 'name')), min_dur=3600*250)\n",
    "gender_screen_show_nh = gender_multicount_stats('show_id', list(Show.objects.values('id', 'name')), min_dur=3600*250, no_host=True)\n",
    "gender_screen_show_jh = gender_multicount_stats('show_id', list(Show.objects.values('id', 'name')), min_dur=3600*50, just_host=True)\n",
    "show_df(gender_screen_show, ['show_id'] + gender_ordering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shots.show()\n",
    "gshow = genders.groupBy('video_id', 'gender_id').agg(func.sum('duration').alias('screen_sum'), func.first('show_id').alias('show_id'))\n",
    "gspeak = speakers.groupBy('video_id', 'gender_id').agg(func.sum('duration').alias('speak_sum'))\n",
    "rows = gshow.join(gspeak, ['video_id', 'gender_id']).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = Show.objects.get(name='Fox and Friends First')\n",
    "rows2 = rows[rows.show_id == show.id]\n",
    "videos = collect([r for _, r in rows2.iterrows()], lambda r: int(r.video_id))\n",
    "bs = []\n",
    "vkeys = []\n",
    "for vid, vrows in videos.iteritems():\n",
    "    vgender = {int(r.gender_id): r for r in vrows}\n",
    "    def balance(key):\n",
    "        return vgender[1][key] / float(vgender[1][key] + vgender[2][key])\n",
    "    try:\n",
    "        bs.append(balance('screen_sum') / balance('speak_sum'))\n",
    "    except KeyError:\n",
    "        bs.append(0)\n",
    "    vkeys.append(vid)\n",
    "idx = np.argsort(bs)[-20:]\n",
    "print(np.array(vkeys)[idx].tolist(), np.array(bs)[idx].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(videos[14087])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(gender_screen_show_nh, ['show_id'] + gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Speaking time')\n",
    "gender_speaking_show = gender_speaker_stats('show_id', list(Show.objects.values('id', 'name')), min_dur=3600*3)\n",
    "gender_speaking_show_nh = gender_speaker_stats('show_id', list(Show.objects.values('id', 'name')), min_dur=3600*3, no_host=True)\n",
    "show_df(    \n",
    "    gender_speaking_show,\n",
    "    ['show_id'] + gender_speaker_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df(    \n",
    "    gender_speaking_show_nh,\n",
    "    ['show_id'] + gender_speaker_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Gender by time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Singlecount')\n",
    "show_df(\n",
    "    gender_singlecount_stats('hour', [{'id': hour, 'name': format_hour(hour)} for hour in hours]),\n",
    "    ['hour'] + gender_ordering)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multicount')\n",
    "gender_screen_tod = gender_multicount_stats('hour', [{'id': hour, 'name': format_hour(hour)} for hour in hours])\n",
    "show_df(gender_screen_tod, ['hour'] + gender_ordering)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Speaking time')\n",
    "gender_speaking_tod = gender_speaker_stats('hour', [{'id': hour, 'name': format_hour(hour)} for hour in hours])\n",
    "show_df(gender_speaking_tod, ['hour'] + gender_speaker_ordering)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender by day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotw = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "print('Singlecount')\n",
    "show_df(\n",
    "    gender_singlecount_stats('week_day', [{'id': i+1, 'name': d} for i, d in enumerate(dotw)]),\n",
    "    ['week_day'] + gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multicount')\n",
    "show_df(\n",
    "    gender_multicount_stats('week_day', [{'id': i+1, 'name': d} for i, d in enumerate(dotw)]),\n",
    "    ['week_day'] + gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Speaking time')\n",
    "show_df(\n",
    "    gender_speaker_stats('week_day', [{'id': i+1, 'name': d} for i, d in enumerate(dotw)]),\n",
    "    ['week_day'] + gender_speaker_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Gender by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THOUGHTS:\n",
    "# - Try topic analysis just on a \"serious\" news show. \n",
    "# - Generate a panel from multiple clips, e.g. endless panel of people on a topic\n",
    "# - Produce an endless stream of men talking about, e.g. birth control\n",
    "\n",
    "print('Singlecount')\n",
    "show_df(\n",
    "    gender_singlecount_stats(\n",
    "        'topic', [{'id': t.id, 'name': t.name} for t in Thing.objects.filter(type__name='topic')],\n",
    "        min_dur=3600*5),\n",
    "    ['topic'] + gender_ordering)\n",
    "\n",
    "# check this \n",
    "# M% is the pecent of time that men are on screen when this topic is being discussed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multicount')\n",
    "gender_screen_topic = gender_multicount_stats(\n",
    "        'topic', [{'id': t.id, 'name': t.name} for t in Thing.objects.filter(type__name='topic')],\n",
    "        min_dur=3600*300)\n",
    "gender_screen_topic_nh = gender_multicount_stats(\n",
    "        'topic', [{'id': t.id, 'name': t.name} for t in Thing.objects.filter(type__name='topic')],\n",
    "        min_dur=3600*300, no_host=True)\n",
    "show_df(gender_screen_topic, ['topic'] + gender_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Speaking time')\n",
    "gender_speaking_topic = gender_speaker_stats(\n",
    "        'topic', [{'id': t.id, 'name': t.name} for t in Thing.objects.filter(type__name='topic')],\n",
    "        min_dur=3600*100)\n",
    "gender_speaking_topic_nh = gender_speaker_stats(\n",
    "        'topic', [{'id': t.id, 'name': t.name} for t in Thing.objects.filter(type__name='topic')],\n",
    "        min_dur=3600*100, no_host=True)\n",
    "show_df(gender_speaking_topic, ['topic'] + gender_speaker_ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "## Male vs. female faces in panels\n",
    "* Smaller percentage of women in panels relative to overall dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: female-domainated situations?\n",
    "# # TODO: slice this on # of people in the panel\n",
    "# # TODO: small visualization that shows sample of segments\n",
    "# # TODO: panels w/ majority male vs. majority female\n",
    "\n",
    "# print('Computing panels')\n",
    "# panels = queries.panels()\n",
    "# print('Computing gender stats')\n",
    "# frame_ids = [frame.id for (frame, _) in panels]\n",
    "# counts = filter_gender(lambda qs: qs.filter(face__person__frame__id__in=frame_ids), lambda qs: qs)\n",
    "# show_df([counts], ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "# Pose\n",
    "* Animatedness of people (specifically hosts)\n",
    "    * e.g. Rachel Maddow vs. others\n",
    "    * Pick 3-4 hours of a few specific hosts, compute dense poses and tracks\n",
    "    * Devise acceleration metric\n",
    "* More gesturing on heated exchanges?\n",
    "* Sitting vs. standing\n",
    "* Repeated gestures (debates vs. state of the union)\n",
    "* Head/eye orientation (are people looking at each other?)\n",
    "* Camera orientation (looking at someone from above/below)\n",
    "* How much are the hosts facing each other\n",
    "* Quantify aggressive body language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = segments.join(segment_links, segments.id == segment_links.segment_id)\n",
    "topics = topics.join(things, things.id == topics.thing_id)\n",
    "\n",
    "def topic_stats(group, labels, type_name, time=False):\n",
    "    ty = ThingType.objects.get(name=type_name)\n",
    "    topic_names = {t.id: t.name for t in Thing.objects.filter(type=ty)}\n",
    "    df = topics.where(topics.type_id == ty.id)\n",
    "\n",
    "    aggs = [func.sum('duration'), func.avg('polarity'), func.avg('subjectivity')]\n",
    "    if group is not None:\n",
    "        groups = ([func.year('time'), func.month('time')] if time else [])\n",
    "        rows = df.groupBy(['thing_id', group] + groups).agg(\n",
    "            *([func.first(group)] + ([func.min('time')] if time else []) + groups + aggs)).sort('thing_id').collect()\n",
    "\n",
    "        def row(r):\n",
    "            new_row = {\n",
    "                'duration': r['sum(duration)'],\n",
    "                'subjectivity': r['avg(subjectivity)'],\n",
    "                'polarity': r['avg(polarity)'],\n",
    "                'topic': topic_names[r['thing_id']],\n",
    "                group: labels[r[group]]\n",
    "            }\n",
    "            if time:\n",
    "                new_row['time'] = r['min(time)']\n",
    "            return new_row\n",
    "    \n",
    "\n",
    "        return pd.DataFrame([row(r) for r in rows])\n",
    "\n",
    "    else:\n",
    "        groups = [func.year('time'), func.month('time')] if time else []\n",
    "        rows = df.groupBy(['thing_id'] + groups).agg(\n",
    "            *(([func.min('time')] if time else []) + groups + aggs)).sort('thing_id').collect()\n",
    "        def row(r):\n",
    "            d =  {\n",
    "                'topic': topic_names[r.thing_id],\n",
    "                'duration': r['sum(duration)']\n",
    "            }\n",
    "            if time:\n",
    "                d['time'] = r['min(time)']\n",
    "            return d\n",
    "        return pd.DataFrame([row(r) for r in rows])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_all = topic_stats(None, None, 'topic', time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_all[topic_all.topic == 'conservatives'].sort_values(by=['time']).plot('time', 'duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = topic_stats('channel_id', {c.id: c.name for c in Channel.objects.all()}, 'topic')\n",
    "dfs['duration'].to_csv('/app/data/topic_channel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = topic_stats('channel_id', {c.id: c.name for c in Channel.objects.all()}, 'topic', time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#topics = dfs.topic.unique()\n",
    "topics = 'doctors, poverty, email, privacy, electricity, refugees, christmas, savings, volcanoes, wiretapping, shopping, anxiety, inauguration'.split(', ')\n",
    "def plt_topic(i, t):\n",
    "    figure = plt.figure()\n",
    "    ax = figure.add_subplot(1, 1, 1)\n",
    "    ax.set_title(t)\n",
    "    def plt_chan(c):\n",
    "        dfs2 = dfs[dfs.channel_id == c]\n",
    "        dfs2 = dfs2[dfs2.topic == t]\n",
    "        if len(dfs2) > 0:\n",
    "            dfs2.sort_values(by=['time']).plot('time', 'duration', ax=ax, label=c)\n",
    "    plt_chan('CNN')\n",
    "    plt_chan('FOXNEWS')    \n",
    "    plt_chan('MSNBC')\n",
    "    \n",
    "# doctors, poverty, email, privacy, electricity, refugees, christmas, savings, volcanoes, wiretapping, shopping\n",
    "# anxiety, inauguration\n",
    "    \n",
    "for i, t in tqdm(list(enumerate(topics))):\n",
    "    plt_topic(i+1, t)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = topic_stats('show_id', {c.id: c.name for c in Show.objects.all()}, 'topic')\n",
    "dfs['duration'].to_csv('/app/data/topic_show.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_all = pd.DataFrame(topic_stats(None, None, 'person'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = topic_stats('channel_id', {c.id: c.name for c in Channel.objects.all()}, 'person')\n",
    "dfs['duration'].to_csv('/app/data/person_channel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = topic_stats('show_id', {c.id: c.name for c in Show.objects.all()}, 'person')\n",
    "dfs['duration'].to_csv('/app/data/person_show.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = topic_stats('channel_id', {c.id: c.name for c in Channel.objects.all()}, 'phrase')\n",
    "dfs['duration'].to_csv('/app/data/phrase_channel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = topic_stats('show_id', {c.id: c.name for c in Show.objects.all()}, 'phrase')\n",
    "dfs['duration'].to_csv('/app/data/phrase_show.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(gender_screen_tod)\n",
    "ax = df.plot('hour', 'M%')\n",
    "pd.DataFrame(gender_speaking_tod).plot('hour', 'M%', ax=ax)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xticks(range(len(df)))\n",
    "ax.set_xticklabels(df.hour)\n",
    "ax.axhline(50, color='r', linestyle='--')\n",
    "ax.legend(['Screen time', 'Speaking time',  '50%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gender_screen_topic).to_csv('/app/data/screen_topic.csv')\n",
    "pd.DataFrame(gender_screen_topic_nh).to_csv('/app/data/screen_topic_nh.csv')\n",
    "pd.DataFrame(gender_speaking_topic).to_csv('/app/data/speaking_topic.csv')\n",
    "pd.DataFrame(gender_speaking_topic_nh).to_csv('/app/data/speaking_topic_nh.csv')\n",
    "\n",
    "pd.DataFrame(gender_screen_show).to_csv('/app/data/screen_show.csv')\n",
    "pd.DataFrame(gender_screen_show_nh).to_csv('/app/data/screen_show_nh.csv')\n",
    "pd.DataFrame(gender_screen_show_jh).to_csv('/app/data/screen_show_jh.csv')\n",
    "pd.DataFrame(gender_speaking_show).to_csv('/app/data/speaking_show.csv')\n",
    "pd.DataFrame(gender_speaking_show_nh).to_csv('/app/data/speaking_show_nh.csv')\n",
    "\n",
    "pd.DataFrame(gender_screen_all).to_csv('/app/data/screen_all.csv')\n",
    "pd.DataFrame(gender_screen_all_nh).to_csv('/app/data/screen_all_nh.csv')\n",
    "pd.DataFrame(gender_speaking_all).to_csv('/app/data/speaking_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "842px",
    "left": "0px",
    "right": "1464px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
