{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Querying-for-Interviews-with-Person-X\" data-toc-modified-id=\"Querying-for-Interviews-with-Person-X-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Querying for Interviews with Person X</a></span><ul class=\"toc-item\"><li><span><a href=\"#Interviews-with-Bernie-Sanders\" data-toc-modified-id=\"Interviews-with-Bernie-Sanders-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Interviews with Bernie Sanders</a></span></li><li><span><a href=\"#Interviews-with-Kellyanne-Conway-and-John-McCain\" data-toc-modified-id=\"Interviews-with-Kellyanne-Conway-and-John-McCain-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Interviews with Kellyanne Conway and John McCain</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:07:01.773397Z",
     "start_time": "2018-11-05T18:07:00.917863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports. Run this first!\n",
    "\n",
    "from query.models import LabeledInterview, LabeledPanel, LabeledCommercial, Video, FaceIdentity\n",
    "from esper.rekall import *\n",
    "from rekall.temporal_predicates import *\n",
    "from rekall.spatial_predicates import *\n",
    "from rekall.interval_list import IntervalList\n",
    "from esper.prelude import esper_widget\n",
    "#from esper.captions import topic_search\n",
    "from django.db.models import FloatField\n",
    "\n",
    "sandbox_videos = [529, 763, 2648, 3459, 3730, 3769, 3952, 4143, 4611, 5281, 6185, 7262, 8220,\n",
    "    8697, 8859, 9215, 9480, 9499, 9901, 10323, 10335, 11003, 11555, 11579, 11792,\n",
    "    12837, 13058, 13141, 13247, 13556, 13827, 13927, 13993, 14482, 15916, 16215,\n",
    "    16542, 16693, 16879, 17458, 17983, 19882, 19959, 20380, 20450, 23181, 23184,\n",
    "    24193, 24847, 24992, 25463, 26386, 27188, 27410, 29001, 31378, 32472, 32996,\n",
    "    33004, 33387, 33541, 33800, 34359, 34642, 36755, 37107, 37113, 37170, 38275,\n",
    "    38420, 40203, 40856, 41480, 41725, 42756, 45472, 45645, 45655, 45698, 48140,\n",
    "    49225, 49931, 50164, 50561, 51175, 52075, 52749, 52945, 53355, 53684, 54377,\n",
    "    55711, 57384, 57592, 57708, 57804, 57990, 59122, 59398, 60186]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying for Interviews with Person X\n",
    "\n",
    "We have an annotated sandbox of panels, interviews, and commercials (`query_labeledpanel`, `query_labeledinterview`, `query_commercial`). In this notebook we'll try to use write queries for these concepts and compare the results against our labels.\n",
    "\n",
    "A few notes about the panels:\n",
    "* Panel segments go from the introduction of panelists to the shot where the host says \"thank you\" or \"goodbye\" to the panelists. Sometimes the camera will cut wide and show all the panelists before a commercial break; such shots are *not* included in the labeled segments.\n",
    "* Panel segments are split up by commercials (i.e., if the same panel appears before and after a commercial break, that will be two panel segments).\n",
    "* Panels segments do not include segments where the host is just cutting to multiple reporters out in the field to cover some news story.\n",
    "\n",
    "A few notes about the interviews. See the third bullet point in particular.\n",
    "* Interview segments go from the first shot of the guest to where the host thanks the guest. Sometimes the host thanks the guest while the guest is on screen, and sometimes the host thanks the guest off-screen. In the former case, the segment continues until the guest is no longer on screen; in the latter case, the segment stops when the host changes the subject after thanking the guest.\n",
    "* Sometimes the host doesn't thank the guest; in this case, the segment ends when the guest is no longer on screen or when the host changes the subject.\n",
    "* **Interviews with analysts and correspondents from the same network are *not* included. This is to differentiate between the typical interview and \"interviews\" where the guest is just presenting a news segment.**\n",
    "* Interviews with reporters from the same network are also usually not included, *unless* the format of the interview is sufficiently different from the typical \"here's a reporter to tell you the news\" format. This is a judgment call on my (Dan Fu) part.\n",
    "\n",
    "This dataset also includes extra annotation of interviews with Kellyanne Conway, Bernie Sanders, and John McCain.\n",
    "* These interview segments include **any** segment where Kellyanne Conway, Bernie Sanders, or John McCain appear and are being interviewed. This includes segments during commercials or short clips where an interview of one of them is being played on another channel or show.\n",
    "* These segments also include clips where the guest appears for a few seconds as a \"preview\" before a commercial break.\n",
    "* Each of these segments is annotated with the name of the guest(s) and interviewer(s).\n",
    "\n",
    "A few notes about the commercials.\n",
    "* Commercial segments go from the beginning of the commercial break to the end of the commercial break. Sometimes networks will put in a segment from the network to let the viewers know that the commercial break is ending (think \"this is CNN, the must trusted name in news\" segment). Such segments are included in the commercial segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some statistics. Suppose we have a set of intervals `query` that represent our query, and a set of intervals `ground_truth` that represent our ground truth. We are interested in four statistics:\n",
    "* **precision**: This is your standard definition of precision, computed over the intervals: `sum(overlap(query, ground_truth)) / sum(query)`\n",
    "* **recall**: This is your standard definition of recall, computed over the intervals: `sum(overlap(query, ground_truth)) / sum(ground_truth)`\n",
    "* **precision_per_item**: We may also be interested in *how many* segments we hit. How many segments in `query` overlap with *any* segment in `ground_truth`? This is `sum(count(overlap(query, ground_truth))) / sum(count(query))`.\n",
    "* **recall_per_item**: Similar to precision_per_item. How many segments in `ground_truth` overlap with *any* segment in `query`? `sum(count(overlap(query, ground_truth))) / sum(count(ground_truth))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:08:36.891549Z",
     "start_time": "2018-11-05T18:08:36.837640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns precision, recall, precision_per_item, recall_per_item\n",
    "def compute_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    total_query_time = 0\n",
    "    total_query_segments = 0\n",
    "    total_ground_truth_time = 0\n",
    "    total_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        total_query_time += query_intrvllists[video].coalesce().get_total_time()\n",
    "        total_query_segments += query_intrvllists[video].size()\n",
    "    for video in ground_truth_intrvllists:\n",
    "        total_ground_truth_time += ground_truth_intrvllists[video].coalesce().get_total_time()\n",
    "        total_ground_truth_segments += ground_truth_intrvllists[video].size()\n",
    "        \n",
    "    total_overlap_time = 0\n",
    "    overlapping_query_segments = 0\n",
    "    overlapping_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        if video in ground_truth_intrvllists:\n",
    "            query_list = query_intrvllists[video]\n",
    "            gt_list = ground_truth_intrvllists[video]\n",
    "            \n",
    "            total_overlap_time += query_list.overlaps(gt_list).coalesce().get_total_time()\n",
    "            overlapping_query_segments += query_list.filter_against(gt_list, predicate=overlaps()).size()\n",
    "            overlapping_ground_truth_segments += gt_list.filter_against(query_list, predicate=overlaps()).size()\n",
    "    \n",
    "    if total_query_time == 0:\n",
    "        precision = 1.0\n",
    "        precision_per_item = 1.0\n",
    "    else:\n",
    "        precision = total_overlap_time / total_query_time\n",
    "        precision_per_item = overlapping_query_segments / total_query_segments\n",
    "    \n",
    "    if total_ground_truth_time == 0:\n",
    "        recall = 1.0\n",
    "        recall_per_item = 1.0\n",
    "    else:\n",
    "        recall = total_overlap_time / total_ground_truth_time\n",
    "        recall_per_item = overlapping_ground_truth_segments / total_ground_truth_segments\n",
    "    \n",
    "    return precision, recall, precision_per_item, recall_per_item\n",
    "\n",
    "def print_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    precision, recall, precision_per_item, recall_per_item = compute_statistics(\n",
    "        query_intrvllists, ground_truth_intrvllists)\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Precision Per Item: \", precision_per_item)\n",
    "    print(\"Recall Per Item: \", recall_per_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's just visualize all the labeled data. Interviews are in red, panels are in blue, and commercials are in purple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:08:41.664130Z",
     "start_time": "2018-11-05T18:08:38.905355Z"
    }
   },
   "outputs": [],
   "source": [
    "interviews = LabeledInterview.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end'))\n",
    "panels = LabeledPanel.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end'))\n",
    "commercials = LabeledCommercial.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end'))\n",
    "\n",
    "result = intrvllists_to_result(qs_to_intrvllists(interviews))\n",
    "add_intrvllists_to_result(result, qs_to_intrvllists(panels), color=\"blue\")\n",
    "add_intrvllists_to_result(result, qs_to_intrvllists(commercials), color=\"purple\")\n",
    "\n",
    "esper_widget(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interviews with Bernie Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:08:50.312516Z",
     "start_time": "2018-11-05T18:08:50.156770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's get all interviews of Bernie Sanders in our dataset and display it as black.\n",
    "# For this task, we won't display any interviews that weren't original appearances.\n",
    "\n",
    "bernie_interviews = LabeledInterview.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end')) \\\n",
    "        .filter(guest1=\"bernie sanders\")\n",
    "\n",
    "bernie_interviews_intrvllists = qs_to_intrvllists(bernie_interviews)\n",
    "bernie_interviews_original_intrvllists = qs_to_intrvllists(bernie_interviews.filter(original=True))\n",
    "\n",
    "# Hide result in a function for namespace reasons\n",
    "def get_result():\n",
    "    result = intrvllists_to_result(bernie_interviews_original_intrvllists, color='black')\n",
    "\n",
    "    return result\n",
    "\n",
    "esper_widget(get_result(), show_middle_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:08:54.839830Z",
     "start_time": "2018-11-05T18:08:54.808070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to get results with ground truth\n",
    "\n",
    "def result_with_ground_truth(intrvllists):\n",
    "    result = intrvllists_to_result(bernie_interviews_original_intrvllists, color='black')\n",
    "    add_intrvllists_to_result(result, intrvllists, color='red')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:53.890784Z",
     "start_time": "2018-11-05T18:13:34.901494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's query for Bernie Sanders interviews. This may take a while to materialize all the data.\n",
    "\n",
    "identities = FaceIdentity.objects.filter(face__shot__video_id__in=sandbox_videos)\n",
    "hosts = identities.filter(face__is_host=True)\n",
    "sanders = identities.filter(identity__name=\"bernie sanders\").filter(probability__gt=0.7)\n",
    "\n",
    "hosts_intrvllists = qs_to_intrvllists(hosts\n",
    "    .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "    .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "    .annotate(max_frame=F(\"face__shot__max_frame\")))\n",
    "sanders_intrvllists = qs_to_intrvllists(sanders\n",
    "    .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "    .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "    .annotate(max_frame=F(\"face__shot__max_frame\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.177915Z",
     "start_time": "2018-11-05T18:15:53.893391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get all shots with Bernie Sanders and a host\n",
    "sanders_with_host_intrvllists = {}\n",
    "for video in sanders_intrvllists:\n",
    "    if video in hosts_intrvllists:\n",
    "        sanders_with_host_intrvllists[video] = sanders_intrvllists[video].overlaps(hosts_intrvllists[video]).coalesce()\n",
    "\n",
    "print_statistics(sanders_with_host_intrvllists, bernie_interviews_original_intrvllists)\n",
    "\n",
    "esper_widget(result_with_ground_truth(sanders_with_host_intrvllists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T23:43:14.593160Z",
     "start_time": "2018-10-30T23:43:14.561056Z"
    }
   },
   "source": [
    "What do we get from those statistics? We are missing half the interviews, but we're hitting all of them. This tells us that part of our problem has to do with not coalescing well enough. We also have a problem where half our query segments do *not* hit an interview, so we need to cull some. Let's try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.362600Z",
     "start_time": "2018-11-05T18:15:54.181445Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We're going to look for the following patterns:\n",
    "    (Bernie Sanders + host) -> host OR\n",
    "    host -> (Bernie Sanders + host) OR\n",
    "    (Bernie Sanders + host) -> Bernie Sanders OR\n",
    "    Bernie Sanders -> (Bernie Sanders + host)\n",
    "\n",
    "We'll coalesce that, and then check in with the Esper widget again.\n",
    "'''\n",
    "sanders_interview_intrvllists = {}\n",
    "for video in sanders_with_host_intrvllists:\n",
    "    sanders_with_host = sanders_with_host_intrvllists[video]\n",
    "    hosts = hosts_intrvllists[video]\n",
    "    sanders = sanders_intrvllists[video]\n",
    "    \n",
    "    sanders_interview_intrvllists[video] = sanders_with_host.merge(\n",
    "        hosts, predicate=or_pred(before(max_dist=10), after(max_dist=10))).set_union(\n",
    "        sanders_with_host.merge(sanders, predicate=or_pred(before(max_dist=10), after(max_dist=10)))\n",
    "    ).coalesce()\n",
    "\n",
    "print_statistics(sanders_interview_intrvllists, bernie_interviews_original_intrvllists)\n",
    "\n",
    "esper_widget(result_with_ground_truth(sanders_interview_intrvllists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're much closer to getting all the interviews, but we still have some large gaps. Let's try to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.613085Z",
     "start_time": "2018-11-05T18:15:54.365505Z"
    }
   },
   "outputs": [],
   "source": [
    "investigation_result = intrvllists_to_result(bernie_interviews_original_intrvllists, color='black')\n",
    "add_intrvllists_to_result(investigation_result, sanders_with_host_intrvllists, color='orange')\n",
    "add_intrvllists_to_result(investigation_result, sanders_intrvllists, color='blue')\n",
    "add_intrvllists_to_result(investigation_result, sanders_interview_intrvllists, color='red')\n",
    "\n",
    "esper_widget(investigation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some gaps because of consecutive Bernie Sanders or host shots. Let's dilate and coalesce those and have another go at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.800421Z",
     "start_time": "2018-11-05T18:15:54.615645Z"
    }
   },
   "outputs": [],
   "source": [
    "sanders_interview_consec_intrvllists = {}\n",
    "for video in sanders_with_host_intrvllists:\n",
    "    sanders_with_host = sanders_with_host_intrvllists[video]\n",
    "    hosts = hosts_intrvllists[video].dilate(10).coalesce().dilate(-10)\n",
    "    sanders = sanders_intrvllists[video].dilate(10).coalesce().dilate(-10)\n",
    "    \n",
    "    sanders_interview_consec_intrvllists[video] = sanders_with_host.merge(\n",
    "        hosts, predicate=or_pred(or_pred(overlaps(), before(max_dist=10)), after(max_dist=10))).set_union(\n",
    "        sanders_with_host.merge(sanders, predicate=or_pred(or_pred(overlaps(), before(max_dist=10)), after(max_dist=10)))\n",
    "    ).coalesce()\n",
    "\n",
    "print_statistics(sanders_interview_consec_intrvllists, bernie_interviews_original_intrvllists)\n",
    "\n",
    "esper_widget(result_with_ground_truth(sanders_interview_consec_intrvllists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.914999Z",
     "start_time": "2018-11-05T18:15:54.803321Z"
    }
   },
   "outputs": [],
   "source": [
    "sanders_interview_filtered_intrvllists = {}\n",
    "for video in sanders_interview_intrvllists:\n",
    "    sanders_interview = sanders_interview_consec_intrvllists[video]\n",
    "    \n",
    "    sanders_interview_filtered_intrvllists[video] = sanders_interview \\\n",
    "        .dilate(600) \\\n",
    "        .coalesce() \\\n",
    "        .dilate(-600) \\\n",
    "        .filter_length(min_length=1350)\n",
    "\n",
    "print_statistics(sanders_interview_filtered_intrvllists, bernie_interviews_original_intrvllists)\n",
    "\n",
    "esper_widget(result_with_ground_truth(sanders_interview_filtered_intrvllists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good. We still have some false positives, but it's hard to get rid of those with what we have right now. Let's summarize what we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:56.286532Z",
     "start_time": "2018-11-05T18:15:54.917790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show multiple stages of our query process all in one timeline.\n",
    "summarize_bernie_result = intrvllists_to_result(bernie_interviews_original_intrvllists, color='black')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_with_host_intrvllists, color='orange')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_intrvllists, color='blue')\n",
    "add_intrvllists_to_result(summarize_bernie_result, hosts_intrvllists, color='purple')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_interview_intrvllists, color='green')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_interview_consec_intrvllists, color='brown')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_interview_filtered_intrvllists, color='red')\n",
    "\n",
    "esper_widget(summarize_bernie_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interviews with Kellyanne Conway and John McCain\n",
    "\n",
    "Now that we have a simple query for interviews with Bernie Sanders, let's do the same thing for Kellyanne Conway and John McCain, using our best method from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:56.362551Z",
     "start_time": "2018-11-05T18:15:56.289539Z"
    }
   },
   "outputs": [],
   "source": [
    "# ground truth for interviews where guest 1 is X\n",
    "def ground_truth_interviews_intrvllists(name, original=True):\n",
    "    interviews = LabeledInterview.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end')) \\\n",
    "        .filter(guest1=name)\n",
    "    if original:\n",
    "        interviews = interviews.filter(original=original)\n",
    "    return qs_to_intrvllists(interviews)\n",
    "\n",
    "# intrvllists for shots with a face with identity X\n",
    "def named_person_intrvllists(name):\n",
    "    person = identities.filter(identity__name=name).filter(probability__gt=0.7)\n",
    "    \n",
    "    return qs_to_intrvllists(person\n",
    "        .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "        .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "        .annotate(max_frame=F(\"face__shot__max_frame\")))\n",
    "\n",
    "# helper function to get hosts\n",
    "def host_intrvllists():\n",
    "    host = identities.filter(face__is_host=True)\n",
    "\n",
    "    return qs_to_intrvllists(hosts\n",
    "        .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "        .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "        .annotate(max_frame=F(\"face__shot__max_frame\")))\n",
    "\n",
    "# query for interviews of person X\n",
    "def interview_query(person_intrvllists, host_intrvllists):\n",
    "    interview_intrvllists = {}\n",
    "    for video in person_intrvllists:\n",
    "        if video not in host_intrvllists:\n",
    "            continue\n",
    "        person = person_intrvllists[video]\n",
    "        host = host_intrvllists[video]\n",
    "        person_with_host = person.overlaps(host).coalesce()\n",
    "        \n",
    "        overlaps_before_or_after_pred = or_pred(or_pred(\n",
    "            overlaps(), before(max_dist=10)), after(max_dist=10))\n",
    "        \n",
    "        interview_candidates = person_with_host \\\n",
    "            .merge(hosts, predicate=overlaps_before_or_after_pred) \\\n",
    "            .set_union(person_with_host.merge(\n",
    "                person, predicate=overlaps_before_or_after_pred)) \\\n",
    "            .coalesce()\n",
    "        \n",
    "        interviews_filtered = interview_candidates \\\n",
    "            .dilate(600) \\\n",
    "            .coalesce() \\\n",
    "            .dilate(-600) \\\n",
    "            .filter_length(min_length=1350)\n",
    "        \n",
    "        if interviews_filtered.size() > 0:\n",
    "            interview_intrvllists[video] = interviews_filtered\n",
    "    \n",
    "    return interview_intrvllists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:56.406676Z",
     "start_time": "2018-11-05T18:15:56.365740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to do all the above in one call\n",
    "\n",
    "def summarize_named_interview(name, original=True):\n",
    "    gt = ground_truth_interviews_intrvllists(name, original)\n",
    "    person = named_person_intrvllists(name)\n",
    "    person_interviews = interview_query(person, hosts_intrvllists)\n",
    "\n",
    "    print_statistics(person_interviews, gt)\n",
    "\n",
    "    summarize_result = intrvllists_to_result(gt, color='black')\n",
    "    add_intrvllists_to_result(summarize_result, person, color='blue')\n",
    "    add_intrvllists_to_result(summarize_result, hosts_intrvllists, color='purple')\n",
    "    add_intrvllists_to_result(summarize_result, person_interviews, color='red')\n",
    "\n",
    "    return summarize_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:16:23.480379Z",
     "start_time": "2018-11-05T18:15:56.409690Z"
    }
   },
   "outputs": [],
   "source": [
    "# This will take a while to materialize some of the data\n",
    "\n",
    "kellyanne_result = summarize_named_interview(\"kellyanne conway\")\n",
    "esper_widget(kellyanne_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:16:55.853296Z",
     "start_time": "2018-11-05T18:16:23.483193Z"
    }
   },
   "outputs": [],
   "source": [
    "# This will take a while to materialize some of the data\n",
    "\n",
    "mccain_result = summarize_named_interview(\"john mccain\")\n",
    "esper_widget(mccain_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in summary, the precision for Kellyanne Conway is pretty good (95%), but it's not as good for John McCain. The main reason is that there are very few interviews of John McCain, so any false positives (there is one) throw the precision numbers quite off. There's also a big false negative for John McCain - an interview with Jake Tapper that was played verbatim on CNN, but not on Jake Tapper's show. This false negative occurs because Jake Tapper's face wasn't registered as a host during that playtime."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
