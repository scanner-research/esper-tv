{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Choose-a-person\" data-toc-modified-id=\"Choose-a-person-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Choose a person</a></span></li><li><span><a href=\"#Get-starting-image-references\" data-toc-modified-id=\"Get-starting-image-references-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Get starting image references</a></span><ul class=\"toc-item\"><li><span><a href=\"#If-you-want-to-get-your-examples-from-Google-Image\" data-toc-modified-id=\"If-you-want-to-get-your-examples-from-Google-Image-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>If you want to get your examples from Google Image</a></span></li><li><span><a href=\"#If-you-want-to-get-images-from-list-of-image-urls\" data-toc-modified-id=\"If-you-want-to-get-images-from-list-of-image-urls-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>If you want to get images from list of image urls</a></span></li><li><span><a href=\"#If-you-want-to-provide-face-ids-from-Esper\" data-toc-modified-id=\"If-you-want-to-provide-face-ids-from-Esper-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>If you want to provide face ids from Esper</a></span></li><li><span><a href=\"#If-your-want-to-load-previously-labeled-model-and-dataset\" data-toc-modified-id=\"If-your-want-to-load-previously-labeled-model-and-dataset-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>If your want to load previously labeled model and dataset</a></span></li></ul></li><li><span><a href=\"#Your-initial-reference-images\" data-toc-modified-id=\"Your-initial-reference-images-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Your initial reference images</a></span></li><li><span><a href=\"#Now-we-will-build-a-training-set\" data-toc-modified-id=\"Now-we-will-build-a-training-set-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Now we will build a training set</a></span><ul class=\"toc-item\"><li><span><a href=\"#Getting-negative-examples-(via-sampling)\" data-toc-modified-id=\"Getting-negative-examples-(via-sampling)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Getting negative examples (via sampling)</a></span></li><li><span><a href=\"#Getting-positive-examples-(via-k-NN)\" data-toc-modified-id=\"Getting-positive-examples-(via-k-NN)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Getting positive examples (via k-NN)</a></span></li></ul></li><li><span><a href=\"#Training-a-Classifier\" data-toc-modified-id=\"Training-a-Classifier-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training a Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-and-obtaining-predictions-across-the-dataset\" data-toc-modified-id=\"Training-and-obtaining-predictions-across-the-dataset-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Training and obtaining predictions across the dataset</a></span></li><li><span><a href=\"#Visualize-predictions-and-label-new-examples\" data-toc-modified-id=\"Visualize-predictions-and-label-new-examples-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Visualize predictions and label new examples</a></span></li></ul></li><li><span><a href=\"#Saving-your-model\" data-toc-modified-id=\"Saving-your-model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Saving your model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Setup\n",
    "\n",
    "Before we begin, we need to load some dependencies and define some utility functions. \n",
    "\n",
    "<b>Run all initialization cells before proceeding.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:14:50.491306Z",
     "start_time": "2018-12-17T22:14:48.278092Z"
    },
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print('Loading libraries... Please wait.')\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(12, 5)\n",
    "import ipywidgets as widgets\n",
    "import itertools\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import PIL.Image\n",
    "import time\n",
    "import traceback\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request as request\n",
    "from sklearn import metrics\n",
    "from collections import namedtuple\n",
    "from subprocess import check_call\n",
    "\n",
    "from esper.prelude import *\n",
    "from esper.stdlib import *\n",
    "from esper.plot_util import tile_images\n",
    "from esper.major_canonical_shows import MAJOR_CANONICAL_SHOWS\n",
    "from esper import embed_google_images\n",
    "\n",
    "import esper.face_embeddings as face_embeddings\n",
    "\n",
    "FACES_PER_PAGE = 25\n",
    "\n",
    "MODEL_DIR = '/app/data/identity_models_v2'\n",
    "GCS_MODEL_DIR = 'gs://esper/tvnews/face_identity_model_v2'\n",
    "\n",
    "ReferenceFaces = namedtuple(\n",
    "    'ReferenceFaces', ['name', 'ids', 'embs', 'imgs'])\n",
    "\n",
    "def show_reference_imgs(refs):\n",
    "    tiled_imgs = tile_images(\n",
    "        [cv2.resize(x, (100, 100)) for x in refs.imgs], \n",
    "        cols=10, blank_value=255)\n",
    "    print('Your reference images for {}.'.format(refs.name))\n",
    "    plt.figure()\n",
    "    imshow(tiled_imgs)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def split_list(l, idx):\n",
    "    return l[:idx], l[idx:]\n",
    "\n",
    "def query_faces(ids):\n",
    "    faces = Face.objects.filter(id__in=ids)\n",
    "    return faces.values(\n",
    "        'id', 'bbox_y1', 'bbox_y2', 'bbox_x1', 'bbox_x2',\n",
    "        'frame__number', 'frame__video__id', 'frame__video__fps',\n",
    "        'shot__min_frame', 'shot__max_frame')\n",
    "\n",
    "def query_sample(qs, n):\n",
    "    return qs.order_by('?')[:n]\n",
    "\n",
    "def query_faces_result(faces, expand_bbox=0.05):\n",
    "    \"\"\"Replaces qs_to_result\"\"\"\n",
    "    result = []\n",
    "    for face in faces:\n",
    "        if (face.get('shot__min_frame') is not None and \n",
    "                face.get('shot__max_frame') is not None):\n",
    "            min_frame = int(\n",
    "                (face['shot__min_frame'] + \n",
    "                 face['shot__max_frame']) / 2)\n",
    "        else:\n",
    "            min_frame = face['frame__number']\n",
    "        face_result = {\n",
    "            'type': 'flat', 'label': '', \n",
    "            'elements': [{\n",
    "                'objects': [{\n",
    "                    'id': face['id'],\n",
    "                    'background': False,\n",
    "                    'type': 'bbox',\n",
    "                    'bbox_y1': max(face['bbox_y1'] - expand_bbox, 0),\n",
    "                    'bbox_y2': min(face['bbox_y2'] + expand_bbox, 1),\n",
    "                    'bbox_x1': max(face['bbox_x1'] - expand_bbox, 0),\n",
    "                    'bbox_x2': min(face['bbox_x2'] + expand_bbox, 1),\n",
    "                }], \n",
    "                'min_frame': min_frame,\n",
    "                'video': face['frame__video__id']\n",
    "            }]\n",
    "        }\n",
    "        result.append(face_result)\n",
    "    return {'type': 'Face', 'count': 0, 'result': result}\n",
    "\n",
    "def load_face_img(face):\n",
    "    return crop(load_frame(face.frame.video, face.frame.number, []), face)\n",
    "\n",
    "def sort_ids_by_distance(ids, embs):\n",
    "    dists = face_embeddings.dist(ids, targets=embs)\n",
    "    return [i for _, i in sorted(zip(dists, ids))]\n",
    "\n",
    "def sort_faces_by_distance(faces, embs, ascending=False):\n",
    "    ids = [f['id'] for f in faces]\n",
    "    id_to_dist = {\n",
    "        k: v for k, v in zip(ids, face_embeddings.dist(ids, targets=embs))\n",
    "    }\n",
    "    order_const = 1 if ascending else -1\n",
    "    faces.sort(key=lambda x: order_const * id_to_dist[x['id']])\n",
    "    return faces\n",
    "\n",
    "def video_ids_with_mentions(phrase):\n",
    "    from esper.captions import phrase_search\n",
    "    # lazy import\n",
    "    result = phrase_search(phrase)\n",
    "    return {d.id for d in result.documents}\n",
    "\n",
    "def continue_yn_prompt(msg):\n",
    "    l = input('{} Continue? (y/N): '.format(msg))\n",
    "    if l.strip().lower() != 'y':\n",
    "        raise ValueError('User entered No. This is not an error.') \n",
    "        \n",
    "def bsearch_gte(l, target, key=lambda x: x):\n",
    "    \"\"\"Find first index greater than or equal to target\"\"\"\n",
    "    assert len(l) > 0\n",
    "    i = 0\n",
    "    j = len(l)\n",
    "    for k in range(math.ceil(math.log(len(l) + 1, 2)) + 1):\n",
    "        if i == j:\n",
    "            return i\n",
    "        pivot = int((i + j) / 2)\n",
    "        pivot_value = key(l[pivot])\n",
    "        if pivot == 0:\n",
    "            if pivot_value >= target:\n",
    "                return 0\n",
    "            assert len(l) == 1\n",
    "            return 1\n",
    "        prev_value = key(l[pivot - 1])\n",
    "        assert pivot_value >= prev_value, 'list is not sorted'\n",
    "        if target > prev_value and target <= pivot_value:\n",
    "            return pivot\n",
    "        elif target <= prev_value:\n",
    "            j = pivot - 1\n",
    "        else: # target > pivot_value:\n",
    "            i = pivot + 1\n",
    "    assert False, 'Unreachable code. Loop executed {} times'.format(k + 1)\n",
    "\n",
    "def confirm_selected_faces(face_ids):        \n",
    "    submit_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Confirm selection',\n",
    "        disabled=False,\n",
    "        button_style='danger',\n",
    "        tooltip='Submit labels'\n",
    "    )\n",
    "    \n",
    "    example_faces = query_faces(sorted(face_ids))\n",
    "    example_selection_widget = esper_widget(\n",
    "        query_faces_result(example_faces), results_per_page=FACES_PER_PAGE,\n",
    "        crop_bboxes=True, jupyter_keybindings=True\n",
    "    )\n",
    "    \n",
    "    def on_submit(b):\n",
    "        ignored_example_face_idxs = set(example_selection_widget.ignored)\n",
    "        example_selection_widget.close()\n",
    "        clear_output()\n",
    "\n",
    "        ids = {\n",
    "            f['id'] for i, f in enumerate(example_faces) \n",
    "            if i not in ignored_example_face_idxs\n",
    "        }\n",
    "        print('You deselected {} and accepted {} faces.'.format(\n",
    "              len(ignored_example_face_idxs), len(ids)))\n",
    "        \n",
    "        imgs = par_for(load_face_img, Face.objects.filter(id__in=face_ids))\n",
    "        embs = [x for _, x in face_embeddings.get(face_ids)]\n",
    "        global face_references\n",
    "        face_references = ReferenceFaces(name=name, ids=ids, imgs=imgs, embs=embs)\n",
    "    \n",
    "    submit_button.on_click(on_submit)\n",
    "    \n",
    "    display(widgets.HBox([widgets.Label('Controls:'), submit_button]))\n",
    "    display(example_selection_widget)\n",
    "    \n",
    "def load_model_and_examples(path=None):\n",
    "    if path is None: \n",
    "        path = os.path.join(MODEL_DIR, '{}.pkl'.format(name.lower().replace(' ', '_')))\n",
    "    print('Loading model: {}'.format(path))\n",
    "    with open(path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    assert model['name'] == name, 'Model name does not match {} != {}'.format(model['name'], name)\n",
    "    \n",
    "    embs = model['init_embs']\n",
    "    ids = set(model['init_ids'])\n",
    "    imgs = model['init_imgs']\n",
    "    weights = model['weights']\n",
    "    \n",
    "    references = ReferenceFaces(\n",
    "        name=model['name'], ids=ids, imgs=imgs, embs=embs)\n",
    "    pos_examples = set(model['pos_examples'])\n",
    "    neg_examples = set(model['neg_examples'])\n",
    "    print('Done! Loaded {} reference faces; {} positive and {} negative examples'.format(\n",
    "          len(embs), len(pos_examples), len(neg_examples)))\n",
    "    return references, pos_examples, neg_examples, weights\n",
    "\n",
    "def save_model_and_examples(path=None, save_to_gcs=True):\n",
    "    underscore_name = face_references.name.lower().replace(' ', '_')\n",
    "    \n",
    "    if path is None: \n",
    "        if not os.path.exists(MODEL_DIR):\n",
    "            os.makedirs(MODEL_DIR)\n",
    "        path = os.path.join(MODEL_DIR, '{}.pkl'.format(underscore_name))\n",
    "    print('Saving model: {}'.format(path))\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        continue_yn_prompt('Existing file will be overwritten')\n",
    "    with open(path, 'wb') as f:\n",
    "        model = {\n",
    "            'name': face_references.name,\n",
    "            'init_embs': face_references.embs,\n",
    "            'init_ids': face_references.ids,\n",
    "            'init_imgs': face_references.imgs,\n",
    "            'pos_examples': pos_examples,\n",
    "            'neg_examples': neg_examples,\n",
    "            'weights': weights\n",
    "        }\n",
    "        pickle.dump(model, f)\n",
    "        if save_to_gcs:\n",
    "            gcs_path = os.path.join(GCS_MODEL_DIR, '{}.pkl'.format(underscore_name))\n",
    "            print('Saving model to GCS: {}'.format(gcs_path))\n",
    "            check_call(['gsutil', 'cp', f.name, gcs_path])\n",
    "    print('Done!')\n",
    "\n",
    "def load_and_select_faces_from_images(img_dir):\n",
    "    \n",
    "    def crop_img(img, bbox):\n",
    "        height, width, _ = img.shape\n",
    "        y1 = int(bbox.y1 * height)\n",
    "        y2 = int(bbox.y2 * height)\n",
    "        x1 = int(bbox.x1 * width)\n",
    "        x2 = int(bbox.x2 * width)\n",
    "        return img[y1:y2, x1:x2, :]\n",
    "    \n",
    "    face_bboxes = embed_google_images.detect_faces(img_dir)\n",
    "    \n",
    "    cand_imgs = []\n",
    "    for img_path, bbox in face_bboxes:\n",
    "        img = cv2.imread(img_path)\n",
    "        img_crop = crop_img(img, bbox)\n",
    "        assert img_crop.size > 0, \\\n",
    "            'Bad crop dimensions: {} from {}'.format(\n",
    "            img_crop.shape, bbox)\n",
    "        img_crop = cv2.resize(img_crop, (100, 100))\n",
    "        cand_imgs.append(img_crop)\n",
    "    \n",
    "    def img_to_widget(img):\n",
    "        height, width, _ = img.shape\n",
    "        f = io.BytesIO()\n",
    "        PIL.Image.fromarray(img).save(f, 'png')\n",
    "        return widgets.Image(value=f.getvalue(), height=height,\n",
    "                             width=width)\n",
    "    \n",
    "    def get_img_checkbox():\n",
    "        img_checkbox = widgets.ToggleButton(\n",
    "            layout=widgets.Layout(width='auto'),\n",
    "            value=True,\n",
    "            description='',\n",
    "            disabled=False,\n",
    "            button_style='danger',\n",
    "            icon='check'\n",
    "        )\n",
    "        def on_toggle(b):\n",
    "            if img_checkbox.value:\n",
    "                img_checkbox.button_style = 'danger'\n",
    "                img_checkbox.icon = 'check'\n",
    "            else:\n",
    "                img_checkbox.button_style = ''\n",
    "                img_checkbox.icon = ''\n",
    "        img_checkbox.observe(on_toggle, names='value')\n",
    "        return img_checkbox\n",
    "    \n",
    "    print('Select reference images below: (default=selected)')\n",
    "    checkboxes = []\n",
    "    vboxes = []\n",
    "    for img_crop in cand_imgs:\n",
    "        img_widget = img_to_widget(\n",
    "            cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB))\n",
    "        img_checkbox = get_img_checkbox()\n",
    "        checkboxes.append(img_checkbox)\n",
    "        vboxes.append(widgets.VBox([img_widget, img_checkbox]))\n",
    "    \n",
    "    images_per_row = 8\n",
    "    for i in range(0, len(vboxes), images_per_row):\n",
    "        display(widgets.HBox(vboxes[i:i + images_per_row]))\n",
    "        \n",
    "    submit_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Confirm selections',\n",
    "        disabled=False,\n",
    "        button_style='danger'\n",
    "    )\n",
    "    def on_submit(b):\n",
    "        imgs = [\n",
    "            x for i, x in enumerate(cand_imgs) \n",
    "            if checkboxes[i].value]\n",
    "        clear_output()\n",
    "        print('Selected {} faces. Ignored {}.'.format(\n",
    "              len(imgs), len(cand_imgs) - len(imgs)))\n",
    "        embs = embed_google_images.embed_images(imgs)\n",
    "        assert len(imgs) == len(embs)\n",
    "        global face_references\n",
    "        face_references = ReferenceFaces(\n",
    "            name=name, ids=set(), embs=embs, imgs=imgs)\n",
    "    submit_button.on_click(on_submit)\n",
    "    \n",
    "    cancel_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Abort selection',\n",
    "        disabled=False,\n",
    "        button_style='warning'\n",
    "    )\n",
    "    def on_cancel(b):\n",
    "        clear_output()\n",
    "        print('Canceled selection. No references images were added.')\n",
    "    cancel_button.on_click(on_cancel)\n",
    "    \n",
    "    display(widgets.HBox([widgets.Label('Controls:'), \n",
    "            submit_button, cancel_button]))\n",
    "    return cand_imgs\n",
    "\n",
    "def get_google_images(name, **kwargs):\n",
    "    img_dir = embed_google_images.fetch_images(name, force='query_extras' in kwargs, \n",
    "                                               **kwargs)\n",
    "    load_and_select_faces_from_images(img_dir)\n",
    "    \n",
    "def get_image_urls(urls):\n",
    "    tmp_dir = tempfile.mkdtemp('img_download')\n",
    "    try:\n",
    "        for i, url in enumerate(urls):\n",
    "            tokens = url.split('.')\n",
    "            if len(tokens) > 1:\n",
    "                ext = tokens[-1]\n",
    "            else:\n",
    "                ext = 'png'\n",
    "            img_path = os.path.join(tmp_dir, '{}.{}'.format(i, ext))\n",
    "            request.urlretrieve(url, img_path)\n",
    "        load_and_select_faces_from_images(tmp_dir)\n",
    "    finally:\n",
    "        if os.path.exists(tmp_dir):\n",
    "            shutil.rmtree(tmp_dir)\n",
    "\n",
    "def get_negative_samples(face_references, k=None):\n",
    "    start_time = time.time()\n",
    "    neg_samples = list(set(face_embeddings.sample(k)))\n",
    "    \n",
    "    submit_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Confirm selections',\n",
    "        disabled=False,\n",
    "        button_style='danger',\n",
    "    )\n",
    "\n",
    "    neg_samples_ord = sort_ids_by_distance(\n",
    "        neg_samples, face_references.embs\n",
    "    )\n",
    "    neg_samples_ord_idxs = {\n",
    "        b: a for a, b in enumerate(neg_samples_ord)\n",
    "    }\n",
    "    \n",
    "    dist_time = time.time()\n",
    "    print('Computed distances: {:0.4f}s'.format(dist_time - start_time))\n",
    "    \n",
    "    neg_samples_faces = list(query_faces(neg_samples_ord))\n",
    "    neg_samples_faces.sort(key=lambda f: neg_samples_ord_idxs[f['id']])\n",
    "    neg_samples_id_set = {f['id'] for f in neg_samples_faces}\n",
    "    neg_samples = list(filter(\n",
    "        lambda x: x in neg_samples_id_set, neg_samples_ord))\n",
    "    print('DB query finished: {:0.4f}s'.format(time.time() - start_time))\n",
    "    \n",
    "    selection_widget = esper_widget(\n",
    "        query_faces_result(neg_samples_faces), results_per_page=FACES_PER_PAGE,\n",
    "        crop_bboxes=True, jupyter_keybindings=True, disable_playback=True\n",
    "    )\n",
    "    \n",
    "    def on_submit(b):\n",
    "        # Read from the widget, update selections, and commit result\n",
    "        ignored_idxs = set(selection_widget.ignored)\n",
    "        selected_idxs = set(selection_widget.selected)\n",
    "        selection_widget.close()\n",
    "        clear_output() \n",
    "        \n",
    "        # Add to positive set\n",
    "        for i in selected_idxs:\n",
    "            face_id = neg_samples_ord[i]\n",
    "            if face_id not in face_references.ids:\n",
    "                _id, emb = face_embeddings.get([face_id])[0]\n",
    "                assert _id == face_id\n",
    "                face_references.ids.add(face_id)\n",
    "                face_references.embs.append(emb)\n",
    "            pos_examples.add(face_id)\n",
    "\n",
    "        # Filter negative set\n",
    "        neg_samples = [\n",
    "            _id for _, _id in filter(\n",
    "                lambda x: x[0] not in ignored_idxs and x[0] not in selected_idxs,\n",
    "                enumerate(neg_samples_ord))\n",
    "        ]\n",
    "        \n",
    "        print('You selected {} and ignored {} faces.'.format(\n",
    "              len(selected_idxs), len(ignored_idxs)))\n",
    "        \n",
    "        global neg_examples\n",
    "        neg_examples |= set(neg_samples)\n",
    "        print('Added {} negative samples and {} examples of {}. There are now a total of {} negative examples.'.format(\n",
    "              len(neg_samples), len(selected_idxs), face_references.name, len(neg_examples)))\n",
    "    submit_button.on_click(on_submit)     \n",
    "   \n",
    "    display(widgets.HBox([widgets.Label('Controls:'), submit_button]))\n",
    "    print('You should select all faces that are {}.'.format(face_references.name))\n",
    "    display(selection_widget)\n",
    "    \n",
    "def get_positive_examples(face_references, k):\n",
    "    submit_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Confirm selections',\n",
    "        disabled=False,\n",
    "        button_style='danger'\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Order by increasing distance, excluding already selected\n",
    "    pos_samples_and_dists = list(filter(\n",
    "        lambda x: x[0] not in pos_examples, \n",
    "        face_embeddings.knn(\n",
    "            targets=face_references.embs, \n",
    "            k=len(pos_examples) + k, max_threshold=1.)\n",
    "    ))\n",
    "    pos_samples_to_idx = {\n",
    "        f[0]: i for i, f in enumerate(pos_samples_and_dists)\n",
    "    }\n",
    "    knn_time = time.time()\n",
    "    print('Comuputed k-NN: {:0.4f}s'.format(knn_time - start_time))\n",
    "    \n",
    "    pos_samples_faces = list(query_faces(\n",
    "        [x[0] for x in pos_samples_and_dists]))\n",
    "    pos_samples_faces.sort(key=lambda f: pos_samples_to_idx[f['id']])\n",
    "    for p in pos_samples_faces:\n",
    "        _, p['dist'] = pos_samples_and_dists[pos_samples_to_idx[p['id']]]\n",
    "    print('DB query finished: {:0.4f}s'.format(time.time() - knn_time))\n",
    "    \n",
    "    selection_widget = esper_widget(\n",
    "        query_faces_result(pos_samples_faces), results_per_page=FACES_PER_PAGE,\n",
    "        crop_bboxes=True, jupyter_keybindings=True, disable_playback=True\n",
    "    )\n",
    "\n",
    "    def on_submit(b):\n",
    "        selected_idxs = selection_widget.selected\n",
    "        ignored_idxs = set(selection_widget.ignored)\n",
    "        max_selected_idx = (\n",
    "            max(selected_idxs)\n",
    "            if len(selected_idxs) > 0 else len(pos_samples_faces))\n",
    "        clear_output()\n",
    "        \n",
    "        pos_samples = {\n",
    "            x['id'] for i, x in enumerate(pos_samples_faces[:max_selected_idx])\n",
    "            if i not in ignored_idxs\n",
    "        }\n",
    "        \n",
    "        global pos_examples\n",
    "        pos_examples |= set(pos_samples)\n",
    "        print('Added {} examples of {}. There are now {} positive examples.'.format(\n",
    "              len(pos_samples), face_references.name, len(pos_examples)))      \n",
    "    submit_button.on_click(on_submit)\n",
    "    \n",
    "    display(widgets.HBox([widgets.Label('Controls:'), submit_button]))\n",
    "    print('All images before and including your highest selection will be chosen.')\n",
    "    display(selection_widget)\n",
    "\n",
    "def load_female_face_ids():\n",
    "    FEMALE_FACE_IDS_CACHE = '/tmp/female_face_ids.pkl'\n",
    "    if os.path.exists(FEMALE_FACE_IDS_CACHE):\n",
    "        with open(FEMALE_FACE_IDS_CACHE, 'rb') as f:\n",
    "            ids = pickle.load(f)\n",
    "    else:\n",
    "        ids = {\n",
    "            f['face__id'] for f in FaceGender.objects.filter(\n",
    "                gender__name='F', face__frame__video__threeyears_dataset=True\n",
    "            ).values('face__id')\n",
    "        }\n",
    "        with open(FEMALE_FACE_IDS_CACHE, 'wb') as f:\n",
    "            pickle.dump(ids, f)\n",
    "    return ids\n",
    "\n",
    "_female_face_ids = None\n",
    "def is_female_face_id(face_id):\n",
    "    global _female_face_ids\n",
    "    if _female_face_ids is None:\n",
    "        _female_face_ids = load_female_face_ids()\n",
    "    return face_id in _female_face_ids\n",
    "\n",
    "print('Done loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Choose a person\n",
    "\n",
    "Please select a person for whom you would like to build a model for. \n",
    "\n",
    "<b>Running the cell below will display a prompt.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T21:57:07.189730Z",
     "start_time": "2018-12-17T21:56:53.661147Z"
    }
   },
   "outputs": [],
   "source": [
    "name = input('Enter a name: ').strip()\n",
    "assert name != '', 'Name cannot be the empty string'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get starting image references\n",
    "\n",
    "In order to train a binary model to identify a person, we need to find some initial visual examples of the target person. We will use these initial example images to build a training set to train the model.\n",
    "\n",
    "We have provided four options for how to obtain these starting images:\n",
    " - Google Image Search\n",
    " - images from list of URLs\n",
    " - face ids from Esper\n",
    " - existing model on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to get your examples from Google Image\n",
    "\n",
    "The following code fetches images using Google Image Search. You will be asked to select, from the faces in the results, which faces are your target person.\n",
    "\n",
    "<b>Click on the checkbox area to toggle an image. Hit the confirm button when done.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T21:58:23.298795Z",
     "start_time": "2018-12-17T21:57:53.262164Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_google_images(name)\n",
    "# If the images returned are not satisfactory, rerun the above with extra params:\n",
    "#     query_extras='' # additional keywords to add to search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to get images from list of image urls\n",
    "\n",
    "Specify a list of URLs for images. Ideally, the images should be PNG or JPG.\n",
    "\n",
    "<b>Click on the checkbox area to toggle an image. Hit the confirm button when done.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T10:17:47.633365Z",
     "start_time": "2018-12-13T10:17:47.306978Z"
    }
   },
   "outputs": [],
   "source": [
    "face_urls = ['http://www.gstatic.com/tv/thumb/persons/1805/1805_v9_bb.jpg'] # LIST OF URLS HERE\n",
    "get_image_urls(face_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to provide face ids from Esper\n",
    "\n",
    "If you already know a set of Esper face identifiers corresponding to the target person, then you can specify an initial set of face idenitifiers below. Running `confirm_selected_faces()` afterwards will display the faces in an interactive widget. \n",
    "\n",
    "<b>You can ignore an image by pressing the '\\]' key while hovering.</b> \n",
    "\n",
    "Any faces not marked as \"ignore\" will be selected. <b>Hit the confirm button when done.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T09:30:17.995781Z",
     "start_time": "2018-12-13T09:30:17.886643Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "face_ids = [] # LIST OF IDS HERE\n",
    "confirm_selected_faces(face_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## If your want to load previously labeled model and dataset\n",
    "\n",
    "If you have previously saved a model for the target person, you can load reference images and the coresponeding dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T21:59:03.959794Z",
     "start_time": "2018-12-17T21:59:03.771939Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "face_references, pos_examples, neg_examples, weights = load_model_and_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Your initial reference images\n",
    "\n",
    "You can always view your initial set of reference images by running `show_reference_imgs()`. This can come in handy if you are unsure if a face is the target or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T21:59:10.054790Z",
     "start_time": "2018-12-17T21:59:09.537511Z"
    }
   },
   "outputs": [],
   "source": [
    "if face_references is None: \n",
    "    raise ValueError('Missing initial reference images')\n",
    "show_reference_imgs(face_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will build a training set\n",
    "\n",
    "Hooray! We have our initial reference images. However, these are still too few to train a model. This section will rectify that by constructing a dataset of sufficient diversity and size to begin training.\n",
    "\n",
    "Note: if the variables `neg_examples` and `pos_examples` are already defined, then you will be asked whether to reinitialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T21:59:12.396101Z",
     "start_time": "2018-12-17T21:59:12.368163Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    neg_examples\n",
    "    continue_yn_prompt('neg_examples will be overwritten')\n",
    "    neg_examples = set()\n",
    "except NameError: \n",
    "    neg_examples = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T21:59:12.819037Z",
     "start_time": "2018-12-17T21:59:12.789450Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pos_examples\n",
    "    continue_yn_prompt('pos_examples will be overwritten')\n",
    "    pos_examples = set(face_references.ids)\n",
    "except NameError: \n",
    "    pos_examples = set(face_references.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Getting negative examples (via sampling)\n",
    "\n",
    "We will obtain negative examples by randomly sampling the dataset. You will also be presented with the opportunity to clean these sampled faces. \n",
    "\n",
    "<b>Cleaning:</b> Faces on TV news do not receive equal screen time. Political figures such as Donald Trump and Hillary Clinton can comprise up to 2% of the total faces in the dataset. This is sufficient to appear when performing negative sampling. `get_negative_samples()` allows you to select these faces that are the target person, remove them from the negative samples, and add them them to positive examples set. \n",
    "\n",
    "<b>To select a single face, hover and press '\\['; to select an entire page of faces, press '\\{' (i.e. 'shift + ['). \n",
    "\n",
    "Hit the \"confirm selections\" button when done.</b>\n",
    "\n",
    "You can rerun `get_negative_samples()` as many times as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T21:59:58.015113Z",
     "start_time": "2018-12-17T21:59:15.483137Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_negative_samples(face_references, k=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting positive examples (via k-NN)\n",
    "\n",
    "To obtain an initial set of positive examples, we use the reference images that you selected earlier and find the k-nearest neighbors in the dataset. `get_positive_examples()` will sample these face ids and load a widget to confirm these positive examples.\n",
    "\n",
    "The goal is to select a clean set of positive examples. The widget will display faces in order of ascending distance from the reference images. \n",
    "\n",
    "<b>All images past your highest index selection (hover and press '\\[') will be discarded. If no selections are made, then all of the faces are accepted. Hit the confirm button when done.</b>\n",
    "\n",
    "You can rerun `get_positive_examples()` as many times as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:00:34.106852Z",
     "start_time": "2018-12-17T21:59:58.018089Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_positive_examples(face_references, k=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Training a Classifier\n",
    "\n",
    "This section will train a model based on examples that you selected previously. Before proceeding, make sure that you have run the negative sampling cell above and generated a set of initial positive examples If you have not, then the following cell with throw a ValueError telling you to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:14:53.953169Z",
     "start_time": "2018-12-17T22:14:50.496382Z"
    },
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "POS_LABEL = 1\n",
    "NEG_LABEL = 0\n",
    "\n",
    "####\n",
    "# DEBUG PLOTS\n",
    "####\n",
    "\n",
    "def plot_roc(y_true, y_pred, title='Receiver Operating Characteristic'):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_binary_score_histograms(y_true, y_pred, y_max=None, \n",
    "                                 title='Score Distribution by Class'):\n",
    "    bins = np.linspace(0, 1, 100)\n",
    "    plt.figure()\n",
    "    plt.hist([x for i, x in enumerate(y_pred) if y_true[i] == POS_LABEL], \n",
    "             bins, alpha=0.5, label=face_references.name)\n",
    "    plt.hist([x for i, x in enumerate(y_pred) if y_true[i] == NEG_LABEL], \n",
    "             bins, alpha=0.5, label='Not {}'.format(face_references.name))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Score')\n",
    "    if y_max is not None: \n",
    "        plt.ylim(0, y_max)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_score_histogram(predictions, sample, x_min=None):\n",
    "    bins = np.linspace(0, 1, 100)\n",
    "    plt.figure()\n",
    "    sampled_pred = (\n",
    "        random.sample(predictions, sample) \n",
    "        if sample < len(predictions) else predictions\n",
    "    )\n",
    "    plt.hist([s for _, s in sampled_pred], bins, alpha=1)\n",
    "    plt.title('Predicted Score Distribution (sample={})'.format(\n",
    "              min(sample, len(predictions))))\n",
    "    plt.xlabel('Predicted Score')\n",
    "    if x_min is not None:\n",
    "        plt.xlim(left=x_min)\n",
    "    plt.xticks(np.arange(11) / 10)\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_estimated_cdf(predictions, sample, x_min=None):\n",
    "    n_bins = 100\n",
    "    def score_to_bin(s):\n",
    "        v = math.ceil(s * n_bins)\n",
    "        return min(v, n_bins)\n",
    "    bins = np.zeros(n_bins + 1)\n",
    "    sampled_pred = (\n",
    "        random.sample(predictions, sample) \n",
    "        if sample < len(predictions) else predictions\n",
    "    )\n",
    "    for _, s in sampled_pred:\n",
    "        bins[score_to_bin(s)] += s\n",
    "\n",
    "    sample_est_pos = np.sum(bins)\n",
    "    total_est_pos = int(sample_est_pos / sample * len(predictions))\n",
    "    \n",
    "    norm_bins = bins / sample_est_pos\n",
    "    cdf_bins = np.cumsum(norm_bins)\n",
    "    inds = np.arange(bins.size) / n_bins\n",
    "    plt.figure()\n",
    "    plt.title('CDF of Positive Predictions ' +\n",
    "              '(total estimated positives={})'.format(\n",
    "              total_est_pos))\n",
    "    plt.plot(inds, cdf_bins, label='Est. Cumulative Proportion')\n",
    "    plt.plot(inds, norm_bins, label='Est. Bin Proportion ({} bins)'.format(n_bins))\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xlabel('Predicted Score')\n",
    "    plt.ylim(bottom=0)\n",
    "    if x_min is not None:\n",
    "        plt.xlim(left=x_min)\n",
    "    plt.xticks(np.arange(11) / 10)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print('Est. Positives by Threshold')\n",
    "    total_est_bins = bins / sample * len(predictions)\n",
    "    total_est_cdf_thresh = np.cumsum(total_est_bins[::-1])\n",
    "    num_thesh = 10\n",
    "    for i in range(num_thesh):\n",
    "        t = 1. - 0.1 * (i + 1)\n",
    "        print('  t={:0.1f}\\t{:0.1f}'.format(\n",
    "              t, total_est_cdf_thresh[num_thesh * (i + 1) - 1]))\n",
    "\n",
    "####\n",
    "# MODEL TRAINING\n",
    "####\n",
    "    \n",
    "def train_model(params, train_val_ratio=10):\n",
    "    print('Training logistic classifier with {}:1 train to validation split'.format(\n",
    "          train_val_ratio))\n",
    "    \n",
    "    print('Hyperparameters')\n",
    "    print('  Epochs:', params['num_epochs'])\n",
    "    print('  Learning rate:', params['learning_rate'])\n",
    "    print('  L2 penalty:', params['l2_penalty'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pos_examples_copy = list(pos_examples)\n",
    "    random.shuffle(pos_examples_copy)\n",
    "    pos_split_idx = int(len(pos_examples_copy) / train_val_ratio)\n",
    "    val_pos, train_pos = split_list(pos_examples_copy, pos_split_idx)\n",
    "    \n",
    "    neg_examples_copy = list(neg_examples)\n",
    "    random.shuffle(neg_examples_copy)\n",
    "    neg_split_idx = int(len(neg_examples_copy) / train_val_ratio)\n",
    "    val_neg, train_neg = split_list(neg_examples_copy, neg_split_idx)\n",
    "    \n",
    "    train_ids = train_pos + train_neg\n",
    "    train_y = ([POS_LABEL] * len(train_pos)) + ([NEG_LABEL] * len(train_neg))\n",
    "    \n",
    "    val_ids = val_pos + val_neg\n",
    "    val_y = ([POS_LABEL] * len(val_pos)) + ([NEG_LABEL] * len(val_neg))\n",
    "    \n",
    "    weights, predictions = face_embeddings.logreg(\n",
    "        train_ids, train_y, 0, 1, **params)\n",
    "    \n",
    "    model_time = time.time()\n",
    "    print('Trained model and obtained predictions: {:0.4f}s'.format(model_time - start_time))\n",
    "    \n",
    "    train_id_to_idx = {v: i for i, v in enumerate(train_ids)}\n",
    "    train_pred_y = [0] * len(train_ids)\n",
    "    val_id_to_idx = {v: i for i, v in enumerate(val_ids)}\n",
    "    val_pred_y = [0] * len(val_ids)\n",
    "    \n",
    "    for v, s in predictions:\n",
    "        if v in train_id_to_idx:\n",
    "            train_pred_y[train_id_to_idx[v]] = s\n",
    "        if v in val_id_to_idx:\n",
    "            val_pred_y[val_id_to_idx[v]] = s\n",
    "            \n",
    "    num_tabs = 3\n",
    "    outputs = [widgets.Output() for _ in range(num_tabs)]\n",
    "    tabs = widgets.Tab(children=outputs)\n",
    "    \n",
    "    with outputs[0]:\n",
    "        tabs.set_title(0, 'Entire Dataset')\n",
    "        plot_score_histogram(predictions, sample=100000)\n",
    "        print('If we interpret the scores produced by the model as probabilities, '\n",
    "              'we can estimate the number of true positives that we expect to find '\n",
    "              'in the dataset. The following plot makes this assumption and shows '\n",
    "              'the expected contribution of faces of varying scores to the total.')\n",
    "        plot_estimated_cdf(predictions, sample=100000)\n",
    "        \n",
    "    with outputs[1]:\n",
    "        tabs.set_title(1, 'Training Set')\n",
    "        plot_roc(train_y, train_pred_y)\n",
    "        plot_binary_score_histograms(train_y, train_pred_y)\n",
    "        \n",
    "    with outputs[2]:\n",
    "        tabs.set_title(2, 'Validation Set')\n",
    "        plot_roc(val_y, val_pred_y)\n",
    "        plot_binary_score_histograms(val_y, val_pred_y)\n",
    "    \n",
    "    print('Generate debugging plots: {:0.4f}s'.format(time.time() - model_time))\n",
    "    display(tabs)\n",
    "    return weights, predictions\n",
    "\n",
    "####\n",
    "# VISUALIZATION CONTROLS\n",
    "####\n",
    "\n",
    "STYLE_ARGS = {'description_width': 'initial'}\n",
    "\n",
    "GENDER_OPTIONS = {\n",
    "    'disabled': 0,\n",
    "    'male': 1,\n",
    "    'female': 2,\n",
    "}\n",
    "\n",
    "MAX_HEIGHT = 1.\n",
    "MIN_HEIGHT = 0.\n",
    "\n",
    "MAX_SHARPNESS = 1000.\n",
    "MIN_SHARPNESS = 0.\n",
    "\n",
    "def display_filter_controls():\n",
    "    \n",
    "    sample_size_text = widgets.BoundedIntText(\n",
    "        style=STYLE_ARGS,\n",
    "        value=100,\n",
    "        min=1,\n",
    "        max=10000,\n",
    "        description='Sample size:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    hide_already_labeled_checkbox = widgets.Checkbox(\n",
    "        style=STYLE_ARGS,\n",
    "        value=True,\n",
    "        description='Hide already labeled examples',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    sample_sort_button = widgets.ToggleButtons(\n",
    "        style=STYLE_ARGS,\n",
    "        options=['random', 'descending distance', 'ascending distance'],\n",
    "        value='descending distance',\n",
    "        description='Sample sort:',\n",
    "        disabled=False,\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "\n",
    "    score_range_slider = widgets.FloatRangeSlider(\n",
    "        layout=widgets.Layout(width='100%'),\n",
    "        style=STYLE_ARGS,\n",
    "        value=[0.45, 0.55],\n",
    "        min=0,\n",
    "        max=1,\n",
    "        step=0.05,\n",
    "        description='Predicted scores:',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='.2f',\n",
    "    )\n",
    "\n",
    "    commercial_filter_button = widgets.ToggleButtons(\n",
    "        style=STYLE_ARGS,\n",
    "        options=['disabled', 'select', 'exclude'],\n",
    "        value='disabled',\n",
    "        description='Commercial filter:',\n",
    "        disabled=False,\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "    \n",
    "    gender_filter_button = widgets.ToggleButtons(\n",
    "        style=STYLE_ARGS,\n",
    "        options=['disabled', 'male', 'female'],\n",
    "        value='disabled',\n",
    "        description='Gender filter:',\n",
    "        disabled=False,\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "\n",
    "    face_height_slider = widgets.FloatRangeSlider(\n",
    "        layout=widgets.Layout(width='100%'),\n",
    "        style=STYLE_ARGS,\n",
    "        value=[MIN_HEIGHT, MAX_HEIGHT],\n",
    "        min=0,\n",
    "        max=1,\n",
    "        step=0.01,\n",
    "        description='Face height (proportion):',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='.2f',\n",
    "    )\n",
    "    \n",
    "    face_sharpness_slider = widgets.FloatRangeSlider(\n",
    "        layout=widgets.Layout(width='100%'),\n",
    "        style=STYLE_ARGS,\n",
    "        value=[MIN_SHARPNESS, MAX_SHARPNESS],\n",
    "        min=MIN_SHARPNESS,\n",
    "        max=MAX_SHARPNESS,\n",
    "        step=0.5,\n",
    "        description='Face sharpness:',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='.1f',\n",
    "    )\n",
    "\n",
    "    caption_filter_button = widgets.ToggleButtons(\n",
    "        style=STYLE_ARGS,\n",
    "        options=['disabled', 'mentioned', 'not mentioned'],\n",
    "        value='disabled',\n",
    "        description='Captions filter:',\n",
    "        disabled=False,\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "\n",
    "    caption_filter_text = widgets.Text(\n",
    "        layout=widgets.Layout(width='100%'),\n",
    "        style=STYLE_ARGS,\n",
    "        value=face_references.name,\n",
    "        placeholder='Type something...',\n",
    "        description='Caption phrases (separated by commas):',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    channel_filter_button = widgets.ToggleButtons(\n",
    "        style=STYLE_ARGS,\n",
    "        options=['disabled', 'CNN', 'FOXNEWS', 'MSNBC'],\n",
    "        value='disabled',\n",
    "        description='Channel filter:',\n",
    "        disabled=False,\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "\n",
    "    canonical_show_dropdown = widgets.Dropdown(\n",
    "        layout=widgets.Layout(width='100%'),\n",
    "        style=STYLE_ARGS,\n",
    "        options=['All'] + list(sorted(MAJOR_CANONICAL_SHOWS)),\n",
    "        value='All',\n",
    "        description='Show filter:',\n",
    "        disabled=False,\n",
    "    )\n",
    "    \n",
    "    global slice_widgets\n",
    "    slice_widgets = {\n",
    "        'sample_size_text': sample_size_text,\n",
    "        'hide_already_labeled_checkbox': hide_already_labeled_checkbox,\n",
    "        'sample_sort_button': sample_sort_button,\n",
    "        'score_range_slider': score_range_slider,\n",
    "        'commercial_filter_button': commercial_filter_button,\n",
    "        'gender_filter_button': gender_filter_button,\n",
    "        'channel_filter_button': channel_filter_button,\n",
    "        'canonical_show_dropdown': canonical_show_dropdown,\n",
    "        'face_height_slider': face_height_slider,\n",
    "        'face_sharpness_slider': face_sharpness_slider,\n",
    "        'caption_filter_button': caption_filter_button,\n",
    "        'caption_filter_text': caption_filter_text\n",
    "    }\n",
    "    \n",
    "    display(widgets.HBox([sample_size_text, hide_already_labeled_checkbox]))\n",
    "    display(sample_sort_button)\n",
    "    display(score_range_slider)\n",
    "    display(commercial_filter_button)\n",
    "    display(gender_filter_button)\n",
    "    display(channel_filter_button)\n",
    "    display(canonical_show_dropdown)\n",
    "    display(face_height_slider)\n",
    "    display(face_sharpness_slider)\n",
    "    display(caption_filter_button)\n",
    "    display(caption_filter_text)\n",
    "    \n",
    "def get_slice_args():\n",
    "    global slice_widgets\n",
    "    score_range = slice_widgets['score_range_slider'].value\n",
    "    height_range = slice_widgets['face_height_slider'].value\n",
    "    sharpness_range = slice_widgets['face_sharpness_slider'].value\n",
    "    try:\n",
    "        custom_filter_fn\n",
    "    except NameError:\n",
    "        custom_filter_fn = None\n",
    "    return {\n",
    "        'hide_already_labeled': slice_widgets['hide_already_labeled_checkbox'].value,\n",
    "        'sample_size': slice_widgets['sample_size_text'].value,\n",
    "        'sample_sort': slice_widgets['sample_sort_button'].value,\n",
    "        'score_range': score_range,\n",
    "        'commercial_filter': slice_widgets['commercial_filter_button'].value,\n",
    "        'gender_filter': slice_widgets['gender_filter_button'].value,\n",
    "        'height_range': height_range,\n",
    "        'sharpness_range': sharpness_range,\n",
    "        'caption_filter': slice_widgets['caption_filter_button'].value,\n",
    "        'caption_text': [t.strip() for t in slice_widgets['caption_filter_text'].value.split(',')],\n",
    "        'channel': slice_widgets['channel_filter_button'].value,\n",
    "        'canonical_show': slice_widgets['canonical_show_dropdown'].value,\n",
    "        'custom_filter_fn': custom_filter_fn\n",
    "    }\n",
    "\n",
    "MAX_DJANGO_QUERY_IDS = 250000\n",
    "def django_query_filter_fn(qs, slice_args):\n",
    "    if slice_args['commercial_filter'] != 'disabled':\n",
    "        qs = qs.filter(\n",
    "            shot__in_commercial=slice_args['commercial_filter'] == 'select')\n",
    "\n",
    "    min_height, max_height = slice_args['height_range']\n",
    "    if min_height > MIN_HEIGHT or max_height < MAX_HEIGHT:\n",
    "        qs = qs.annotate(height=BoundingBox.height_expr())\n",
    "        min_height = min_height\n",
    "        if min_height > MIN_HEIGHT:\n",
    "            qs = qs.filter(height__gte=min_height)\n",
    "        max_height = max_height\n",
    "        if max_height < MAX_HEIGHT:\n",
    "            qs = qs.filter(height__lte=max_height)\n",
    "\n",
    "    min_sharpness, max_sharpness = slice_args['sharpness_range']\n",
    "    if min_sharpness > MIN_SHARPNESS:\n",
    "        qs = qs.filter(blurriness__gte=min_sharpness)\n",
    "    if max_sharpness < MAX_SHARPNESS:\n",
    "        qs = qs.filter(blurriness__lte=max_sharpness)\n",
    "\n",
    "    if slice_args['channel'] != 'disabled':\n",
    "        qs = qs.filter(\n",
    "            frame__video__channel__name=slice_args['channel'])\n",
    "        \n",
    "    if slice_args['canonical_show'] != 'All':\n",
    "        qs = qs.filter(\n",
    "            frame__video__show__canonical_show__name=slice_args['canonical_show'])\n",
    "\n",
    "    if slice_args['caption_filter'] != 'disabled':\n",
    "        video_ids = set()\n",
    "        for phrase in slice_args['caption_text']:\n",
    "            video_ids |= video_ids_with_mentions(phrase)\n",
    "            video_ids |= video_ids_with_mentions(phrase.upper())\n",
    "        if slice_args['caption_filter'] == 'mentioned':\n",
    "            qs = qs.filter(frame__video__id__in=video_ids)\n",
    "        else:\n",
    "            qs = qs.exclude(frame__video__id__in=video_ids)\n",
    "\n",
    "    # Execute custom Esper query\n",
    "    if slice_args['custom_filter_fn'] is not None:\n",
    "        try:\n",
    "            qs = slice_args['custom_filter_fn'](qs)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "    return qs\n",
    "\n",
    "def gender_filter_fn(gender_filter, face_id):\n",
    "    if gender_filter == 1:    # Male \n",
    "        return not is_female_face_id(face_id)\n",
    "    elif gender_filter == 2:  # Female\n",
    "        return is_female_face_id(face_id)\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "####\n",
    "# SLICE SELECTION WIDGET\n",
    "####\n",
    "\n",
    "def visualize():\n",
    "    print('Loading widget...')\n",
    "    \n",
    "    slice_args = get_slice_args()\n",
    "    \n",
    "    submit_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Confirm selections',\n",
    "        disabled=False,\n",
    "        button_style='danger'\n",
    "    )\n",
    "    \n",
    "    refresh_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Refresh (w/o confirming)',\n",
    "        disabled=False,\n",
    "        button_style='',\n",
    "    )\n",
    "    \n",
    "    dismiss_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Dismiss widget',\n",
    "        disabled=False,\n",
    "        button_style=''\n",
    "    )\n",
    "    \n",
    "    labeled_ids_set = pos_examples | neg_examples\n",
    "    \n",
    "    gender_filter = GENDER_OPTIONS[slice_args['gender_filter']]\n",
    "    hide_already_labeled = slice_args['hide_already_labeled']\n",
    "    def pre_query_filter_fn(face_id_and_score):\n",
    "        face_id, _ = face_id_and_score\n",
    "        if hide_already_labeled and face_id in labeled_ids_set:\n",
    "            return False\n",
    "        return gender_filter_fn(gender_filter, face_id)\n",
    "    \n",
    "    pre_filter_start = time.time()\n",
    "    min_score, max_score = slice_args['score_range']\n",
    "    score_min_idx = bsearch_gte(predictions, min_score, key=lambda x: x[1])\n",
    "    score_max_idx = bsearch_gte(predictions, max_score, key=lambda x: x[1])\n",
    "    filtered_pred = list(\n",
    "        filter(pre_query_filter_fn, \n",
    "               itertools.islice(predictions, score_min_idx, score_max_idx)))\n",
    "    print('Pre-filter (Python): {:0.3f}s ({} objects remain)'.format(\n",
    "          time.time() - pre_filter_start, len(filtered_pred)))\n",
    "    if len(filtered_pred) > MAX_DJANGO_QUERY_IDS:\n",
    "        print('SQL query size exceeded {} ids. Sampling for performance reasons...'.format(\n",
    "              MAX_DJANGO_QUERY_IDS), file=sys.stderr)\n",
    "        filtered_pred = random.sample(filtered_pred, MAX_DJANGO_QUERY_IDS)\n",
    "    \n",
    "    sql_filter_start = time.time()\n",
    "    filtered_pred_faces = query_faces([x[0] for x in filtered_pred])\n",
    "    filtered_pred_faces = django_query_filter_fn(filtered_pred_faces, slice_args)\n",
    "    filtered_count = filtered_pred_faces.count()\n",
    "    sample_size = slice_args['sample_size']\n",
    "    if filtered_count > sample_size:\n",
    "        filtered_pred_faces = query_sample(filtered_pred_faces, sample_size)\n",
    "    filtered_pred_faces = list(filtered_pred_faces)\n",
    "    print('Filter + Materialize (SQL): {:0.3f}s'.format(\n",
    "          time.time() - sql_filter_start))\n",
    "    \n",
    "    print('Showing {} of {} faces'.format(\n",
    "          min(sample_size, filtered_count), filtered_count))\n",
    "    \n",
    "    # Reorder the samples\n",
    "    if slice_args['sample_sort'] != 'disabled':\n",
    "        filtered_pred_faces = sort_faces_by_distance(\n",
    "            filtered_pred_faces, face_references.embs,\n",
    "            'ascending' in slice_args['sample_sort'])\n",
    "\n",
    "    selection_widget = esper_widget(\n",
    "        query_faces_result(filtered_pred_faces), disable_playback=True,\n",
    "        crop_bboxes=True, jupyter_keybindings=True, results_per_page=FACES_PER_PAGE)\n",
    "    \n",
    "    def on_submit(b):\n",
    "        selected_idxs = set(selection_widget.selected)\n",
    "        ignored_idxs = set(selection_widget.ignored)\n",
    "        clear_output()\n",
    "        \n",
    "        selected_face_ids = []\n",
    "        ignored_face_ids = []\n",
    "        for i, f in enumerate(filtered_pred_faces):\n",
    "            if i in selected_idxs:\n",
    "                selected_face_ids.append(f['id'])\n",
    "            if i in ignored_idxs:\n",
    "                ignored_face_ids.append(f['id'])\n",
    "              \n",
    "        new_pos_labels = 0\n",
    "        for i in selected_face_ids:\n",
    "            if i not in labeled_ids_set:\n",
    "                pos_examples.add(i)\n",
    "                new_pos_labels += 1\n",
    "        new_neg_labels = 0\n",
    "        for i in ignored_face_ids:\n",
    "            if i not in labeled_ids_set:\n",
    "                neg_examples.add(i)\n",
    "                new_neg_labels += 1\n",
    "                \n",
    "        print('Added {} new positive and {} new negative examples'.format(\n",
    "              new_pos_labels, new_neg_labels))\n",
    "        visualize()\n",
    "    submit_button.on_click(on_submit)\n",
    "        \n",
    "    def on_refresh(b):\n",
    "        clear_output()\n",
    "        print('Refreshed without updating examples')\n",
    "        visualize()\n",
    "    refresh_button.on_click(on_refresh)\n",
    "    \n",
    "    def on_dismiss(b):\n",
    "        clear_output()\n",
    "        print('Dismissed widget. Rerun the cell to get it back.')\n",
    "    dismiss_button.on_click(on_dismiss)\n",
    "    \n",
    "    display(widgets.HBox(\n",
    "        [widgets.Label('Controls:'), submit_button, refresh_button, dismiss_button]))\n",
    "    print(('Highlight in yellow faces (use \\'[\\' key) that are {} and '\n",
    "           'highlight in red faces (\\']\\' key) that are not.').format(\n",
    "          face_references.name))\n",
    "    display(selection_widget)\n",
    "    \n",
    "####\n",
    "# SLICE DEBUG WIDGET\n",
    "####\n",
    "\n",
    "def debug_charts(min_score=0.05):\n",
    "    print('Loading charts for slice... Note: for efficiency, min_score={}'.format(min_score))\n",
    "\n",
    "    slice_args = get_slice_args()\n",
    "    \n",
    "    refresh_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Refresh',\n",
    "        disabled=False,\n",
    "        button_style='info',\n",
    "        tooltip='Refresh examples'\n",
    "    )\n",
    "    def on_refresh(b):\n",
    "        clear_output()\n",
    "        debug_charts()\n",
    "    refresh_button.on_click(on_refresh)\n",
    "    \n",
    "    dismiss_button = widgets.Button(\n",
    "        layout=widgets.Layout(width='auto'),\n",
    "        style={'description_width': 'initial'},\n",
    "        description='Dismiss widget',\n",
    "        disabled=False,\n",
    "        button_style='',\n",
    "        tooltip='Dismiss widget'\n",
    "    )\n",
    "    def on_dismiss(b):\n",
    "        clear_output()\n",
    "        print('Dismissed charts. Rerun the cell to get them back.')\n",
    "    dismiss_button.on_click(on_dismiss)\n",
    "    \n",
    "    gender_filter = GENDER_OPTIONS[slice_args['gender_filter']]\n",
    "\n",
    "    num_tabs = 3\n",
    "    outputs = [widgets.Output() for _ in range(num_tabs)]\n",
    "    tabs = widgets.Tab(children=outputs)\n",
    "    tabs.set_title(0, 'CDF and Positive Count Estimate')\n",
    "    tabs.set_title(1, 'Positive Training Examples')\n",
    "    tabs.set_title(2, 'Negative Training Examples')\n",
    "    \n",
    "    display(widgets.HBox([\n",
    "        widgets.Label('Controls:'), refresh_button, dismiss_button]))\n",
    "    display(tabs)\n",
    "    \n",
    "    with outputs[0]:\n",
    "        print('Computing prediction distibution for slice')\n",
    "        def pre_query_filter_fn(face_id_and_score):\n",
    "            face_id, _ = face_id_and_score\n",
    "            return gender_filter_fn(gender_filter, face_id)\n",
    "        \n",
    "        score_min_idx = bsearch_gte(predictions, min_score, \n",
    "                                    key=lambda x: x[1])\n",
    "        slice_pred = list(filter(pre_query_filter_fn, itertools.islice(\n",
    "            predictions, score_min_idx, len(predictions))))\n",
    "        slice_pred_faces = Face.objects.filter(id__in=[x[0] for x in slice_pred])\n",
    "        slice_pred_faces = django_query_filter_fn(slice_pred_faces, slice_args)\n",
    "        \n",
    "        # Filter predictions\n",
    "        slice_pred_face_ids = {f['id'] for f in slice_pred_faces.values('id')}\n",
    "        slice_pred = list(filter(lambda x: x[0] in slice_pred_face_ids, slice_pred))\n",
    "        \n",
    "        print('Face count: {}'.format(len(slice_pred_face_ids)))\n",
    "        plot_score_histogram(slice_pred, sample=100000, x_min=min_score)\n",
    "        plot_estimated_cdf(slice_pred, sample=100000, x_min=min_score)\n",
    "        \n",
    "    def face_gender_filter_fn(face):\n",
    "        face_id = face['id']\n",
    "        return gender_filter_fn(gender_filter, face_id)\n",
    "        \n",
    "    with outputs[1]:\n",
    "        def show_pos_train_faces():\n",
    "            print('Showing positive training examples from slice (by descending distance).\\n'\n",
    "                  'Press \\']\\' to highlight errors (not {}).'.format(face_references.name))\n",
    "            pos_faces = query_faces(pos_examples)\n",
    "            pos_faces = django_query_filter_fn(pos_faces, slice_args)\n",
    "            if gender_filter != 0:\n",
    "                pos_faces = filter(face_gender_filter_fn, pos_faces)\n",
    "            pos_faces = sort_faces_by_distance(\n",
    "                list(pos_faces), face_references.embs, ascending=True)\n",
    "            pos_train_widget = esper_widget(\n",
    "                query_faces_result(pos_faces), disable_playback=True,\n",
    "                crop_bboxes=True, jupyter_keybindings=True, results_per_page=FACES_PER_PAGE)\n",
    "\n",
    "            submit_pos_button = widgets.Button(\n",
    "                layout=widgets.Layout(width='auto'),\n",
    "                style={'description_width': 'initial'},\n",
    "                description='Commit selections',\n",
    "                disabled=False,\n",
    "                button_style='danger',\n",
    "            )\n",
    "            def on_pos_submit(b):\n",
    "                ignored_idxs = set(pos_train_widget.ignored)\n",
    "                ignored_ids = {\n",
    "                    f['id'] for i, f in enumerate(pos_faces) if i in ignored_idxs\n",
    "                }\n",
    "                global pos_examples, neg_examples\n",
    "                pos_examples = pos_examples - ignored_ids\n",
    "                neg_examples = neg_examples | ignored_ids\n",
    "                clear_output()\n",
    "                print(('Removed {} negative examples from the positive set '\n",
    "                       'and added them to the negative set.').format(\n",
    "                       len(ignored_ids)))\n",
    "                show_pos_train_faces()\n",
    "            submit_pos_button.on_click(on_pos_submit)\n",
    "            \n",
    "            print('Loading widget...')\n",
    "            display(submit_pos_button)\n",
    "            display(pos_train_widget)\n",
    "        show_pos_train_faces()\n",
    "        \n",
    "    with outputs[2]:\n",
    "        def show_neg_train_faces():\n",
    "            print('Showing negative training examples from slice (by ascending distance).\\n'\n",
    "                  'Press \\'[\\' to highlight errors (faces that are {}).'.format(\n",
    "                  face_references.name))\n",
    "            neg_faces = query_faces(neg_examples)\n",
    "            neg_faces = django_query_filter_fn(neg_faces, slice_args)\n",
    "            if gender_filter != 0:\n",
    "                neg_faces = filter(face_gender_filter_fn, neg_faces)\n",
    "            neg_faces = sort_faces_by_distance(\n",
    "                list(neg_faces), face_references.embs, ascending=True)\n",
    "            neg_train_widget = esper_widget(\n",
    "                query_faces_result(neg_faces), disable_playback=True,\n",
    "                crop_bboxes=True, jupyter_keybindings=True, results_per_page=FACES_PER_PAGE)\n",
    "\n",
    "            submit_neg_button = widgets.Button(\n",
    "                layout=widgets.Layout(width='auto'),\n",
    "                style={'description_width': 'initial'},\n",
    "                description='Commit selections',\n",
    "                disabled=False,\n",
    "                button_style='danger',\n",
    "            )\n",
    "            def on_neg_submit(b):\n",
    "                selected_idxs = set(neg_train_widget.selected)\n",
    "                selected_ids = {\n",
    "                    f['id'] for i, f in enumerate(neg_faces) if i in selected_idxs\n",
    "                }\n",
    "                global pos_examples, neg_examples\n",
    "                pos_examples = pos_examples | selected_ids\n",
    "                neg_examples = neg_examples - selected_ids\n",
    "                clear_output()\n",
    "                print(('Removed {} {}s from the negative set '\n",
    "                       'and added them to the positive set.').format(\n",
    "                      len(selected_ids), face_references.name))\n",
    "                show_neg_train_faces()\n",
    "            submit_neg_button.on_click(on_neg_submit)\n",
    "            \n",
    "            print('Loading widget...')\n",
    "            display(submit_neg_button)\n",
    "            display(neg_train_widget)\n",
    "        show_neg_train_faces()\n",
    "        \n",
    "print('Done loading ML and visualization libraries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:01:35.698015Z",
     "start_time": "2018-12-17T22:01:35.665398Z"
    }
   },
   "outputs": [],
   "source": [
    "if pos_examples is None:\n",
    "    raise ValueError('No positive training examples! Did you confirm the selection above?')\n",
    "if neg_examples is None:\n",
    "    raise ValueError('No negative training examples!')\n",
    "print('Proceeding with {} positive and {} negative training examples'.format(\n",
    "    len(pos_examples), len(neg_examples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and obtaining predictions across the dataset\n",
    "\n",
    "`train_model()` will train a binary classifier using the face identifiers in `pos_examples` and `neg_examples`. This will take roughly 20 seconds. Each time you rerun `train_model()`, your model will be retrained, so be sure to rerun it when you have added new labels and are ready to retrain. This will also generate some debugging charts to diagnose model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:13:11.102189Z",
     "start_time": "2018-12-17T22:12:38.570157Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_epochs': 40,\n",
    "    'learning_rate': 1,\n",
    "    'l2_penalty': 1e-5\n",
    "}\n",
    "weights, predictions = train_model(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions and label new examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:02:14.915560Z",
     "start_time": "2018-12-17T22:02:14.340431Z"
    }
   },
   "outputs": [],
   "source": [
    "show_reference_imgs(face_references)\n",
    "display_filter_controls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also define a custom query filter function using any of the Esper models. Note that this cell will need to be re-run each time the function is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:02:56.835357Z",
     "start_time": "2018-12-17T22:02:56.803164Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_filter_fn(qs):\n",
    "    # BEGIN: INSERT CODE HERE\n",
    "    print('No custom filter defined.', file=sys.stderr)\n",
    "    # END\n",
    "    return qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labeling widget will display below once `visualize()` is called. If you update the selections and sliders above, you can reload the visualization by confirming your current labels by hitting the <b>Confirm selections</b> button or by hitting the <b>Refresh</b> button. Alternatively, rerun the cell.\n",
    "\n",
    "<b>To label a positive face, press '['. To label all faces on a page, press '{' (i.e., 'shift + [').</b>\n",
    "\n",
    "<b>To label a negative face, press ']'. To label all faces on a page, press '}' (i.e., 'shift + ]').</b>\n",
    "\n",
    "<b>To expand an image, press '=', and press again to shrink it.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:07:25.419901Z",
     "start_time": "2018-12-17T22:07:24.393901Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to visualizing raw images, it can be helpful to examine debugging plots on varying slices of the dataset. The following cell calles `debug_charts()` which generates plots specific to the selected slice. \n",
    "\n",
    "Note: \"sample size\" and \"score range\" are not applicable to slices. This cell may also be slow to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:13:31.866870Z",
     "start_time": "2018-12-17T22:13:18.378990Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debug_charts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Saving your model\n",
    "\n",
    "Serialize the model weights and the training set. Store the file locally and in Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:14:06.521187Z",
     "start_time": "2018-12-17T22:14:03.159089Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "save_model_and_examples(path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
